{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a139da4",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8417d6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /work/mherre/master-projectV2/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "print(\"Current working directory:\", current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d59c29",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56eab160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "def generate_dataset_overview():\n",
    "    # Load dataset ids from json file\n",
    "    json_file_path = os.path.join(\"../config\", \"config.json\")\n",
    "    with open(json_file_path, \"r\") as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "    # Datasets are in data[datasets]\n",
    "    dataset_ids = config[\"data\"][\"datasets\"]\n",
    "\n",
    "    # Convert dataset_ids to standard Python integers\n",
    "    dataset_ids = [int(dataset_id) for dataset_id in dataset_ids]\n",
    "\n",
    "    regression_data = []\n",
    "    binary_data = []\n",
    "\n",
    "    for dataset_id in dataset_ids:\n",
    "        # Get dataset name from OpenML\n",
    "        dataset = openml.datasets.get_dataset(dataset_id)\n",
    "        name = dataset.name\n",
    "\n",
    "        # Load the actual data to get features\n",
    "        X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute\n",
    "        )\n",
    "\n",
    "        # Calculate statistics\n",
    "        n_samples = len(X)\n",
    "        n_features = X.shape[1]\n",
    "        n_cat_features = sum(categorical_indicator)\n",
    "\n",
    "        # Determine if it's regression or binary classification\n",
    "        if pd.api.types.is_numeric_dtype(y) and len(y.unique()) > 2:\n",
    "            # Regression dataset\n",
    "            task_type = \"regression\"\n",
    "            data_entry = {\n",
    "                \"Name\": name,\n",
    "                \"Samples\": n_samples,\n",
    "                \"Features\": n_features,\n",
    "                \"Cat Features\": n_cat_features,\n",
    "                \"OpenML ID\": dataset_id,\n",
    "            }\n",
    "            regression_data.append(data_entry)\n",
    "        elif len(y.unique()) == 2:\n",
    "            # Binary classification dataset\n",
    "            task_type = \"binary\"\n",
    "            value_counts = y.value_counts(normalize=True)\n",
    "            minority_class_pct = min(value_counts) * 100\n",
    "            \n",
    "            data_entry = {\n",
    "                \"Name\": name,\n",
    "                \"Samples\": n_samples,\n",
    "                \"Features\": n_features,\n",
    "                \"Cat Features\": n_cat_features,\n",
    "                \"Minority Class (%)\": round(minority_class_pct, 2),\n",
    "                \"OpenML ID\": dataset_id,\n",
    "            }\n",
    "            binary_data.append(data_entry)\n",
    "\n",
    "    # Create DataFrames\n",
    "    regression_df = pd.DataFrame(regression_data)\n",
    "    binary_df = pd.DataFrame(binary_data)\n",
    "\n",
    "    # Define columns for each type\n",
    "    regression_cols = [\"Name\", \"Samples\", \"Features\", \"Cat Features\", \"OpenML ID\"]\n",
    "    binary_cols = [\"Name\", \"Samples\", \"Features\", \"Cat Features\", \"Minority Class (%)\", \"OpenML ID\"]\n",
    "\n",
    "    # Reorder columns and sort by samples\n",
    "    if not regression_df.empty:\n",
    "        regression_df = regression_df[regression_cols].sort_values(by=\"Samples\", ascending=True)\n",
    "    \n",
    "    if not binary_df.empty:\n",
    "        binary_df = binary_df[binary_cols].sort_values(by=\"Samples\", ascending=True)\n",
    "\n",
    "    return regression_df, binary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa3ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION DATASETS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_42a15\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_42a15_level0_col0\" class=\"col_heading level0 col0\" >Name</th>\n",
       "      <th id=\"T_42a15_level0_col1\" class=\"col_heading level0 col1\" >Samples</th>\n",
       "      <th id=\"T_42a15_level0_col2\" class=\"col_heading level0 col2\" >Features</th>\n",
       "      <th id=\"T_42a15_level0_col3\" class=\"col_heading level0 col3\" >Cat Features</th>\n",
       "      <th id=\"T_42a15_level0_col4\" class=\"col_heading level0 col4\" >OpenML ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_42a15_row0_col0\" class=\"data row0 col0\" >analcatdata_supreme</td>\n",
       "      <td id=\"T_42a15_row0_col1\" class=\"data row0 col1\" >4052</td>\n",
       "      <td id=\"T_42a15_row0_col2\" class=\"data row0 col2\" >7</td>\n",
       "      <td id=\"T_42a15_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_42a15_row0_col4\" class=\"data row0 col4\" >504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42a15_row1_col0\" class=\"data row1 col0\" >Mercedes_Benz_Greener_Manufacturing</td>\n",
       "      <td id=\"T_42a15_row1_col1\" class=\"data row1 col1\" >4209</td>\n",
       "      <td id=\"T_42a15_row1_col2\" class=\"data row1 col2\" >376</td>\n",
       "      <td id=\"T_42a15_row1_col3\" class=\"data row1 col3\" >8</td>\n",
       "      <td id=\"T_42a15_row1_col4\" class=\"data row1 col4\" >42570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42a15_row2_col0\" class=\"data row2 col0\" >wine_quality</td>\n",
       "      <td id=\"T_42a15_row2_col1\" class=\"data row2 col1\" >6497</td>\n",
       "      <td id=\"T_42a15_row2_col2\" class=\"data row2 col2\" >11</td>\n",
       "      <td id=\"T_42a15_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "      <td id=\"T_42a15_row2_col4\" class=\"data row2 col4\" >287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42a15_row3_col0\" class=\"data row3 col0\" >cpu_act</td>\n",
       "      <td id=\"T_42a15_row3_col1\" class=\"data row3 col1\" >8192</td>\n",
       "      <td id=\"T_42a15_row3_col2\" class=\"data row3 col2\" >21</td>\n",
       "      <td id=\"T_42a15_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_42a15_row3_col4\" class=\"data row3 col4\" >197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42a15_row4_col0\" class=\"data row4 col0\" >visualizing_soil</td>\n",
       "      <td id=\"T_42a15_row4_col1\" class=\"data row4 col1\" >8641</td>\n",
       "      <td id=\"T_42a15_row4_col2\" class=\"data row4 col2\" >4</td>\n",
       "      <td id=\"T_42a15_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "      <td id=\"T_42a15_row4_col4\" class=\"data row4 col4\" >688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42a15_row5_col0\" class=\"data row5 col0\" >yprop_4_1</td>\n",
       "      <td id=\"T_42a15_row5_col1\" class=\"data row5 col1\" >8885</td>\n",
       "      <td id=\"T_42a15_row5_col2\" class=\"data row5 col2\" >251</td>\n",
       "      <td id=\"T_42a15_row5_col3\" class=\"data row5 col3\" >0</td>\n",
       "      <td id=\"T_42a15_row5_col4\" class=\"data row5 col4\" >416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42a15_row6_col0\" class=\"data row6 col0\" >sulfur</td>\n",
       "      <td id=\"T_42a15_row6_col1\" class=\"data row6 col1\" >10081</td>\n",
       "      <td id=\"T_42a15_row6_col2\" class=\"data row6 col2\" >6</td>\n",
       "      <td id=\"T_42a15_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_42a15_row6_col4\" class=\"data row6 col4\" >23515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_42a15_row7_col0\" class=\"data row7 col0\" >Brazilian_houses</td>\n",
       "      <td id=\"T_42a15_row7_col1\" class=\"data row7 col1\" >10692</td>\n",
       "      <td id=\"T_42a15_row7_col2\" class=\"data row7 col2\" >12</td>\n",
       "      <td id=\"T_42a15_row7_col3\" class=\"data row7 col3\" >4</td>\n",
       "      <td id=\"T_42a15_row7_col4\" class=\"data row7 col4\" >42688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e2b6d14c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BINARY CLASSIFICATION DATASETS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_093b4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_093b4_level0_col0\" class=\"col_heading level0 col0\" >Name</th>\n",
       "      <th id=\"T_093b4_level0_col1\" class=\"col_heading level0 col1\" >Samples</th>\n",
       "      <th id=\"T_093b4_level0_col2\" class=\"col_heading level0 col2\" >Features</th>\n",
       "      <th id=\"T_093b4_level0_col3\" class=\"col_heading level0 col3\" >Cat Features</th>\n",
       "      <th id=\"T_093b4_level0_col4\" class=\"col_heading level0 col4\" >Minority Class (%)</th>\n",
       "      <th id=\"T_093b4_level0_col5\" class=\"col_heading level0 col5\" >OpenML ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row0_col0\" class=\"data row0 col0\" >dresses-sales</td>\n",
       "      <td id=\"T_093b4_row0_col1\" class=\"data row0 col1\" >500</td>\n",
       "      <td id=\"T_093b4_row0_col2\" class=\"data row0 col2\" >12</td>\n",
       "      <td id=\"T_093b4_row0_col3\" class=\"data row0 col3\" >11</td>\n",
       "      <td id=\"T_093b4_row0_col4\" class=\"data row0 col4\" >42.00</td>\n",
       "      <td id=\"T_093b4_row0_col5\" class=\"data row0 col5\" >23381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row1_col0\" class=\"data row1 col0\" >climate-model-simulation-crashes</td>\n",
       "      <td id=\"T_093b4_row1_col1\" class=\"data row1 col1\" >540</td>\n",
       "      <td id=\"T_093b4_row1_col2\" class=\"data row1 col2\" >18</td>\n",
       "      <td id=\"T_093b4_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_093b4_row1_col4\" class=\"data row1 col4\" >8.52</td>\n",
       "      <td id=\"T_093b4_row1_col5\" class=\"data row1 col5\" >40994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row2_col0\" class=\"data row2 col0\" >cylinder-bands</td>\n",
       "      <td id=\"T_093b4_row2_col1\" class=\"data row2 col1\" >540</td>\n",
       "      <td id=\"T_093b4_row2_col2\" class=\"data row2 col2\" >37</td>\n",
       "      <td id=\"T_093b4_row2_col3\" class=\"data row2 col3\" >19</td>\n",
       "      <td id=\"T_093b4_row2_col4\" class=\"data row2 col4\" >42.22</td>\n",
       "      <td id=\"T_093b4_row2_col5\" class=\"data row2 col5\" >6332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row3_col0\" class=\"data row3 col0\" >wdbc</td>\n",
       "      <td id=\"T_093b4_row3_col1\" class=\"data row3 col1\" >569</td>\n",
       "      <td id=\"T_093b4_row3_col2\" class=\"data row3 col2\" >30</td>\n",
       "      <td id=\"T_093b4_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_093b4_row3_col4\" class=\"data row3 col4\" >37.26</td>\n",
       "      <td id=\"T_093b4_row3_col5\" class=\"data row3 col5\" >1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row4_col0\" class=\"data row4 col0\" >ilpd</td>\n",
       "      <td id=\"T_093b4_row4_col1\" class=\"data row4 col1\" >583</td>\n",
       "      <td id=\"T_093b4_row4_col2\" class=\"data row4 col2\" >10</td>\n",
       "      <td id=\"T_093b4_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "      <td id=\"T_093b4_row4_col4\" class=\"data row4 col4\" >28.64</td>\n",
       "      <td id=\"T_093b4_row4_col5\" class=\"data row4 col5\" >1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row5_col0\" class=\"data row5 col0\" >tokyo1</td>\n",
       "      <td id=\"T_093b4_row5_col1\" class=\"data row5 col1\" >959</td>\n",
       "      <td id=\"T_093b4_row5_col2\" class=\"data row5 col2\" >44</td>\n",
       "      <td id=\"T_093b4_row5_col3\" class=\"data row5 col3\" >2</td>\n",
       "      <td id=\"T_093b4_row5_col4\" class=\"data row5 col4\" >36.08</td>\n",
       "      <td id=\"T_093b4_row5_col5\" class=\"data row5 col5\" >40705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row6_col0\" class=\"data row6 col0\" >qsar-biodeg</td>\n",
       "      <td id=\"T_093b4_row6_col1\" class=\"data row6 col1\" >1055</td>\n",
       "      <td id=\"T_093b4_row6_col2\" class=\"data row6 col2\" >41</td>\n",
       "      <td id=\"T_093b4_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_093b4_row6_col4\" class=\"data row6 col4\" >33.74</td>\n",
       "      <td id=\"T_093b4_row6_col5\" class=\"data row6 col5\" >1494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row7_col0\" class=\"data row7 col0\" >ozone-level-8hr</td>\n",
       "      <td id=\"T_093b4_row7_col1\" class=\"data row7 col1\" >2534</td>\n",
       "      <td id=\"T_093b4_row7_col2\" class=\"data row7 col2\" >72</td>\n",
       "      <td id=\"T_093b4_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_093b4_row7_col4\" class=\"data row7 col4\" >6.31</td>\n",
       "      <td id=\"T_093b4_row7_col5\" class=\"data row7 col5\" >1487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row8_col0\" class=\"data row8 col0\" >madelon</td>\n",
       "      <td id=\"T_093b4_row8_col1\" class=\"data row8 col1\" >2600</td>\n",
       "      <td id=\"T_093b4_row8_col2\" class=\"data row8 col2\" >500</td>\n",
       "      <td id=\"T_093b4_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td id=\"T_093b4_row8_col4\" class=\"data row8 col4\" >50.00</td>\n",
       "      <td id=\"T_093b4_row8_col5\" class=\"data row8 col5\" >1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row9_col0\" class=\"data row9 col0\" >wilt</td>\n",
       "      <td id=\"T_093b4_row9_col1\" class=\"data row9 col1\" >4839</td>\n",
       "      <td id=\"T_093b4_row9_col2\" class=\"data row9 col2\" >5</td>\n",
       "      <td id=\"T_093b4_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_093b4_row9_col4\" class=\"data row9 col4\" >5.39</td>\n",
       "      <td id=\"T_093b4_row9_col5\" class=\"data row9 col5\" >40983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row10_col0\" class=\"data row10 col0\" >churn</td>\n",
       "      <td id=\"T_093b4_row10_col1\" class=\"data row10 col1\" >5000</td>\n",
       "      <td id=\"T_093b4_row10_col2\" class=\"data row10 col2\" >20</td>\n",
       "      <td id=\"T_093b4_row10_col3\" class=\"data row10 col3\" >4</td>\n",
       "      <td id=\"T_093b4_row10_col4\" class=\"data row10 col4\" >14.14</td>\n",
       "      <td id=\"T_093b4_row10_col5\" class=\"data row10 col5\" >40701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row11_col0\" class=\"data row11 col0\" >phoneme</td>\n",
       "      <td id=\"T_093b4_row11_col1\" class=\"data row11 col1\" >5404</td>\n",
       "      <td id=\"T_093b4_row11_col2\" class=\"data row11 col2\" >5</td>\n",
       "      <td id=\"T_093b4_row11_col3\" class=\"data row11 col3\" >0</td>\n",
       "      <td id=\"T_093b4_row11_col4\" class=\"data row11 col4\" >29.35</td>\n",
       "      <td id=\"T_093b4_row11_col5\" class=\"data row11 col5\" >1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row12_col0\" class=\"data row12 col0\" >SpeedDating</td>\n",
       "      <td id=\"T_093b4_row12_col1\" class=\"data row12 col1\" >8378</td>\n",
       "      <td id=\"T_093b4_row12_col2\" class=\"data row12 col2\" >120</td>\n",
       "      <td id=\"T_093b4_row12_col3\" class=\"data row12 col3\" >61</td>\n",
       "      <td id=\"T_093b4_row12_col4\" class=\"data row12 col4\" >16.47</td>\n",
       "      <td id=\"T_093b4_row12_col5\" class=\"data row12 col5\" >40536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_093b4_row13_col0\" class=\"data row13 col0\" >PhishingWebsites</td>\n",
       "      <td id=\"T_093b4_row13_col1\" class=\"data row13 col1\" >11055</td>\n",
       "      <td id=\"T_093b4_row13_col2\" class=\"data row13 col2\" >30</td>\n",
       "      <td id=\"T_093b4_row13_col3\" class=\"data row13 col3\" >30</td>\n",
       "      <td id=\"T_093b4_row13_col4\" class=\"data row13 col4\" >44.31</td>\n",
       "      <td id=\"T_093b4_row13_col5\" class=\"data row13 col5\" >4534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e2b6d14c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the two separate tables\n",
    "regression_table, binary_table = generate_dataset_overview()\n",
    "\n",
    "print(\"REGRESSION DATASETS\")\n",
    "display(regression_table.style.hide(axis=\"index\"))\n",
    "\n",
    "print(\"\\nBINARY CLASSIFICATION DATASETS\")\n",
    "display(binary_table.style.hide(axis=\"index\").format({\"Minority Class (%)\": \"{:.2f}\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7716e",
   "metadata": {},
   "source": [
    "#  Performance Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064931f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "def load_all_results():\n",
    "    \"\"\"Load all teacher and student results from the results directory.\"\"\"\n",
    "    results_dir = \"../results\"\n",
    "    all_results = {}\n",
    "    \n",
    "    # Load teacher results\n",
    "    teacher_dir = os.path.join(results_dir, \"teacher\")\n",
    "    if os.path.exists(teacher_dir):\n",
    "        for file in os.listdir(teacher_dir):\n",
    "            if file.endswith(\"_results.json\"):\n",
    "                dataset_id = file.split(\"_\")[0]\n",
    "                with open(os.path.join(teacher_dir, file), 'r') as f:\n",
    "                    teacher_data = json.load(f)\n",
    "                \n",
    "                if dataset_id not in all_results:\n",
    "                    all_results[dataset_id] = {}\n",
    "                \n",
    "                for key, result in teacher_data.items():\n",
    "                    model_type = result.get(\"model_type\", \"unknown\")\n",
    "                    task_type = result.get(\"task_type\", \"unknown\")\n",
    "                    all_results[dataset_id][f\"{model_type}_teacher\"] = result\n",
    "    \n",
    "    # Load student results\n",
    "    student_dir = os.path.join(results_dir, \"student\")\n",
    "    if os.path.exists(student_dir):\n",
    "        for file in os.listdir(student_dir):\n",
    "            if file.endswith(\"_results.json\"):\n",
    "                dataset_id = file.split(\"_\")[0]\n",
    "                with open(os.path.join(student_dir, file), 'r') as f:\n",
    "                    student_data = json.load(f)\n",
    "                \n",
    "                if dataset_id not in all_results:\n",
    "                    all_results[dataset_id] = {}\n",
    "                \n",
    "                for key, result in student_data.items():\n",
    "                    student_model = result.get(\"student_model_type\", \"unknown\")\n",
    "                    teacher_model = result.get(\"teacher_model_type\", \"unknown\")\n",
    "                    task_type = result.get(\"student_task_type\", result.get(\"task_type\", \"unknown\"))\n",
    "                    model_key = f\"{student_model}({teacher_model})_student\"\n",
    "                    all_results[dataset_id][model_key] = result\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def get_dataset_info():\n",
    "    \"\"\"Get dataset information including names and sizes.\"\"\"\n",
    "    json_file_path = os.path.join(\"../config\", \"config.json\")\n",
    "    with open(json_file_path, \"r\") as file:\n",
    "        config = json.load(file)\n",
    "    \n",
    "    dataset_ids = [str(id) for id in config[\"data\"][\"datasets\"]]\n",
    "    \n",
    "    # You can extend this to get actual dataset sizes from your data\n",
    "    # For now, we'll use placeholder sizes or load from cached data\n",
    "    dataset_info = {}\n",
    "    \n",
    "    # Try to get sizes from your cached data or OpenML\n",
    "    import openml\n",
    "    for dataset_id in dataset_ids:\n",
    "        try:\n",
    "            dataset = openml.datasets.get_dataset(int(dataset_id))\n",
    "            X, y, _, _ = dataset.get_data(dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "            dataset_info[dataset_id] = {\n",
    "                'name': dataset.name,\n",
    "                'size': len(X),\n",
    "                'task_type': 'binary' if len(y.unique()) == 2 else 'regression'\n",
    "            }\n",
    "        except:\n",
    "            dataset_info[dataset_id] = {\n",
    "                'name': f'Dataset_{dataset_id}',\n",
    "                'size': 0,\n",
    "                'task_type': 'unknown'\n",
    "            }\n",
    "    \n",
    "    return dataset_info\n",
    "\n",
    "def create_results_table(metric='f1', task_filter=None, model_filter=None):\n",
    "    \"\"\"\n",
    "    Create a comprehensive results table.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    metric : str\n",
    "        The metric to display (e.g., 'f1', 'acc', 'roc', 'mae', 'mse', 'rmse', 'r2')\n",
    "    task_filter : str or None\n",
    "        Filter by task type ('binary', 'regression', or None for all)\n",
    "    model_filter : str or None\n",
    "        Filter by model type ('teacher', 'student', 'both', or None for all).\n",
    "        If None, defaults to 'both'.\n",
    "    \"\"\"\n",
    "    all_results = load_all_results()\n",
    "    dataset_info = get_dataset_info()\n",
    "    \n",
    "    table_data = []\n",
    "    \n",
    "    for dataset_id, models_data_for_dataset in all_results.items():\n",
    "        if dataset_id not in dataset_info:\n",
    "            continue\n",
    "            \n",
    "        current_dataset_info = dataset_info[dataset_id]\n",
    "        \n",
    "        # Filter by task type if specified\n",
    "        if task_filter and current_dataset_info['task_type'] != task_filter:\n",
    "            continue\n",
    "\n",
    "        # Initialize row with dataset-specific info\n",
    "        row = {\n",
    "            'Dataset ID': dataset_id,\n",
    "            'Dataset Name': current_dataset_info['name'],\n",
    "            'Size': current_dataset_info['size'],\n",
    "            'Task Type': current_dataset_info['task_type']\n",
    "        }\n",
    "        \n",
    "        at_least_one_filtered_model_has_data = False\n",
    "        \n",
    "        for model_name, result in models_data_for_dataset.items():\n",
    "            # Determine if this model should be included based on model_filter\n",
    "            include_this_model = False\n",
    "            if model_filter == 'teacher':\n",
    "                if model_name.endswith('_teacher'):\n",
    "                    include_this_model = True\n",
    "            elif model_filter == 'student':\n",
    "                if model_name.endswith('_student'):\n",
    "                    include_this_model = True\n",
    "            elif model_filter == 'both' or model_filter is None: # Treat None as 'both'\n",
    "                include_this_model = True\n",
    "            # else: model_filter is an unexpected value, model is not included.\n",
    "\n",
    "            if include_this_model:\n",
    "                mean_key = f\"mean_{metric}\"\n",
    "                std_key = f\"std_{metric}\"\n",
    "                \n",
    "                if mean_key in result and std_key in result:\n",
    "                    mean_val = result[mean_key]\n",
    "                    std_val = result[std_key]\n",
    "                    row[model_name] = f\"{mean_val:.3f} ± {std_val:.3f}\"\n",
    "                    at_least_one_filtered_model_has_data = True\n",
    "                elif metric in result:  # Fallback if no std available\n",
    "                    row[model_name] = f\"{result[metric]:.3f}\"\n",
    "                    at_least_one_filtered_model_has_data = True\n",
    "                else:\n",
    "                    # Model is selected by filter, but lacks the specific metric.\n",
    "                    # Add it as a column with \"N/A\".\n",
    "                    row[model_name] = \"N/A\"\n",
    "        \n",
    "        # If no model that passed the filter actually had the metric data, skip this dataset row.\n",
    "        if not at_least_one_filtered_model_has_data:\n",
    "            continue\n",
    "            \n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(table_data)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"No results found for metric '{metric}' with task filter '{task_filter}' and model filter '{model_filter}'\")\n",
    "        return df\n",
    "    \n",
    "    # Sort by dataset size\n",
    "    df = df.sort_values('Size', ascending=True)\n",
    "    \n",
    "    # Reorder columns: Dataset info first, then models\n",
    "    info_cols = ['Dataset ID', 'Dataset Name', 'Size', 'Task Type']\n",
    "    # Model columns are dynamically determined by what was added to the rows\n",
    "    model_cols = [col for col in df.columns if col not in info_cols]\n",
    "    df = df[info_cols + sorted(model_cols)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def display_results_table(metric='f1', task_filter=None, model_filter=None):\n",
    "    \"\"\"Display the results table with styling.\"\"\"\n",
    "    df = create_results_table(metric, task_filter, model_filter)\n",
    "    \n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    print(f\"Results Table - Metric: {metric.upper()}\")\n",
    "    if task_filter:\n",
    "        print(f\"Task Filter: {task_filter}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Style the table\n",
    "    styled_df = df.style.hide(axis=\"index\")\n",
    "    \n",
    "    # Apply formatting\n",
    "    styled_df = styled_df.format({\n",
    "        'Size': '{:,}',\n",
    "        'Dataset ID': lambda x: str(x)\n",
    "    })\n",
    "    \n",
    "    display(styled_df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208b8987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Results Table - Metric: F1\n",
      "Task Filter: binary\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bae29\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_bae29_level0_col0\" class=\"col_heading level0 col0\" >Dataset ID</th>\n",
       "      <th id=\"T_bae29_level0_col1\" class=\"col_heading level0 col1\" >Dataset Name</th>\n",
       "      <th id=\"T_bae29_level0_col2\" class=\"col_heading level0 col2\" >Size</th>\n",
       "      <th id=\"T_bae29_level0_col3\" class=\"col_heading level0 col3\" >Task Type</th>\n",
       "      <th id=\"T_bae29_level0_col4\" class=\"col_heading level0 col4\" >catboost_teacher</th>\n",
       "      <th id=\"T_bae29_level0_col5\" class=\"col_heading level0 col5\" >grande_teacher</th>\n",
       "      <th id=\"T_bae29_level0_col6\" class=\"col_heading level0 col6\" >mlp_teacher</th>\n",
       "      <th id=\"T_bae29_level0_col7\" class=\"col_heading level0 col7\" >random_forest_teacher</th>\n",
       "      <th id=\"T_bae29_level0_col8\" class=\"col_heading level0 col8\" >tabm_teacher</th>\n",
       "      <th id=\"T_bae29_level0_col9\" class=\"col_heading level0 col9\" >tabpfn_teacher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row0_col0\" class=\"data row0 col0\" >23381</td>\n",
       "      <td id=\"T_bae29_row0_col1\" class=\"data row0 col1\" >dresses-sales</td>\n",
       "      <td id=\"T_bae29_row0_col2\" class=\"data row0 col2\" >500</td>\n",
       "      <td id=\"T_bae29_row0_col3\" class=\"data row0 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row0_col4\" class=\"data row0 col4\" >0.507 ± 0.032</td>\n",
       "      <td id=\"T_bae29_row0_col5\" class=\"data row0 col5\" >0.596 ± 0.045</td>\n",
       "      <td id=\"T_bae29_row0_col6\" class=\"data row0 col6\" >0.543 ± 0.061</td>\n",
       "      <td id=\"T_bae29_row0_col7\" class=\"data row0 col7\" >0.585 ± 0.037</td>\n",
       "      <td id=\"T_bae29_row0_col8\" class=\"data row0 col8\" >0.582 ± 0.057</td>\n",
       "      <td id=\"T_bae29_row0_col9\" class=\"data row0 col9\" >0.599 ± 0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row1_col0\" class=\"data row1 col0\" >40994</td>\n",
       "      <td id=\"T_bae29_row1_col1\" class=\"data row1 col1\" >climate-model-simulation-crashes</td>\n",
       "      <td id=\"T_bae29_row1_col2\" class=\"data row1 col2\" >540</td>\n",
       "      <td id=\"T_bae29_row1_col3\" class=\"data row1 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row1_col4\" class=\"data row1 col4\" >0.709 ± 0.087</td>\n",
       "      <td id=\"T_bae29_row1_col5\" class=\"data row1 col5\" >0.787 ± 0.083</td>\n",
       "      <td id=\"T_bae29_row1_col6\" class=\"data row1 col6\" >0.775 ± 0.063</td>\n",
       "      <td id=\"T_bae29_row1_col7\" class=\"data row1 col7\" >0.554 ± 0.079</td>\n",
       "      <td id=\"T_bae29_row1_col8\" class=\"data row1 col8\" >0.842 ± 0.047</td>\n",
       "      <td id=\"T_bae29_row1_col9\" class=\"data row1 col9\" >0.811 ± 0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row2_col0\" class=\"data row2 col0\" >6332</td>\n",
       "      <td id=\"T_bae29_row2_col1\" class=\"data row2 col1\" >cylinder-bands</td>\n",
       "      <td id=\"T_bae29_row2_col2\" class=\"data row2 col2\" >540</td>\n",
       "      <td id=\"T_bae29_row2_col3\" class=\"data row2 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row2_col4\" class=\"data row2 col4\" >0.777 ± 0.062</td>\n",
       "      <td id=\"T_bae29_row2_col5\" class=\"data row2 col5\" >0.755 ± 0.023</td>\n",
       "      <td id=\"T_bae29_row2_col6\" class=\"data row2 col6\" >0.779 ± 0.042</td>\n",
       "      <td id=\"T_bae29_row2_col7\" class=\"data row2 col7\" >0.806 ± 0.040</td>\n",
       "      <td id=\"T_bae29_row2_col8\" class=\"data row2 col8\" >0.763 ± 0.058</td>\n",
       "      <td id=\"T_bae29_row2_col9\" class=\"data row2 col9\" >0.753 ± 0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row3_col0\" class=\"data row3 col0\" >1510</td>\n",
       "      <td id=\"T_bae29_row3_col1\" class=\"data row3 col1\" >wdbc</td>\n",
       "      <td id=\"T_bae29_row3_col2\" class=\"data row3 col2\" >569</td>\n",
       "      <td id=\"T_bae29_row3_col3\" class=\"data row3 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row3_col4\" class=\"data row3 col4\" >0.943 ± 0.039</td>\n",
       "      <td id=\"T_bae29_row3_col5\" class=\"data row3 col5\" >0.968 ± 0.009</td>\n",
       "      <td id=\"T_bae29_row3_col6\" class=\"data row3 col6\" >0.974 ± 0.010</td>\n",
       "      <td id=\"T_bae29_row3_col7\" class=\"data row3 col7\" >0.951 ± 0.016</td>\n",
       "      <td id=\"T_bae29_row3_col8\" class=\"data row3 col8\" >0.974 ± 0.008</td>\n",
       "      <td id=\"T_bae29_row3_col9\" class=\"data row3 col9\" >0.974 ± 0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row4_col0\" class=\"data row4 col0\" >1480</td>\n",
       "      <td id=\"T_bae29_row4_col1\" class=\"data row4 col1\" >ilpd</td>\n",
       "      <td id=\"T_bae29_row4_col2\" class=\"data row4 col2\" >583</td>\n",
       "      <td id=\"T_bae29_row4_col3\" class=\"data row4 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row4_col4\" class=\"data row4 col4\" >0.564 ± 0.021</td>\n",
       "      <td id=\"T_bae29_row4_col5\" class=\"data row4 col5\" >0.597 ± 0.033</td>\n",
       "      <td id=\"T_bae29_row4_col6\" class=\"data row4 col6\" >0.579 ± 0.032</td>\n",
       "      <td id=\"T_bae29_row4_col7\" class=\"data row4 col7\" >0.579 ± 0.043</td>\n",
       "      <td id=\"T_bae29_row4_col8\" class=\"data row4 col8\" >0.562 ± 0.030</td>\n",
       "      <td id=\"T_bae29_row4_col9\" class=\"data row4 col9\" >0.528 ± 0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row5_col0\" class=\"data row5 col0\" >40705</td>\n",
       "      <td id=\"T_bae29_row5_col1\" class=\"data row5 col1\" >tokyo1</td>\n",
       "      <td id=\"T_bae29_row5_col2\" class=\"data row5 col2\" >959</td>\n",
       "      <td id=\"T_bae29_row5_col3\" class=\"data row5 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row5_col4\" class=\"data row5 col4\" >0.916 ± 0.012</td>\n",
       "      <td id=\"T_bae29_row5_col5\" class=\"data row5 col5\" >0.919 ± 0.021</td>\n",
       "      <td id=\"T_bae29_row5_col6\" class=\"data row5 col6\" >0.904 ± 0.027</td>\n",
       "      <td id=\"T_bae29_row5_col7\" class=\"data row5 col7\" >0.925 ± 0.017</td>\n",
       "      <td id=\"T_bae29_row5_col8\" class=\"data row5 col8\" >0.915 ± 0.017</td>\n",
       "      <td id=\"T_bae29_row5_col9\" class=\"data row5 col9\" >0.915 ± 0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row6_col0\" class=\"data row6 col0\" >1494</td>\n",
       "      <td id=\"T_bae29_row6_col1\" class=\"data row6 col1\" >qsar-biodeg</td>\n",
       "      <td id=\"T_bae29_row6_col2\" class=\"data row6 col2\" >1,055</td>\n",
       "      <td id=\"T_bae29_row6_col3\" class=\"data row6 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row6_col4\" class=\"data row6 col4\" >0.853 ± 0.015</td>\n",
       "      <td id=\"T_bae29_row6_col5\" class=\"data row6 col5\" >0.856 ± 0.016</td>\n",
       "      <td id=\"T_bae29_row6_col6\" class=\"data row6 col6\" >0.856 ± 0.025</td>\n",
       "      <td id=\"T_bae29_row6_col7\" class=\"data row6 col7\" >0.857 ± 0.007</td>\n",
       "      <td id=\"T_bae29_row6_col8\" class=\"data row6 col8\" >0.864 ± 0.013</td>\n",
       "      <td id=\"T_bae29_row6_col9\" class=\"data row6 col9\" >0.865 ± 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row7_col0\" class=\"data row7 col0\" >1487</td>\n",
       "      <td id=\"T_bae29_row7_col1\" class=\"data row7 col1\" >ozone-level-8hr</td>\n",
       "      <td id=\"T_bae29_row7_col2\" class=\"data row7 col2\" >2,534</td>\n",
       "      <td id=\"T_bae29_row7_col3\" class=\"data row7 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row7_col4\" class=\"data row7 col4\" >0.587 ± 0.054</td>\n",
       "      <td id=\"T_bae29_row7_col5\" class=\"data row7 col5\" >0.691 ± 0.054</td>\n",
       "      <td id=\"T_bae29_row7_col6\" class=\"data row7 col6\" >0.712 ± 0.026</td>\n",
       "      <td id=\"T_bae29_row7_col7\" class=\"data row7 col7\" >0.590 ± 0.050</td>\n",
       "      <td id=\"T_bae29_row7_col8\" class=\"data row7 col8\" >0.738 ± 0.035</td>\n",
       "      <td id=\"T_bae29_row7_col9\" class=\"data row7 col9\" >0.695 ± 0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row8_col0\" class=\"data row8 col0\" >1485</td>\n",
       "      <td id=\"T_bae29_row8_col1\" class=\"data row8 col1\" >madelon</td>\n",
       "      <td id=\"T_bae29_row8_col2\" class=\"data row8 col2\" >2,600</td>\n",
       "      <td id=\"T_bae29_row8_col3\" class=\"data row8 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row8_col4\" class=\"data row8 col4\" >0.840 ± 0.017</td>\n",
       "      <td id=\"T_bae29_row8_col5\" class=\"data row8 col5\" >0.798 ± 0.019</td>\n",
       "      <td id=\"T_bae29_row8_col6\" class=\"data row8 col6\" >0.558 ± 0.021</td>\n",
       "      <td id=\"T_bae29_row8_col7\" class=\"data row8 col7\" >0.726 ± 0.019</td>\n",
       "      <td id=\"T_bae29_row8_col8\" class=\"data row8 col8\" >0.596 ± 0.013</td>\n",
       "      <td id=\"T_bae29_row8_col9\" class=\"data row8 col9\" >0.895 ± 0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row9_col0\" class=\"data row9 col0\" >40983</td>\n",
       "      <td id=\"T_bae29_row9_col1\" class=\"data row9 col1\" >wilt</td>\n",
       "      <td id=\"T_bae29_row9_col2\" class=\"data row9 col2\" >4,839</td>\n",
       "      <td id=\"T_bae29_row9_col3\" class=\"data row9 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row9_col4\" class=\"data row9 col4\" >0.924 ± 0.016</td>\n",
       "      <td id=\"T_bae29_row9_col5\" class=\"data row9 col5\" >0.939 ± 0.016</td>\n",
       "      <td id=\"T_bae29_row9_col6\" class=\"data row9 col6\" >0.930 ± 0.008</td>\n",
       "      <td id=\"T_bae29_row9_col7\" class=\"data row9 col7\" >0.908 ± 0.020</td>\n",
       "      <td id=\"T_bae29_row9_col8\" class=\"data row9 col8\" >0.931 ± 0.015</td>\n",
       "      <td id=\"T_bae29_row9_col9\" class=\"data row9 col9\" >0.944 ± 0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row10_col0\" class=\"data row10 col0\" >40701</td>\n",
       "      <td id=\"T_bae29_row10_col1\" class=\"data row10 col1\" >churn</td>\n",
       "      <td id=\"T_bae29_row10_col2\" class=\"data row10 col2\" >5,000</td>\n",
       "      <td id=\"T_bae29_row10_col3\" class=\"data row10 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row10_col4\" class=\"data row10 col4\" >0.899 ± 0.009</td>\n",
       "      <td id=\"T_bae29_row10_col5\" class=\"data row10 col5\" >0.918 ± 0.014</td>\n",
       "      <td id=\"T_bae29_row10_col6\" class=\"data row10 col6\" >0.825 ± 0.018</td>\n",
       "      <td id=\"T_bae29_row10_col7\" class=\"data row10 col7\" >0.889 ± 0.020</td>\n",
       "      <td id=\"T_bae29_row10_col8\" class=\"data row10 col8\" >0.896 ± 0.017</td>\n",
       "      <td id=\"T_bae29_row10_col9\" class=\"data row10 col9\" >0.922 ± 0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row11_col0\" class=\"data row11 col0\" >1489</td>\n",
       "      <td id=\"T_bae29_row11_col1\" class=\"data row11 col1\" >phoneme</td>\n",
       "      <td id=\"T_bae29_row11_col2\" class=\"data row11 col2\" >5,404</td>\n",
       "      <td id=\"T_bae29_row11_col3\" class=\"data row11 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row11_col4\" class=\"data row11 col4\" >0.871 ± 0.008</td>\n",
       "      <td id=\"T_bae29_row11_col5\" class=\"data row11 col5\" >0.846 ± 0.007</td>\n",
       "      <td id=\"T_bae29_row11_col6\" class=\"data row11 col6\" >0.847 ± 0.031</td>\n",
       "      <td id=\"T_bae29_row11_col7\" class=\"data row11 col7\" >0.892 ± 0.005</td>\n",
       "      <td id=\"T_bae29_row11_col8\" class=\"data row11 col8\" >0.878 ± 0.006</td>\n",
       "      <td id=\"T_bae29_row11_col9\" class=\"data row11 col9\" >0.895 ± 0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row12_col0\" class=\"data row12 col0\" >40536</td>\n",
       "      <td id=\"T_bae29_row12_col1\" class=\"data row12 col1\" >SpeedDating</td>\n",
       "      <td id=\"T_bae29_row12_col2\" class=\"data row12 col2\" >8,378</td>\n",
       "      <td id=\"T_bae29_row12_col3\" class=\"data row12 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row12_col4\" class=\"data row12 col4\" >0.696 ± 0.023</td>\n",
       "      <td id=\"T_bae29_row12_col5\" class=\"data row12 col5\" >0.713 ± 0.020</td>\n",
       "      <td id=\"T_bae29_row12_col6\" class=\"data row12 col6\" >0.703 ± 0.018</td>\n",
       "      <td id=\"T_bae29_row12_col7\" class=\"data row12 col7\" >0.626 ± 0.020</td>\n",
       "      <td id=\"T_bae29_row12_col8\" class=\"data row12 col8\" >0.724 ± 0.023</td>\n",
       "      <td id=\"T_bae29_row12_col9\" class=\"data row12 col9\" >0.693 ± 0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bae29_row13_col0\" class=\"data row13 col0\" >4534</td>\n",
       "      <td id=\"T_bae29_row13_col1\" class=\"data row13 col1\" >PhishingWebsites</td>\n",
       "      <td id=\"T_bae29_row13_col2\" class=\"data row13 col2\" >11,055</td>\n",
       "      <td id=\"T_bae29_row13_col3\" class=\"data row13 col3\" >binary</td>\n",
       "      <td id=\"T_bae29_row13_col4\" class=\"data row13 col4\" >0.965 ± 0.002</td>\n",
       "      <td id=\"T_bae29_row13_col5\" class=\"data row13 col5\" >0.961 ± 0.003</td>\n",
       "      <td id=\"T_bae29_row13_col6\" class=\"data row13 col6\" >0.962 ± 0.004</td>\n",
       "      <td id=\"T_bae29_row13_col7\" class=\"data row13 col7\" >0.970 ± 0.002</td>\n",
       "      <td id=\"T_bae29_row13_col8\" class=\"data row13 col8\" >0.969 ± 0.004</td>\n",
       "      <td id=\"T_bae29_row13_col9\" class=\"data row13 col9\" >0.963 ± 0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2d442777f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, let's see what metrics are available\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "table = display_results_table(metric='f1', task_filter='binary', model_filter='teacher')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06512d9b",
   "metadata": {},
   "source": [
    "# Normalized Mean and MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bfc8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalized_mean_and_mrr(metric='f1', task_filter=None, model_filter='both'):\n",
    "    \"\"\"\n",
    "    Calculate normalized mean performance and Mean Reciprocal Rank (MRR) across all datasets and models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    metric : str\n",
    "        The metric to evaluate (e.g., 'f1', 'acc', 'roc', 'mae', 'mse', 'rmse', 'r2')\n",
    "    task_filter : str or None\n",
    "        Filter by task type ('binary', 'regression', or None for all)\n",
    "    model_filter : str\n",
    "        Which models to include ('teacher', 'student', or 'both')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: Contains normalized means and MRR for each model\n",
    "    \"\"\"\n",
    "    all_results = load_all_results()\n",
    "    dataset_info = get_dataset_info()\n",
    "    \n",
    "    # Determine if lower is better for this metric\n",
    "    lower_is_better = metric.lower() in ['mae', 'mse', 'rmse', 'loss', 'inference_time']\n",
    "    \n",
    "    # Collect all model performances per dataset\n",
    "    dataset_performances = {}  # {dataset_id: {model_name: performance}}\n",
    "    all_models = set()\n",
    "    \n",
    "    for dataset_id, models in all_results.items():\n",
    "        if dataset_id not in dataset_info:\n",
    "            continue\n",
    "            \n",
    "        # Filter by task type if specified\n",
    "        if task_filter and dataset_info[dataset_id]['task_type'] != task_filter:\n",
    "            continue\n",
    "        \n",
    "        dataset_performances[dataset_id] = {}\n",
    "        \n",
    "        for model_name, result in models.items():\n",
    "            # Apply model filter\n",
    "            if model_filter == 'teacher' and not model_name.endswith('_teacher'):\n",
    "                continue\n",
    "            elif model_filter == 'student' and not model_name.endswith('_student'):\n",
    "                continue\n",
    "            elif model_filter == 'both':\n",
    "                pass  # Include all models\n",
    "            \n",
    "            mean_key = f\"mean_{metric}\"\n",
    "            if mean_key in result:\n",
    "                performance = result[mean_key]\n",
    "                dataset_performances[dataset_id][model_name] = performance\n",
    "                all_models.add(model_name)\n",
    "    \n",
    "    if not dataset_performances:\n",
    "        print(f\"No data found for metric '{metric}' with given filters\")\n",
    "        return {}\n",
    "    \n",
    "    # Calculate normalized performances and ranks for each dataset\n",
    "    normalized_performances = {model: [] for model in all_models}\n",
    "    reciprocal_ranks = {model: [] for model in all_models}\n",
    "    \n",
    "    for dataset_id, model_perfs in dataset_performances.items():\n",
    "        if len(model_perfs) < 2:  # Need at least 2 models to normalize\n",
    "            continue\n",
    "            \n",
    "        # Get performance values\n",
    "        performances = list(model_perfs.values())\n",
    "        model_names = list(model_perfs.keys())\n",
    "        \n",
    "        # Calculate min and max for normalization\n",
    "        min_perf = min(performances)\n",
    "        max_perf = max(performances)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if max_perf == min_perf:\n",
    "            # All models perform equally, assign normalized score of 1.0 to all\n",
    "            for model_name in model_names:\n",
    "                normalized_performances[model_name].append(1.0)\n",
    "                reciprocal_ranks[model_name].append(1.0)  # All tied for first place\n",
    "            continue\n",
    "        \n",
    "        # Normalize performances to [0, 1]\n",
    "        normalized_dataset_perfs = {}\n",
    "        for model_name, perf in model_perfs.items():\n",
    "            if lower_is_better:\n",
    "                # For metrics where lower is better, invert the normalization\n",
    "                normalized_perf = (max_perf - perf) / (max_perf - min_perf)\n",
    "            else:\n",
    "                # For metrics where higher is better\n",
    "                normalized_perf = (perf - min_perf) / (max_perf - min_perf)\n",
    "            \n",
    "            normalized_dataset_perfs[model_name] = normalized_perf\n",
    "            normalized_performances[model_name].append(normalized_perf)\n",
    "        \n",
    "        # Calculate ranks (1 = best, 2 = second best, etc.)\n",
    "        if lower_is_better:\n",
    "            sorted_models = sorted(model_perfs.items(), key=lambda x: x[1])  # ascending for lower is better\n",
    "        else:\n",
    "            sorted_models = sorted(model_perfs.items(), key=lambda x: x[1], reverse=True)  # descending for higher is better\n",
    "        \n",
    "        # Handle ties by assigning average rank\n",
    "        ranks = {}\n",
    "        current_rank = 1\n",
    "        i = 0\n",
    "        while i < len(sorted_models):\n",
    "            # Find all models with the same performance\n",
    "            current_perf = sorted_models[i][1]\n",
    "            tied_models = [sorted_models[i][0]]\n",
    "            j = i + 1\n",
    "            while j < len(sorted_models) and sorted_models[j][1] == current_perf:\n",
    "                tied_models.append(sorted_models[j][0])\n",
    "                j += 1\n",
    "            \n",
    "            # Assign average rank to tied models\n",
    "            if len(tied_models) == 1:\n",
    "                ranks[tied_models[0]] = current_rank\n",
    "            else:\n",
    "                avg_rank = current_rank + (len(tied_models) - 1) / 2\n",
    "                for model in tied_models:\n",
    "                    ranks[model] = avg_rank\n",
    "            \n",
    "            current_rank += len(tied_models)\n",
    "            i = j\n",
    "        \n",
    "        # Calculate reciprocal ranks\n",
    "        for model_name in model_names:\n",
    "            rank = ranks[model_name]\n",
    "            reciprocal_ranks[model_name].append(1.0 / rank)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    results = {}\n",
    "    for model in all_models:\n",
    "        if normalized_performances[model]:  # Only include models with data\n",
    "            norm_mean = np.mean(normalized_performances[model])\n",
    "            mrr = np.mean(reciprocal_ranks[model])\n",
    "            results[model] = {\n",
    "                'normalized_mean': norm_mean,\n",
    "                'mrr': mrr,\n",
    "                'num_datasets': len(normalized_performances[model])\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def prettify(key: str) -> str:\n",
    "    \"\"\"Convert `tabpfn_teacher` → `TabPFN (Teacher)`.\"\"\"\n",
    "    # 1) drop trailing \"_teacher\" / \"_student\" if present\n",
    "    base = key.rsplit('_', 1)[0] if key.endswith(('_teacher', '_student')) else key\n",
    "\n",
    "    # 2) explicit dictionary for the spellings you want\n",
    "    mapping = {\n",
    "        'tabpfn'      : 'TabPFN',\n",
    "        'tabm'        : 'TabM',\n",
    "        'grande'      : 'GRANDE',\n",
    "        'catboost'    : 'CatBoost',\n",
    "        'mlp'         : 'MLP',\n",
    "        'random_forest' : 'RForest',\n",
    "        # add more if needed\n",
    "    }\n",
    "\n",
    "    return mapping.get(base.lower(), base.replace('_', ' ').title())\n",
    "\n",
    "def display_normalized_results(metric='f1', task_filter=None, model_filter='both'):\n",
    "    \"\"\"Display normalized mean and MRR results in a formatted table.\"\"\"\n",
    "    results = calculate_normalized_mean_and_mrr(metric, task_filter, model_filter)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No results to display\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = []\n",
    "    for model_name, metrics in results.items():\n",
    "        data.append({\n",
    "            'Model': prettify(model_name),\n",
    "            'Normalized Mean': metrics['normalized_mean'],\n",
    "            'MRR': metrics['mrr'],\n",
    "            'Datasets': metrics['num_datasets']\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Sort by normalized mean (descending)\n",
    "    df = df.sort_values('Normalized Mean', ascending=False)\n",
    "    \n",
    "    print(f\"\\nNormalized Performance Results - Metric: {metric.upper()}\")\n",
    "    if task_filter:\n",
    "        print(f\"Task Filter: {task_filter}\")\n",
    "    print(f\"Model Filter: {model_filter}\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"Normalized Mean: Performance normalized to [0,1] across datasets\")\n",
    "    print(\"MRR: Mean Reciprocal Rank (higher is better)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Style the table\n",
    "    styled_df = df.style.hide(axis=\"index\").format({\n",
    "        'Normalized Mean': '{:.4f}',\n",
    "        'MRR': '{:.4f}',\n",
    "        'Datasets': '{:d}'\n",
    "    })\n",
    "    \n",
    "    display(styled_df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f41cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized Performance Results - Metric: F1\n",
      "Task Filter: binary\n",
      "Model Filter: teacher\n",
      "================================================================================\n",
      "Normalized Mean: Performance normalized to [0,1] across datasets\n",
      "MRR: Mean Reciprocal Rank (higher is better)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_81096\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_81096_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_81096_level0_col1\" class=\"col_heading level0 col1\" >Normalized Mean</th>\n",
       "      <th id=\"T_81096_level0_col2\" class=\"col_heading level0 col2\" >MRR</th>\n",
       "      <th id=\"T_81096_level0_col3\" class=\"col_heading level0 col3\" >Datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_81096_row0_col0\" class=\"data row0 col0\" >TabPFN</td>\n",
       "      <td id=\"T_81096_row0_col1\" class=\"data row0 col1\" >0.7133</td>\n",
       "      <td id=\"T_81096_row0_col2\" class=\"data row0 col2\" >0.5821</td>\n",
       "      <td id=\"T_81096_row0_col3\" class=\"data row0 col3\" >14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81096_row1_col0\" class=\"data row1 col0\" >TabM</td>\n",
       "      <td id=\"T_81096_row1_col1\" class=\"data row1 col1\" >0.7095</td>\n",
       "      <td id=\"T_81096_row1_col2\" class=\"data row1 col2\" >0.5048</td>\n",
       "      <td id=\"T_81096_row1_col3\" class=\"data row1 col3\" >14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81096_row2_col0\" class=\"data row2 col0\" >GRANDE</td>\n",
       "      <td id=\"T_81096_row2_col1\" class=\"data row2 col1\" >0.6250</td>\n",
       "      <td id=\"T_81096_row2_col2\" class=\"data row2 col2\" >0.3893</td>\n",
       "      <td id=\"T_81096_row2_col3\" class=\"data row2 col3\" >14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81096_row3_col0\" class=\"data row3 col0\" >RForest</td>\n",
       "      <td id=\"T_81096_row3_col1\" class=\"data row3 col1\" >0.5174</td>\n",
       "      <td id=\"T_81096_row3_col2\" class=\"data row3 col2\" >0.4298</td>\n",
       "      <td id=\"T_81096_row3_col3\" class=\"data row3 col3\" >14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81096_row4_col0\" class=\"data row4 col0\" >MLP</td>\n",
       "      <td id=\"T_81096_row4_col1\" class=\"data row4 col1\" >0.4246</td>\n",
       "      <td id=\"T_81096_row4_col2\" class=\"data row4 col2\" >0.2833</td>\n",
       "      <td id=\"T_81096_row4_col3\" class=\"data row4 col3\" >14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_81096_row5_col0\" class=\"data row5 col0\" >CatBoost</td>\n",
       "      <td id=\"T_81096_row5_col1\" class=\"data row5 col1\" >0.4180</td>\n",
       "      <td id=\"T_81096_row5_col2\" class=\"data row5 col2\" >0.2607</td>\n",
       "      <td id=\"T_81096_row5_col3\" class=\"data row5 col3\" >14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e48065e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = display_normalized_results(metric='f1', task_filter='binary', model_filter='teacher')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d60860",
   "metadata": {},
   "source": [
    "# Cumulative Performance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ec29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def calculate_best_model_frequencies(metric='f1', task_filter=None, model_filter='both'):\n",
    "    \"\"\"\n",
    "    Calculate how often each model performs best across datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    metric : str\n",
    "        The metric to evaluate (e.g., 'f1', 'acc', 'roc', 'mae', 'mse', 'rmse', 'r2')\n",
    "    task_filter : str or None\n",
    "        Filter by task type ('binary', 'regression', or None for all)\n",
    "    model_filter : str\n",
    "        Which models to include ('teacher', 'student', or 'both')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: Model names and their frequencies of being best\n",
    "    \"\"\"\n",
    "    all_results = load_all_results()\n",
    "    dataset_info = get_dataset_info()\n",
    "    \n",
    "    model_best_counts = {}\n",
    "    total_datasets = 0\n",
    "    \n",
    "    for dataset_id, models in all_results.items():\n",
    "        if dataset_id not in dataset_info:\n",
    "            continue\n",
    "            \n",
    "        # Filter by task type if specified\n",
    "        if task_filter and dataset_info[dataset_id]['task_type'] != task_filter:\n",
    "            continue\n",
    "        \n",
    "        # Filter models based on model_filter\n",
    "        filtered_models = {}\n",
    "        for model_name, result in models.items():\n",
    "            if model_filter == 'teacher' and not model_name.endswith('_teacher'):\n",
    "                continue\n",
    "            elif model_filter == 'student' and not model_name.endswith('_student'):\n",
    "                continue\n",
    "            elif model_filter == 'both':\n",
    "                pass  # Include all models\n",
    "            \n",
    "            mean_key = f\"mean_{metric}\"\n",
    "            if mean_key in result:\n",
    "                filtered_models[model_name] = result[mean_key]\n",
    "        \n",
    "        if not filtered_models:\n",
    "            continue\n",
    "            \n",
    "        # Find the best model for this dataset\n",
    "        # For metrics like mae, mse, rmse - lower is better\n",
    "        # For metrics like f1, acc, roc, r2 - higher is better\n",
    "        lower_is_better = metric.lower() in ['mae', 'mse', 'rmse', 'loss', 'inference_time']\n",
    "        \n",
    "        if lower_is_better:\n",
    "            best_model = min(filtered_models, key=filtered_models.get)\n",
    "        else:\n",
    "            best_model = max(filtered_models, key=filtered_models.get)\n",
    "        \n",
    "        # Count this best model\n",
    "        if best_model not in model_best_counts:\n",
    "            model_best_counts[best_model] = 0\n",
    "        model_best_counts[best_model] += 1\n",
    "        total_datasets += 1\n",
    "    \n",
    "    # Convert counts to frequencies\n",
    "    model_frequencies = {}\n",
    "    for model, count in model_best_counts.items():\n",
    "        model_frequencies[model] = count / total_datasets if total_datasets > 0 else 0\n",
    "    \n",
    "    return model_frequencies, total_datasets\n",
    "\n",
    "def prettify(key: str) -> str:\n",
    "    \"\"\"Convert `tabpfn_teacher` → `TabPFN (Teacher)`.\"\"\"\n",
    "    # 1) drop trailing \"_teacher\" / \"_student\" if present\n",
    "    base = key.rsplit('_', 1)[0] if key.endswith(('_teacher', '_student')) else key\n",
    "\n",
    "    # 2) explicit dictionary for the spellings you want\n",
    "    mapping = {\n",
    "        'tabpfn'      : 'TabPFN',\n",
    "        'tabm'        : 'TabM',\n",
    "        'grande'      : 'GRANDE',\n",
    "        'catboost'    : 'CatBoost',\n",
    "        'mlp'         : 'MLP',\n",
    "        'random_forest' : 'RForest',\n",
    "        # add more if needed\n",
    "    }\n",
    "\n",
    "    return mapping.get(base.lower(), base.replace('_', ' ').title())\n",
    "\n",
    "\n",
    "def plot_cumulative_optimal_achievements(metric='f1', task_filter=None, model_filter='both',\n",
    "                                         figsize=(14, 10), save_path=None):\n",
    "    \"\"\"\n",
    "    Create a cumulative bar plot showing the percentage of optimal achievements for each model.\n",
    "    Models are sorted by performance, and bars are stacked horizontally on different y-levels.\n",
    "    Includes all participating models, even those with zero optimal achievements.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    metric : str\n",
    "        The metric to evaluate (e.g., 'f1', 'acc', 'roc', 'mae', 'mse', 'rmse', 'r2').\n",
    "    task_filter : str or None\n",
    "        Filter by task type ('binary', 'regression', or None for all).\n",
    "    model_filter : str\n",
    "        Which models to include ('teacher', 'student', or 'both').\n",
    "    figsize : tuple\n",
    "        Figure size (width, height).\n",
    "    save_path : str or None\n",
    "        Path to save the plot (if None, just display).\n",
    "    \"\"\"\n",
    "    # 1. Get win frequencies for models that were best\n",
    "    win_frequencies, total_datasets = calculate_best_model_frequencies(\n",
    "        metric, task_filter, model_filter\n",
    "    )\n",
    "\n",
    "    if total_datasets == 0:\n",
    "        print(f\"No datasets analyzed for metric '{metric}' with filters: task='{task_filter}', model='{model_filter}'. Cannot generate plot.\")\n",
    "        # Still, we might want to show models with 0% if they exist.\n",
    "        # Let's proceed to find all participating models.\n",
    "\n",
    "    # 2. Get all models that participated under the given filters and had the metric\n",
    "    all_participating_models = set()\n",
    "    raw_results = load_all_results()\n",
    "    dataset_details = get_dataset_info()\n",
    "\n",
    "    for dataset_id, model_results_for_dataset in raw_results.items():\n",
    "        dataset_task_type = dataset_details.get(dataset_id, {}).get('task_type')\n",
    "        if task_filter and dataset_task_type != task_filter:\n",
    "            continue\n",
    "\n",
    "        for model_key, result_data in model_results_for_dataset.items():\n",
    "            # Apply model filter\n",
    "            if model_filter == 'teacher' and not model_key.endswith('_teacher'):\n",
    "                continue\n",
    "            if model_filter == 'student' and not model_key.endswith('_student'):\n",
    "                continue\n",
    "            \n",
    "            # Check if this model has the required metric\n",
    "            mean_key = f\"mean_{metric}\"\n",
    "            if mean_key in result_data:\n",
    "                 all_participating_models.add(model_key)\n",
    "\n",
    "    if not all_participating_models:\n",
    "        print(f\"No participating models found for metric '{metric}' with filters: task='{task_filter}', model='{model_filter}'.\")\n",
    "        return\n",
    "\n",
    "    # 3. Combine win frequencies with all participating models (defaulting to 0 if never won)\n",
    "    plot_data = {}\n",
    "    for model_name in all_participating_models:\n",
    "        plot_data[model_name] = win_frequencies.get(model_name, 0.0)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2.  Prepare the plotting data  (unchanged)\n",
    "    # ------------------------------------------------------------------\n",
    "    sorted_models_by_freq = sorted(plot_data.items(),\n",
    "                                   key=lambda x: x[1], reverse=True)\n",
    "    model_names            = [m for m, _ in sorted_models_by_freq]\n",
    "    pretty_names = [prettify(n) for n in model_names]\n",
    "    individual_frequencies = np.array([f for _, f in sorted_models_by_freq])\n",
    "\n",
    "    cumulative_offset          = 0.0\n",
    "    bar_left_positions         = []\n",
    "    actual_bar_widths_percent  = []\n",
    "\n",
    "    for freq in individual_frequencies:\n",
    "        pct = freq * 100\n",
    "        bar_left_positions.append(cumulative_offset)\n",
    "        actual_bar_widths_percent.append(pct)\n",
    "        cumulative_offset += pct\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3.  Plot with SciencePlots (science + ieee + no-latex)\n",
    "    # ------------------------------------------------------------------\n",
    "    with plt.style.context(['science',      # base look & feel\n",
    "                            'ieee',         # fonts / sizes for IEEE papers\n",
    "                            'no-latex']):   # disable TeX rendering\n",
    "\n",
    "        # optional: override the very small ieee default dpi\n",
    "        plt.rcParams.update({'figure.dpi': 150})\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4.5,2.5))\n",
    "\n",
    "        renderer   = fig.canvas.get_renderer()        # for pixel math\n",
    "        bbox       = ax.get_window_extent(renderer)\n",
    "        axis_width = bbox.width\n",
    "\n",
    "        color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "        for i, (pretty, width_val, left_pos) in enumerate(\n",
    "                zip(pretty_names, actual_bar_widths_percent, bar_left_positions)):\n",
    "            ax.barh(pretty, width_val, left=left_pos,\n",
    "                    # height=0.9,\n",
    "                    color=color_cycle[i % len(color_cycle)],\n",
    "                    edgecolor='black', alpha=0.85)\n",
    "            \n",
    "            width_px = (width_val / ax.get_xlim()[1]) * axis_width\n",
    "            if width_px > 40:                         # threshold; tweak as you like\n",
    "                ax.text(left_pos + width_val / 2, pretty,\n",
    "                        f'{width_val:.2f}%', ha='center', va='center',\n",
    "                        color='white' if width_val > 5 else 'black')\n",
    "\n",
    "        # styling\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel('Optimal Achievement Rate (%)', fontsize=12)\n",
    "        ax.set_ylabel('Method', fontsize=12)\n",
    "        ax.set_xlim(0, max(100.0, cumulative_offset * 1.05))\n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x)}'))\n",
    "        ax.xaxis.grid(True, linestyle='--', alpha=0.5)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_path:\n",
    "            # Ensure the directory exists\n",
    "            save_path = os.path.join(save_path, f'cumulative_optimal_achievements_{metric}_{task_filter or \"all\"}_{model_filter}.pdf')\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            # Save the figure\n",
    "            fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f'Plot saved to: {save_path}')\n",
    "\n",
    "        plt.show() \n",
    "\n",
    "    # Optional: Print summary\n",
    "    print(f\"\\nSummary for {metric.upper()} ({task_filter if task_filter else 'all'} tasks, {model_filter} models):\")\n",
    "    print(f\"Total datasets analyzed: {total_datasets}\")\n",
    "    print(\"\\nModel Contributions to Optimal Achievements:\")\n",
    "    current_sum_print = 0\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        ind_freq_perc = individual_frequencies[i] * 100\n",
    "        current_sum_print += ind_freq_perc\n",
    "        print(f\"{i+1:2d}. {model_name:<40s}: {ind_freq_perc:>6.2f}% (Cumulative: {current_sum_print:>6.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57040ca7",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'science' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/matplotlib/style/core.py:137\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/matplotlib/__init__.py:873\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[0;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[1;32m    872\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 873\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_or_url(fname) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/matplotlib/__init__.py:850\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    849\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[0;32m--> 850\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'science'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example 1: Cumulative F1 score for binary classification (both teacher and student models)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplot_cumulative_optimal_achievements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minference_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mteacher\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs/outputs.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 177\u001b[0m, in \u001b[0;36mplot_cumulative_optimal_achievements\u001b[0;34m(metric, task_filter, model_filter, figsize, save_path)\u001b[0m\n\u001b[1;32m    172\u001b[0m     cumulative_offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pct\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# 3.  Plot with SciencePlots (science + ieee + no-latex)\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mcontext([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscience\u001b[39m\u001b[38;5;124m'\u001b[39m,      \u001b[38;5;66;03m# base look & feel\u001b[39;00m\n\u001b[1;32m    178\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mieee\u001b[39m\u001b[38;5;124m'\u001b[39m,         \u001b[38;5;66;03m# fonts / sizes for IEEE papers\u001b[39;00m\n\u001b[1;32m    179\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno-latex\u001b[39m\u001b[38;5;124m'\u001b[39m]):   \u001b[38;5;66;03m# disable TeX rendering\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# optional: override the very small ieee default dpi\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     plt\u001b[38;5;241m.\u001b[39mrcParams\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.dpi\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m150\u001b[39m})\n\u001b[1;32m    184\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4.5\u001b[39m,\u001b[38;5;241m2.5\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/matplotlib/style/core.py:194\u001b[0m, in \u001b[0;36mcontext\u001b[0;34m(style, after_reset)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m after_reset:\n\u001b[1;32m    193\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mrcdefaults()\n\u001b[0;32m--> 194\u001b[0m \u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/matplotlib/style/core.py:139\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    137\u001b[0m         style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid package style, path of style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, URL of style file, or library style name (library \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyles are listed in `style.available`)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    143\u001b[0m filtered \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: 'science' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "# Example 1: Cumulative F1 score for binary classification (both teacher and student models)\n",
    "plot_cumulative_optimal_achievements(metric='inference_time', task_filter='binary', model_filter='teacher', save_path='outputs/outputs.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
