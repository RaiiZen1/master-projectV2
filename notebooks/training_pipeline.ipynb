{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e297aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to: /work/mherre/master-projectV3/master-projectV2/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "if not current_dir.endswith('notebooks'):\n",
    "    os.chdir('notebooks')\n",
    "    print(f\"Changed working directory to: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Already in notebooks directory: {current_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681be5eb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eaf3d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 13:45:49.175903: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-20 13:45:49.910757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mherre/.local/lib/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "/home/mherre/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, accuracy_score, f1_score, roc_auc_score,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, OneHotEncoder, LabelEncoder, TargetEncoder\n",
    ")\n",
    "\n",
    "# Deep learning imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model-specific imports\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "from GRANDE import GRANDE\n",
    "from packages.tabm_reference import Model, make_parameter_groups\n",
    "\n",
    "# Optimization imports\n",
    "import optuna\n",
    "\n",
    "# Data source imports\n",
    "import openml\n",
    "\n",
    "# Abstract base class imports\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Literal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae3463",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf7565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"\n",
    "    Set random seeds for reproducibility across Python, NumPy, PyTorch, and TensorFlow.\n",
    "\n",
    "    Args:\n",
    "        seed: Integer seed for random number generators\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "def setup_logging() -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Set up logging configuration.\n",
    "    This function configures the logging settings for the application, including\n",
    "    the logging level and format. It returns a logger instance that can be used\n",
    "    throughout the application.\n",
    "    Returns:\n",
    "        logging.Logger: Configured logger instance.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def check_GPU_availability():\n",
    "    \"\"\"\n",
    "    Checks if a GPU is available and configures TensorFlow to use it appropriately.\n",
    "\n",
    "    Sets up memory growth for TensorFlow GPU usage to avoid allocating all GPU memory at once.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: A torch device object ('cuda' if GPU is available, 'cpu' otherwise)\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "    if torch.cuda.is_available():\n",
    "        logger.info(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "        device = torch.device(\"cuda\")\n",
    "        gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        logger.info(\"Using CPU for training.\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14164da",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3635ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_target(y):\n",
    "    \"\"\"\n",
    "    Encode the target variable using LabelEncoder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array\n",
    "        The target variable to encode.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_encoded : np.array\n",
    "        The encoded target variable.\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    return y_encoded\n",
    "\n",
    "\n",
    "def preprocess(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_val: pd.DataFrame,\n",
    "    cat_cols: list,\n",
    "    config: dict,\n",
    "    preprocessing_type: str,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Preprocess the training and validation datasets based on the specified model type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pandas.DataFrame\n",
    "        The training dataset features.\n",
    "    y_train : pandas.Series or np.array\n",
    "        The target variable for the training dataset.\n",
    "    X_val : pandas.DataFrame\n",
    "        The validation dataset features.\n",
    "    cat_cols : list or array of bool\n",
    "        Boolean mask indicating which columns in X_train and X_val are categorical (True).\n",
    "    config : dict\n",
    "        Configuration dictionary containing model and preprocessing details.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : np.array\n",
    "        The preprocessed training dataset features.\n",
    "    X_val : np.array\n",
    "        The preprocessed validation dataset features.\n",
    "    \"\"\"\n",
    "    X_train, preprocessor_inner = _minimal_preprocess_train(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cat_cols,\n",
    "        preprocessing_type,\n",
    "        config,\n",
    "    )\n",
    "    X_val = _minimal_preprocess_test(X_val, preprocessor_inner)\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "\n",
    "def _minimal_preprocess_train(X, y, categorical_features, model_type, config):\n",
    "    \"\"\"\n",
    "    Perform minimal preprocessing on the input features for training.\n",
    "\n",
    "    This function applies preprocessing to both numeric and categorical features\n",
    "    based on the model type specified in the configuration. For Neural Networks,\n",
    "    it standardizes numeric features and one-hot encodes categorical features. For\n",
    "    tree-based models, it does not scale numeric features and applies different\n",
    "    encoding strategies for low- and high-cardinality categorical features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pandas.DataFrame\n",
    "        The input features.\n",
    "\n",
    "    categorical_features : list or array of bool\n",
    "        Boolean mask indicating which columns in X are categorical (True) and\n",
    "        which are numeric (False).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_preprocessed : np.array\n",
    "        The preprocessed features.\n",
    "    preprocessor : ColumnTransformer\n",
    "        The fitted preprocessor, which can be used to transform future datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the boolean mask to a NumPy array (if not already) for fast indexing.\n",
    "    cat_mask = np.asarray(categorical_features)\n",
    "\n",
    "    # Check that the mask length matches the number of columns in X.\n",
    "    if cat_mask.shape[0] != X.shape[1]:\n",
    "        raise ValueError(\n",
    "            \"Length of categorical_features mask must match the number of columns in X.\"\n",
    "        )\n",
    "\n",
    "    # Extract column names using boolean indexing.\n",
    "    categorical_feature_names = X.columns[cat_mask].tolist()\n",
    "    numeric_feature_names = X.columns[~cat_mask].tolist()\n",
    "\n",
    "    # Select pipeline based on config.\n",
    "    logger = setup_logging()\n",
    "\n",
    "    # Neural Networks: standardize numeric features and one-hot encode categoricals.\n",
    "    if model_type == \"nn\":\n",
    "\n",
    "        # Define the preprocessing pipeline for numeric features.\n",
    "        numeric_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Define the preprocessing pipeline for categorical features.\n",
    "        categorical_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\n",
    "                    \"onehot\",\n",
    "                    OneHotEncoder(\n",
    "                        drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        transformers = [\n",
    "            (\"num\", numeric_pipeline, numeric_feature_names),\n",
    "            (\"cat\", categorical_pipeline, categorical_feature_names),\n",
    "        ]\n",
    "\n",
    "        logger.info(\"Preprocessing pipeline for Neural Network model.\")\n",
    "\n",
    "    elif model_type == \"tree\":\n",
    "\n",
    "        # Tree-based models: leave numeric features unscaled, and differentiate encoding for categoricals.\n",
    "        numeric_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            ]\n",
    "        )\n",
    "        # Split categorical features into low- and high-cardinality groups.\n",
    "        threshold = config[\"preprocessing\"][\"threshold_high_cardinality\"]\n",
    "        low_card_features = []\n",
    "        high_card_features = []\n",
    "        for feature in categorical_feature_names:\n",
    "            if X[feature].nunique() <= threshold:\n",
    "                low_card_features.append(feature)\n",
    "            else:\n",
    "                high_card_features.append(feature)\n",
    "\n",
    "        # For low-cardinality categoricals, use one-hot encoding.\n",
    "        low_card_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\n",
    "                    \"onehot\",\n",
    "                    OneHotEncoder(\n",
    "                        drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # For high-cardinality categoricals, use target encoding.\n",
    "        high_card_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"target_encode\", TargetEncoder()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        transformers = [\n",
    "            (\"num\", numeric_pipeline, numeric_feature_names),\n",
    "            (\"low_card\", low_card_pipeline, low_card_features),\n",
    "            (\"high_card\", high_card_pipeline, high_card_features),\n",
    "        ]\n",
    "\n",
    "        logger.info(\"Preprocessing pipeline for Decision Tree model.\")\n",
    "\n",
    "    elif model_type == \"grande\":\n",
    "        logger.info(\"No preprocessing required for Grande model.\")\n",
    "        return X, None\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unknown teacher type. Must be 'nn' for Neural Network, 'tree' for Decision Tree, or 'grande' for Gradient Based Tree.\"\n",
    "        )\n",
    "\n",
    "    # Create a ColumnTransformer to apply the transformations to the appropriate columns.\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=transformers,\n",
    "        n_jobs=-2,\n",
    "    )\n",
    "\n",
    "    # Fit the preprocessor on the training data and transform it.\n",
    "    X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "\n",
    "    return X_preprocessed, preprocessor\n",
    "\n",
    "\n",
    "def _minimal_preprocess_test(X, preprocessor):\n",
    "    \"\"\"\n",
    "    Transform the input features according to the preprocessor fitted on the training data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pandas.DataFrame\n",
    "        The input features.\n",
    "    preprocessor : ColumnTransformer\n",
    "        The preprocessor fitted on the training data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_preprocessed : np.array\n",
    "        The preprocessed features.\n",
    "    \"\"\"\n",
    "    if preprocessor is None:\n",
    "        return X\n",
    "    return preprocessor.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d700d2",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f642a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_id: int, config: dict):\n",
    "    \"\"\"\n",
    "    Loads an OpenML dataset based on its ID and processes it according to the task type.\n",
    "\n",
    "    This function fetches the dataset using the _fetch_dataset helper, then processes\n",
    "    the target variable based on whether the task is binary classification or regression.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_id (int): The ID of the dataset on OpenML.\n",
    "        config (dict): Configuration dictionary containing data paths and settings.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - X: The feature data (pandas DataFrame)\n",
    "            - y: The processed target variable (encoded for binary classification or numpy array for regression)\n",
    "            - cat_cols: List of booleans indicating which features are categorical\n",
    "            - attribute_names: List of attribute names\n",
    "            - task_type: String indicating the task type ('binary' or 'regression')\n",
    "    \"\"\"\n",
    "    X, y, cat_cols, attribute_names, task_type = fetch_dataset(\n",
    "        dataset_id=dataset_id,\n",
    "        cache_dir=config[\"data\"][\"cache_dir_path\"],\n",
    "    )\n",
    "    if task_type == \"binary\":\n",
    "        # Encode the target variable if it's binary\n",
    "        y = encode_target(y)\n",
    "    else:\n",
    "        # Transform to np.array for regression\n",
    "        y = np.array(y, dtype=float)\n",
    "\n",
    "    return X, y, cat_cols, attribute_names, task_type\n",
    "\n",
    "\n",
    "def fetch_dataset(dataset_id: int, cache_dir: str = \"data/cache/\"):\n",
    "    \"\"\"\n",
    "    Downloads an OpenML dataset based on its id, caches the data locally, and returns the data\n",
    "    along with its metadata.\n",
    "\n",
    "    The five returned objects are:\n",
    "        - X: The feature data (typically a pandas DataFrame).\n",
    "        - y: The target variable.\n",
    "        - categorical_indicator: A list of booleans indicating which features are categorical.\n",
    "        - attribute_names: A list of attribute names.\n",
    "        - task_type: A string indicating the type of task ('binary' or 'regression').\n",
    "\n",
    "    If the dataset has been previously downloaded and stored in the cache directory,\n",
    "    it will be loaded from the local file instead of re-downloading.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_id (int): The id of the dataset on OpenML.\n",
    "        cache_dir (str): The directory to store the downloaded dataset. Defaults to \"openml_cache\".\n",
    "\n",
    "    Returns:\n",
    "        X, y, categorical_indicator, attribute_names, task_type\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "\n",
    "    # Ensure the cache directory exists\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    # Define a cache file name that is unique to the dataset id\n",
    "    cache_file = os.path.join(cache_dir, f\"openml_dataset_{dataset_id}.pkl\")\n",
    "\n",
    "    # If the cache file exists, load the data from the file.\n",
    "    if os.path.exists(cache_file):\n",
    "        logger.info(\n",
    "            f\"Loading dataset {dataset_id} from cache at '{cache_file}'...\"\n",
    "        )\n",
    "        with open(cache_file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        X = data[\"X\"]\n",
    "        y = data[\"y\"]\n",
    "        categorical_indicator = data[\"categorical_indicator\"]\n",
    "        attribute_names = data[\"attribute_names\"]\n",
    "        task_type = data[\"task_type\"]\n",
    "    else:\n",
    "        # Download the dataset from OpenML.\n",
    "        logger.info(f\"Downloading dataset {dataset_id} from OpenML...\")\n",
    "        dataset = openml.datasets.get_dataset(dataset_id)\n",
    "\n",
    "        # Use the default target attribute (if defined) when retrieving the data.\n",
    "        X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            target=dataset.default_target_attribute, dataset_format=\"dataframe\"\n",
    "        )\n",
    "\n",
    "        # Determine the task type (binary classification or regression)\n",
    "        task_type = _determine_task_type(y)\n",
    "\n",
    "        # Store the data and metadata in a dictionary.\n",
    "        data = {\n",
    "            \"X\": X,\n",
    "            \"y\": y,\n",
    "            \"categorical_indicator\": categorical_indicator,\n",
    "            \"attribute_names\": attribute_names,\n",
    "            \"task_type\": task_type,\n",
    "        }\n",
    "\n",
    "        # Save the dictionary to a local file using pickle.\n",
    "        with open(cache_file, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "        logger.info(f\"Dataset {dataset_id} stored locally at '{cache_file}'.\")\n",
    "\n",
    "    logger.info(f\"Dataset {dataset_id} loaded successfully with task type: {task_type}\")\n",
    "\n",
    "    return X, y, categorical_indicator, attribute_names, task_type\n",
    "\n",
    "\n",
    "def _determine_task_type(y):\n",
    "    \"\"\"\n",
    "    Determines if the target variable is for binary classification, or regression.\n",
    "\n",
    "    Parameters:\n",
    "        y: The target variable (pandas dataframe).\n",
    "\n",
    "    Returns:\n",
    "        str: 'binary', or 'regression'\n",
    "    \"\"\"\n",
    "\n",
    "    # Get unique values\n",
    "    unique_values = pd.unique(y)\n",
    "\n",
    "    # Check if it's binary (2 unique values)\n",
    "    if len(unique_values) == 2:\n",
    "        return \"binary\"\n",
    "    else:\n",
    "        return \"regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4579812",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7681de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_prob, y_true):\n",
    "    \"\"\"\n",
    "    Evaluate classification performance using balanced accuracy, F1 score, and ROC AUC.\n",
    "\n",
    "    Parameters:\n",
    "        y_prob (np.array): Predicted probabilities for the positive class.\n",
    "        y_true (np.array): True labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "    y_pred = (y_prob[:, 1] > 0.5).astype(int)\n",
    "    acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    roc_auc = roc_auc_score(y_true, y_prob[:, 1])\n",
    "\n",
    "    logger.info(f\"\\t Balanced Accuracy: {acc:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"roc\": roc_auc,\n",
    "    }\n",
    "\n",
    "def evaluate_regression(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Evaluate regression performance using R^2 score.\n",
    "\n",
    "    Parameters:\n",
    "        y_pred (np.array): Predicted values.\n",
    "        y_true (np.array): True values.\n",
    "\n",
    "    Returns:\n",
    "        float: R^2 score.\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    logger.info(f\"\\t MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"mae\": mae,\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse,\n",
    "        \"r2\": r2,\n",
    "    }\n",
    "\n",
    "def evaluate_fidelity_classification(y_prob_student, y_prob_teacher):\n",
    "    \"\"\"\n",
    "    Evaluate the fidelity of a student model compared to a teacher model in classification tasks.\n",
    "\n",
    "    Parameters:\n",
    "        y_prob_teacher (np.array): Predicted probabilities from the teacher model.\n",
    "        y_prob_student (np.array): Predicted probabilities from the student model.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics for fidelity.\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "\n",
    "    y_pred_student = (y_prob_student[:, 1] > 0.5).astype(int)\n",
    "\n",
    "    if y_prob_teacher.ndim == 2:\n",
    "        y_pred_teacher = (y_prob_teacher[:, 1] > 0.5).astype(int)\n",
    "        kl_div = kl_divergence_soft(y_prob_student[:, 1], y_prob_teacher[:, 1])\n",
    "\n",
    "    elif y_prob_teacher.ndim == 1:\n",
    "        y_pred_teacher = y_prob_teacher.astype(int)\n",
    "        kl_div = kl_divergence_hard(y_prob_student[:, 1], y_pred_teacher)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"y_prob_teacher has unexpected shape: {y_prob_teacher.shape}\"\n",
    "        )\n",
    "    \n",
    "    acc = balanced_accuracy_score(y_pred_teacher, y_pred_student)\n",
    "    f1 = f1_score(y_pred_teacher, y_pred_student, average=\"macro\")\n",
    "    roc_auc = roc_auc_score(y_pred_teacher, y_prob_student[:, 1])\n",
    "\n",
    "    logger.info(f\"\\t Fidelity - Balanced Accuracy: {acc:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}, KL Divergence: {kl_div:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"fidelity_acc\": acc,\n",
    "        \"fidelity_f1\": f1,\n",
    "        \"fidelity_roc\": roc_auc,\n",
    "        \"fidelity_kl_div\": kl_div,\n",
    "    }\n",
    "\n",
    "def evaluate_fidelity_regression(y_pred_student, y_pred_teacher):\n",
    "    \"\"\"\n",
    "    Evaluate the fidelity of a student model compared to a teacher model in regression tasks.\n",
    "\n",
    "    Parameters:\n",
    "        y_pred_teacher (np.array): Predicted values from the teacher model.\n",
    "        y_pred_student (np.array): Predicted values from the student model.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics for fidelity.\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "\n",
    "    mae = mean_absolute_error(y_pred_teacher, y_pred_student)\n",
    "    mse = mean_squared_error(y_pred_teacher, y_pred_student)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_pred_teacher, y_pred_student)\n",
    "\n",
    "    logger.info(f\"\\t Fidelity - MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"fidelity_mae\": mae,\n",
    "        \"fidelity_mse\": mse,\n",
    "        \"fidelity_rmse\": rmse,\n",
    "        \"fidelity_r2\": r2,\n",
    "    }\n",
    "\n",
    "def kl_divergence_hard(probs_pos, y_true):\n",
    "    eps = 1e-7  \n",
    "    probs_pos = np.clip(probs_pos, eps, 1 - eps)\n",
    "    \n",
    "    log_likelihood = y_true * np.log(probs_pos) + (1 - y_true) * np.log(1 - probs_pos)\n",
    "    result = -np.mean(log_likelihood)\n",
    "    \n",
    "    return result if not np.isnan(result) else 0.0\n",
    "\n",
    "def kl_divergence_soft(p, q):\n",
    "    eps = 1e-7\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "    q = np.clip(q, eps, 1 - eps)\n",
    "    return np.mean(p * np.log(p / q) + (1 - p) * np.log((1 - p) / (1 - q)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8af1a5",
   "metadata": {},
   "source": [
    "# Model Factory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb36799",
   "metadata": {},
   "source": [
    "## Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9825c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherModelBase(ABC):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.params = kwargs\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Trains the model on the given data.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.ndarray): The input features with shape (n_samples, n_features).\n",
    "            y (np.ndarray): The target labels with shape (n_samples,).\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Makes predictions on the provided data.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.ndarray): The input features with shape (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: An array of predicted probabilities with shape (n_samples, n_classes).\n",
    "                        (If the model returns logits, these should be post-processed to probabilities.)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, y_pred: np.ndarray, y_true: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluates the model's predictions against the true labels.\n",
    "\n",
    "        Parameters:\n",
    "            y_pred (np.ndarray): The predicted probabilities or values.\n",
    "            y_true (np.ndarray): The true labels.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: A dictionary containing evaluation metrics.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            metrics = evaluate_classification(y_pred, y_true)\n",
    "            metrics['parameters'] = self.count_parameters()\n",
    "            return metrics\n",
    "        \n",
    "        elif self.task_type == \"regression\":\n",
    "            metrics = evaluate_regression(y_pred, y_true)\n",
    "            metrics['parameters'] = self.count_parameters()\n",
    "            return metrics\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task type: {self.task_type}. Must be 'binary' or 'regression'.\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def count_parameters(self) -> int:\n",
    "        \"\"\"\n",
    "        Counts the number of trainable parameters in the model.\n",
    "\n",
    "        Returns:\n",
    "            int: The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class TabPFNTeacherModel(TeacherModelBase):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a TabPFN teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base\n",
    "            class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y, **training_params):\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model = TabPFNClassifier()\n",
    "        else:\n",
    "            self.model = TabPFNRegressor()\n",
    "        # If X is bigger than 10000 samples, reduce data size to 10000\n",
    "        if X.shape[0] > 10000:\n",
    "            X = X[:10000]\n",
    "            y = y[:10000]\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "\n",
    "    def count_parameters(self) -> int:\n",
    "        \"\"\"\n",
    "        Counts the number of trainable parameters in the underlying TabPFN model.\n",
    "\n",
    "        Returns:\n",
    "            int: Total number of trainable parameters.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the TabPFN model has not been fitted yet.\n",
    "        \"\"\"\n",
    "        if not hasattr(self.model, \"model_\"):\n",
    "            raise ValueError(\n",
    "                \"The TabPFN model is not fitted yet. Please call fit() first.\"\n",
    "            )\n",
    "        return sum(p.numel() for p in self.model.model_.parameters() if p.requires_grad)\n",
    "    \n",
    "\n",
    "class CatBoostTeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a CatBoost teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the CatBoost model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the CatBoost model's fit method.\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        # Initialize the CatBoost model\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model = CatBoostClassifier(\n",
    "                random_seed=random_state,\n",
    "                thread_count=-1,  # Use all available CPU cores\n",
    "                logging_level=\"Silent\",  # Suppress CatBoost output\n",
    "                task_type=(\"GPU\" if str(self.device).lower() == \"cuda\" else \"CPU\"),\n",
    "                **self.hyperparams,  # Include the sampled hyperparameters\n",
    "            )\n",
    "        else:\n",
    "            self.model = CatBoostRegressor(\n",
    "                random_seed=random_state,\n",
    "                thread_count=-1,  # Use all available CPU cores\n",
    "                logging_level=\"Silent\",  # Suppress CatBoost output\n",
    "                task_type=(\"GPU\" if str(self.device).lower() == \"cuda\" else \"CPU\"),\n",
    "                **self.hyperparams,  # Include the sampled hyperparameters\n",
    "            )\n",
    "\n",
    "        # Split data into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        # Train the model\n",
    "        self.model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=(X_val, y_val),\n",
    "            early_stopping_rounds=20, \n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples, n_classes)\n",
    "            The predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of parameters in the trained CatBoost model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of parameters in the model.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\") or self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet.\")\n",
    "\n",
    "        # Get the number of trees in the model\n",
    "        tree_count = self.model.tree_count_\n",
    "\n",
    "        # For each tree, count:\n",
    "        # - split values (one per non-leaf node)\n",
    "        # - leaf values (one per leaf node)\n",
    "        # - feature indices (one per non-leaf node)\n",
    "        # For a binary tree with depth d, there are 2^d - 1 non-leaf nodes and 2^d leaf nodes\n",
    "        # This is a simplified approximation\n",
    "        approx_depth = self.hyperparams.get(\"max_depth\", 6)  # Default depth in CatBoost is 6\n",
    "        non_leaf_nodes = 2**approx_depth - 1\n",
    "        leaf_nodes = 2**approx_depth\n",
    "\n",
    "        # Total parameters per tree\n",
    "        params_per_tree = (\n",
    "            non_leaf_nodes * 2 + leaf_nodes\n",
    "        )  # split values + feature indices + leaf values\n",
    "        return tree_count * params_per_tree\n",
    "    \n",
    "\n",
    "class GRANDETeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a GRANDE teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments. The `device` parameter is popped from kwargs and\n",
    "            defaults to 'cpu' if not provided.\n",
    "        \"\"\"\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "        os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        self.cat_cols = kwargs.pop(\"cat_cols\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the GRANDE teacher model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the GRANDE model's fit method.\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        # Determine categorical indices\n",
    "        cat_indices = [i for i, is_cat in enumerate(self.cat_cols) if is_cat]\n",
    "\n",
    "        training_params = {\n",
    "            \"epochs\": 1000,\n",
    "            \"early_stopping_epochs\": 25,\n",
    "            \"batch_size\": 64,\n",
    "            \"cat_idx\": cat_indices,\n",
    "            \"random_seed\": random_state,\n",
    "        }\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            training_params[\"objective\"] = \"binary\"\n",
    "        else:\n",
    "            training_params[\"objective\"] = \"regression\"\n",
    "\n",
    "        # Instantiate the GRANDE teacher model.\n",
    "        self.model = GRANDE(params=self.hyperparams, args=training_params)\n",
    "\n",
    "        # Split the data into training and validation sets.\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        self.model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given input data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like\n",
    "            The predicted target values.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict(X)\n",
    "        else:\n",
    "            return self.model.predict(X).squeeze()\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the GRANDE teacher model based on the\n",
    "        dense representation of a single tree and the number of trees in the ensemble.\n",
    "\n",
    "        The number of parameters for a single tree is computed as:\n",
    "            leaf parameters: 2^d\n",
    "            split thresholds: (2^d - 1) * n\n",
    "            feature selection (one-hot): (2^d - 1) * n\n",
    "        so that:\n",
    "            params_per_tree = 2^d + 2 * n * (2^d - 1)\n",
    "        The total is then:\n",
    "            total_params = n_estimators * params_per_tree\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained/initialized yet.\")\n",
    "\n",
    "        # These attributes must be set when the GRANDE model is instantiated.\n",
    "        # Adjust the attribute names if they are different in your GRANDE implementation.\n",
    "        d = self.model.depth  # Depth of each decision tree.\n",
    "        n = self.model.number_of_variables  # Number of features used in the tree.\n",
    "        E = self.model.n_estimators  # Number of trees in the ensemble.\n",
    "\n",
    "        # Calculate the number of parameters for one tree.\n",
    "        params_per_tree = (2**d) + 2 * n * ((2**d) - 1)\n",
    "        total_params = E * params_per_tree\n",
    "\n",
    "        return total_params\n",
    "    \n",
    "class TabMTeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a TabM teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Set up AMP if CUDA is available.\n",
    "        if torch.cuda.is_available():\n",
    "            self.amp_dtype = (\n",
    "                torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "            )\n",
    "            self.amp_enabled = True\n",
    "        else:\n",
    "            self.amp_dtype = None\n",
    "            self.amp_enabled = False\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the TabM model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the TabM model's fit method.\n",
    "        \"\"\"\n",
    "        # Get parameters\n",
    "        n_blocks = self.hyperparams.get(\"n_blocks\")\n",
    "        d_block = self.hyperparams.get(\"d_block\")\n",
    "        dropout = self.hyperparams.get(\"dropout\")\n",
    "        lr = self.hyperparams.get(\"learning_rate\")\n",
    "        weight_decay = self.hyperparams.get(\"weight_decay\")\n",
    "\n",
    "        # Set model architecture\n",
    "        arch_type = \"tabm\"\n",
    "        bins = None\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            n_classes = len(np.unique(y))\n",
    "            self.n_classes = n_classes\n",
    "            cat_idx = []  # Assumes all features are continuous\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=cat_idx,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=32,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        else:\n",
    "            if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "                # Multiclass logits\n",
    "                n_outputs = y.shape[1]\n",
    "            else:\n",
    "                # Binary or single-output regression\n",
    "                n_outputs = 1\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=[],  # Assumes all features are continuous\n",
    "                n_classes=n_outputs,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=32,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            make_parameter_groups(self.model), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        self.evaluation_mode = torch.no_grad if compile_model else torch.inference_mode\n",
    "\n",
    "        # Prepare data\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        if self.task_type == \"binary\":\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long, device=self.device)\n",
    "        else:\n",
    "            y_tensor = torch.tensor(y, dtype=torch.float32, device=self.device)\n",
    "        n_samples = X_tensor.size(0)\n",
    "        indices = torch.randperm(n_samples)\n",
    "        train_end = int(0.8 * n_samples)\n",
    "        train_idx, val_idx = indices[:train_end], indices[train_end:]\n",
    "        self.data = {\n",
    "            \"train\": {\"x_cont\": X_tensor[train_idx], \"y\": y_tensor[train_idx]},\n",
    "            \"val\": {\"x_cont\": X_tensor[val_idx], \"y\": y_tensor[val_idx]},\n",
    "        }\n",
    "        Y_train = self.data[\"train\"][\"y\"]\n",
    "\n",
    "        # Training parameters\n",
    "        n_epochs = 100000\n",
    "        patience = 16\n",
    "        batch_size = 256\n",
    "        train_size = len(Y_train)\n",
    "        best = {\"val\": -float(\"inf\"), \"epoch\": -1}\n",
    "        remaining_patience = patience\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            batches = torch.randperm(train_size, device=self.device).split(batch_size)\n",
    "            for batch_idx in batches:\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_fn(\n",
    "                    self.apply_model(\"train\", batch_idx), Y_train[batch_idx]\n",
    "                )\n",
    "                if self.amp_enabled and self.amp_dtype == torch.float16:\n",
    "                    scaler = torch.cuda.amp.GradScaler()\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            val_score = self.evaluate_tabm(\"val\")\n",
    "            if val_score > best[\"val\"]:\n",
    "                best = {\"val\": val_score, \"epoch\": epoch}\n",
    "                remaining_patience = patience\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "\n",
    "    def apply_model(self, part: str, idx: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply the model to a batch of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "        idx : torch.Tensor\n",
    "            The indices of the samples to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The model output.\n",
    "        \"\"\"\n",
    "        with torch.autocast(\n",
    "            self.device.type, enabled=self.amp_enabled, dtype=self.amp_dtype\n",
    "        ):\n",
    "            x_cont = self.data[part][\"x_cont\"][idx]\n",
    "            x_cat = self.data[part].get(\"x_cat\")\n",
    "            if self.task_type == \"binary\":\n",
    "                return self.model(x_cont, x_cat).float()\n",
    "            else:\n",
    "                return (\n",
    "                    self.model(x_cont, x_cat)\n",
    "                    .squeeze(-1)  # Remove the last dimension for regression tasks\n",
    "                    .float()\n",
    "                )\n",
    "\n",
    "    def loss_fn(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            The predicted outputs.\n",
    "        y_true : torch.Tensor\n",
    "            The ground truth.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss value.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            # Use the second-to-last dimension for averaging over k heads.\n",
    "            k = y_pred.shape[-2]\n",
    "            target = y_true.repeat_interleave(k)\n",
    "            return F.cross_entropy(y_pred.flatten(0, 1), target)\n",
    "        else:\n",
    "            # TabM produces k predictions. Each of them must be trained separately.\n",
    "            # For student model (regression on logits), y_pred.shape == (batch_size, k)\n",
    "            k = y_pred.shape[-1 if len(y_pred.shape) <= 2 else -2]\n",
    "\n",
    "            # Flatten the predictions and repeat the targets\n",
    "            return F.mse_loss(\n",
    "                y_pred.flatten(0, 1),\n",
    "                (\n",
    "                    y_true.repeat_interleave(k)\n",
    "                    if self.model.share_training_batches\n",
    "                    else y_true\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def evaluate_tabm(self, part: str) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model on a data partition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The accuracy score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with self.evaluation_mode():\n",
    "            eval_batch_size = 8096\n",
    "\n",
    "            if self.task_type == \"binary\":\n",
    "                indices = torch.arange(\n",
    "                    len(self.data[part][\"y\"]), device=self.device\n",
    "                ).split(eval_batch_size)\n",
    "                y_pred = torch.cat(\n",
    "                    [self.apply_model(part, idx) for idx in indices]\n",
    "                ).cpu()\n",
    "                y_pred = torch.softmax(y_pred, dim=-1).mean(1)\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "                return float(accuracy_score(y_true, y_pred.argmax(1)))\n",
    "            else:\n",
    "                y_pred = (\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            self.apply_model(part, idx)\n",
    "                            for idx in torch.arange(\n",
    "                                len(self.data[part][\"y\"]), device=self.device\n",
    "                            ).split(eval_batch_size)\n",
    "                        ]\n",
    "                    )\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "                # Transform the predictions back to the original label space\n",
    "                if hasattr(self, \"regression_label_stats\"):\n",
    "                    y_pred = (\n",
    "                        y_pred * self.regression_label_stats[\"std\"]\n",
    "                        + self.regression_label_stats[\"mean\"]\n",
    "                    )\n",
    "\n",
    "                # Compute the mean of the k predictions\n",
    "                y_pred = y_pred.mean(1)\n",
    "\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "\n",
    "                # For student model, we want to minimize MSE, so return negative MSE\n",
    "                # The higher the value, the better (consistent with example.ipynb)\n",
    "                score = -(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "                return float(score)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples,)\n",
    "            The predicted class indices.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(X_tensor)\n",
    "                # Since share_training_batches is True, average over the second dimension.\n",
    "                probs = torch.softmax(logits, dim=-1).mean(1)\n",
    "                return probs.cpu().numpy()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                # TabM produces output with shape (batch_size, k) or (batch_size, k, n_outputs)\n",
    "                logits = self.model(X_tensor)\n",
    "\n",
    "                # For student model (regression), we need to average over the k predictions\n",
    "                # Check the dimensions of logits and average appropriately\n",
    "                if logits.ndim > 2:  # Case: (batch_size, k, n_outputs)\n",
    "                    logits = logits.mean(1)  # Average over k dimension\n",
    "                elif (\n",
    "                    logits.shape[1] > 1\n",
    "                    and hasattr(self.model, \"k\")\n",
    "                    and self.model.k > 1\n",
    "                ):\n",
    "                    # Case: (batch_size, k) for single output regression\n",
    "                    logits = logits.mean(\n",
    "                        1, keepdim=True\n",
    "                    )  # Average and keep output dimension\n",
    "\n",
    "                return logits.cpu().numpy().squeeze(-1)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained yet\")\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)    \n",
    "\n",
    "\n",
    "class MLPTeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a TabM teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Set up AMP if CUDA is available.\n",
    "        if torch.cuda.is_available():\n",
    "            self.amp_dtype = (\n",
    "                torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "            )\n",
    "            self.amp_enabled = True\n",
    "        else:\n",
    "            self.amp_dtype = None\n",
    "            self.amp_enabled = False\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the TabM model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the TabM model's fit method.\n",
    "        \"\"\"\n",
    "        # Get parameters\n",
    "        n_blocks = self.hyperparams.get(\"n_blocks\")\n",
    "        d_block = self.hyperparams.get(\"d_block\")\n",
    "        dropout = self.hyperparams.get(\"dropout\")\n",
    "        lr = self.hyperparams.get(\"learning_rate\")\n",
    "        weight_decay = self.hyperparams.get(\"weight_decay\")\n",
    "\n",
    "        # Set model architecture\n",
    "        arch_type = \"plain\"\n",
    "        bins = None\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            n_classes = len(np.unique(y))\n",
    "            self.n_classes = n_classes\n",
    "            cat_idx = []  # Assumes all features are continuous\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=cat_idx,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=None,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        else:\n",
    "            if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "                # Multiclass logits\n",
    "                n_outputs = y.shape[1]\n",
    "            else:\n",
    "                # Binary or single-output regression\n",
    "                n_outputs = 1\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=[],  # Assumes all features are continuous\n",
    "                n_classes=n_outputs,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=None,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            make_parameter_groups(self.model), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        self.evaluation_mode = torch.no_grad if compile_model else torch.inference_mode\n",
    "\n",
    "        # Prepare data\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        if self.task_type == \"binary\":\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long, device=self.device)\n",
    "        else:\n",
    "            y_tensor = torch.tensor(y, dtype=torch.float32, device=self.device)\n",
    "        n_samples = X_tensor.size(0)\n",
    "        indices = torch.randperm(n_samples)\n",
    "        train_end = int(0.8 * n_samples)\n",
    "        train_idx, val_idx = indices[:train_end], indices[train_end:]\n",
    "        self.data = {\n",
    "            \"train\": {\"x_cont\": X_tensor[train_idx], \"y\": y_tensor[train_idx]},\n",
    "            \"val\": {\"x_cont\": X_tensor[val_idx], \"y\": y_tensor[val_idx]},\n",
    "        }\n",
    "        Y_train = self.data[\"train\"][\"y\"]\n",
    "\n",
    "        # Training parameters\n",
    "        n_epochs = 100000\n",
    "        patience = 16\n",
    "        batch_size = 256\n",
    "        train_size = len(Y_train)\n",
    "        best = {\"val\": -float(\"inf\"), \"epoch\": -1}\n",
    "        remaining_patience = patience\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            batches = torch.randperm(train_size, device=self.device).split(batch_size)\n",
    "            for batch_idx in batches:\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_fn(\n",
    "                    self.apply_model(\"train\", batch_idx), Y_train[batch_idx]\n",
    "                )\n",
    "                if self.amp_enabled and self.amp_dtype == torch.float16:\n",
    "                    scaler = torch.cuda.amp.GradScaler()\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            val_score = self.evaluate_tabm(\"val\")\n",
    "            if val_score > best[\"val\"]:\n",
    "                best = {\"val\": val_score, \"epoch\": epoch}\n",
    "                remaining_patience = patience\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "\n",
    "    def apply_model(self, part: str, idx: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply the model to a batch of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "        idx : torch.Tensor\n",
    "            The indices of the samples to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The model output.\n",
    "        \"\"\"\n",
    "        with torch.autocast(\n",
    "            self.device.type, enabled=self.amp_enabled, dtype=self.amp_dtype\n",
    "        ):\n",
    "            x_cont = self.data[part][\"x_cont\"][idx]\n",
    "            x_cat = self.data[part].get(\"x_cat\")\n",
    "            if self.task_type == \"binary\":\n",
    "                return self.model(x_cont, x_cat).float()\n",
    "            else:\n",
    "                return (\n",
    "                    self.model(x_cont, x_cat)\n",
    "                    .squeeze(-1)  # Remove the last dimension for regression tasks\n",
    "                    .float()\n",
    "                )\n",
    "\n",
    "    def loss_fn(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            The predicted outputs.\n",
    "        y_true : torch.Tensor\n",
    "            The ground truth.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss value.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            # Use the second-to-last dimension for averaging over k heads.\n",
    "            k = y_pred.shape[-2]\n",
    "            target = y_true.repeat_interleave(k)\n",
    "            return F.cross_entropy(y_pred.flatten(0, 1), target)\n",
    "        else:\n",
    "            # TabM produces k predictions. Each of them must be trained separately.\n",
    "            # For student model (regression on logits), y_pred.shape == (batch_size, k)\n",
    "            k = y_pred.shape[-1 if len(y_pred.shape) <= 2 else -2]\n",
    "\n",
    "            # Flatten the predictions and repeat the targets\n",
    "            return F.mse_loss(\n",
    "                y_pred.flatten(0, 1),\n",
    "                (\n",
    "                    y_true.repeat_interleave(k)\n",
    "                    if self.model.share_training_batches\n",
    "                    else y_true\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def evaluate_tabm(self, part: str) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model on a data partition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The accuracy score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with self.evaluation_mode():\n",
    "            eval_batch_size = 8096\n",
    "\n",
    "            if self.task_type == \"binary\":\n",
    "                indices = torch.arange(\n",
    "                    len(self.data[part][\"y\"]), device=self.device\n",
    "                ).split(eval_batch_size)\n",
    "                y_pred = torch.cat(\n",
    "                    [self.apply_model(part, idx) for idx in indices]\n",
    "                ).cpu()\n",
    "                y_pred = torch.softmax(y_pred, dim=-1).mean(1)\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "                return float(accuracy_score(y_true, y_pred.argmax(1)))\n",
    "            else:\n",
    "                y_pred = (\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            self.apply_model(part, idx)\n",
    "                            for idx in torch.arange(\n",
    "                                len(self.data[part][\"y\"]), device=self.device\n",
    "                            ).split(eval_batch_size)\n",
    "                        ]\n",
    "                    )\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "                # Transform the predictions back to the original label space\n",
    "                if hasattr(self, \"regression_label_stats\"):\n",
    "                    y_pred = (\n",
    "                        y_pred * self.regression_label_stats[\"std\"]\n",
    "                        + self.regression_label_stats[\"mean\"]\n",
    "                    )\n",
    "\n",
    "                # Compute the mean of the k predictions\n",
    "                y_pred = y_pred.mean(1)\n",
    "\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "\n",
    "                # For student model, we want to minimize MSE, so return negative MSE\n",
    "                # The higher the value, the better (consistent with example.ipynb)\n",
    "                score = -(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "                return float(score)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples,)\n",
    "            The predicted class indices.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(X_tensor)\n",
    "                # Since share_training_batches is True, average over the second dimension.\n",
    "                probs = torch.softmax(logits, dim=-1).mean(1)\n",
    "                return probs.cpu().numpy()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                # TabM produces output with shape (batch_size, k) or (batch_size, k, n_outputs)\n",
    "                logits = self.model(X_tensor)\n",
    "\n",
    "                # For student model (regression), we need to average over the k predictions\n",
    "                # Check the dimensions of logits and average appropriately\n",
    "                if logits.ndim > 2:  # Case: (batch_size, k, n_outputs)\n",
    "                    logits = logits.mean(1)  # Average over k dimension\n",
    "                elif (\n",
    "                    logits.shape[1] > 1\n",
    "                    and hasattr(self.model, \"k\")\n",
    "                    and self.model.k > 1\n",
    "                ):\n",
    "                    # Case: (batch_size, k) for single output regression\n",
    "                    logits = logits.mean(\n",
    "                        1, keepdim=True\n",
    "                    )  # Average and keep output dimension\n",
    "\n",
    "                return logits.cpu().numpy().squeeze(-1)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained yet\")\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "class RandomForestTeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a RandomForest teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the RandomForest teacher model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters (not used for RandomForest).\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            # Initialize the RandomForest model with the provided hyperparameters\n",
    "            self.model = RandomForestClassifier(\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,  # Use all available CPU cores\n",
    "                **self.hyperparams,\n",
    "            )\n",
    "        else:\n",
    "            self.model = RandomForestRegressor(\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,  # Use all available CPU cores\n",
    "                **self.hyperparams,\n",
    "            )\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make probability predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples, n_classes)\n",
    "            The predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of parameters in the trained RandomForest model.\n",
    "\n",
    "        For each tree, we count:\n",
    "        - The feature indices at each node (1 parameter per node except leaf nodes)\n",
    "        - The thresholds at each node (1 parameter per node except leaf nodes)\n",
    "        - The values at each leaf node (1 parameter per leaf node)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of parameters in the model.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\") or self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet.\")\n",
    "\n",
    "        n_params = 0\n",
    "        for tree in self.model.estimators_:\n",
    "            tree = tree.tree_\n",
    "            # Number of nodes in the tree\n",
    "            n_nodes = tree.node_count\n",
    "            # Number of leaf nodes\n",
    "            n_leaves = tree.n_leaves\n",
    "            # Number of internal nodes\n",
    "            n_internal = n_nodes - n_leaves\n",
    "            # Each internal node has a feature index and a threshold\n",
    "            n_params += 2 * n_internal\n",
    "\n",
    "            # Each leaf node has value(s) - depends on task type\n",
    "            if self.task_type == \"binary\":\n",
    "                # For classification, each leaf stores class distribution\n",
    "                n_params += n_leaves * self.model.n_classes_\n",
    "            else:\n",
    "                # For regression, each leaf stores a single value\n",
    "                n_params += n_leaves\n",
    "\n",
    "        return n_params\n",
    "    \n",
    "def get_teacher_model(config: dict, task_type: Literal[\"binary\", \"regression\"], device, hyperparams, cat_cols=None) -> TeacherModelBase:\n",
    "    \"\"\"\n",
    "    Returns an instance of the teacher model based on the configuration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict\n",
    "        Configuration dictionary containing model and dataset details.\n",
    "    device : torch.device\n",
    "        The device to use for training (CPU or GPU).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TeacherModelBase\n",
    "        An instance of the teacher model.\n",
    "    \"\"\"\n",
    "    model_type = config[\"model\"][\"teacher_model\"]\n",
    "    if model_type == \"tabpfn\":\n",
    "        return TabPFNTeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"catboost\":\n",
    "        return CatBoostTeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"grande\":\n",
    "        return GRANDETeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams, cat_cols=cat_cols)\n",
    "    elif model_type == \"tabm\":\n",
    "        return TabMTeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"mlp\":\n",
    "        return MLPTeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"random_forest\":\n",
    "        return RandomForestTeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown teacher type: {config['model']['teacher_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ba41a",
   "metadata": {},
   "source": [
    "## Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbb13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentModelBase(ABC):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.params = kwargs\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Trains the model on the given data.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.ndarray): The input features with shape (n_samples, n_features).\n",
    "            y (np.ndarray): The target labels with shape (n_samples,).\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Makes predictions on the provided data.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.ndarray): The input features with shape (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: An array of predicted probabilities with shape (n_samples, n_classes).\n",
    "                        (If the model returns logits, these should be post-processed to probabilities.)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, y_pred: np.ndarray, y_true: np.ndarray, y_teacher_true: np.ndarray, original_task_type: Literal[\"binary\", \"regression\"]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluates the model's predictions against the true labels.\n",
    "\n",
    "        Parameters:\n",
    "            y_pred (np.ndarray): The predicted probabilities or values.\n",
    "            y_true (np.ndarray): The true labels.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: A dictionary containing evaluation metrics.\n",
    "        \"\"\"     \n",
    "        if original_task_type == \"binary\":\n",
    "            if self.task_type == \"binary\":\n",
    "                metrics = evaluate_classification(y_pred, y_true)\n",
    "                fidelity_metrics = evaluate_fidelity_classification(y_pred, y_teacher_true)\n",
    "                metrics.update(fidelity_metrics)\n",
    "                metrics['parameters'] = self.count_parameters()\n",
    "                return metrics\n",
    "            \n",
    "            elif self.task_type == \"regression\":\n",
    "                # Convert logits to probabilities\n",
    "                y_prob = 1 / (1 + np.exp(-y_pred))  # Sigmoid function\n",
    "                y_prob = np.column_stack([1 - y_prob, y_prob])  # Create 2D array with probs for both classes\n",
    "\n",
    "                y_teacher_prob = 1 / (1 + np.exp(-y_teacher_true))\n",
    "                y_teacher_prob = np.column_stack([1 - y_teacher_prob, y_teacher_prob])\n",
    "                \n",
    "                metrics = evaluate_classification(y_prob, y_true)\n",
    "                class_fidelity_metrics = evaluate_fidelity_classification(y_prob, y_teacher_prob)\n",
    "                metrics.update(class_fidelity_metrics)\n",
    "                reg_fidelity_metrics = evaluate_fidelity_regression(y_pred, y_teacher_true)\n",
    "                metrics.update(reg_fidelity_metrics)\n",
    "                metrics['parameters'] = self.count_parameters()\n",
    "                return metrics\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(f\"Unknown task type: {self.task_type}. Must be 'binary' or 'regression'.\")\n",
    "        \n",
    "        elif original_task_type == \"regression\":\n",
    "            metrics = evaluate_regression(y_pred, y_true)\n",
    "            fidelity_metrics = evaluate_fidelity_regression(y_pred, y_teacher_true)\n",
    "            metrics.update(fidelity_metrics)\n",
    "            metrics['parameters'] = self.count_parameters()\n",
    "            return metrics\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task type: {self.task_type}. Must be 'binary' or 'regression'.\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def count_parameters(self) -> int:\n",
    "        \"\"\"\n",
    "        Counts the number of trainable parameters in the model.\n",
    "\n",
    "        Returns:\n",
    "            int: The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class CatBoostStudentModel(StudentModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a CatBoost teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the CatBoost model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the CatBoost model's fit method.\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        # Initialize the CatBoost model\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model = CatBoostClassifier(\n",
    "                random_seed=random_state,\n",
    "                thread_count=-1,  # Use all available CPU cores\n",
    "                logging_level=\"Silent\",  # Suppress CatBoost output\n",
    "                task_type=(\"GPU\" if str(self.device).lower() == \"cuda\" else \"CPU\"),\n",
    "                **self.hyperparams,  # Include the sampled hyperparameters\n",
    "            )\n",
    "        else:\n",
    "            self.model = CatBoostRegressor(\n",
    "                random_seed=random_state,\n",
    "                thread_count=-1,  # Use all available CPU cores\n",
    "                logging_level=\"Silent\",  # Suppress CatBoost output\n",
    "                task_type=(\"GPU\" if str(self.device).lower() == \"cuda\" else \"CPU\"),\n",
    "                **self.hyperparams,  # Include the sampled hyperparameters\n",
    "            )\n",
    "\n",
    "        # Split data into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        # Train the model\n",
    "        self.model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=(X_val, y_val),\n",
    "            early_stopping_rounds=20, \n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples, n_classes)\n",
    "            The predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of parameters in the trained CatBoost model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of parameters in the model.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\") or self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet.\")\n",
    "\n",
    "        # Get the number of trees in the model\n",
    "        tree_count = self.model.tree_count_\n",
    "\n",
    "        # For each tree, count:\n",
    "        # - split values (one per non-leaf node)\n",
    "        # - leaf values (one per leaf node)\n",
    "        # - feature indices (one per non-leaf node)\n",
    "        # For a binary tree with depth d, there are 2^d - 1 non-leaf nodes and 2^d leaf nodes\n",
    "        # This is a simplified approximation\n",
    "        approx_depth = self.hyperparams.get(\"max_depth\", 6)  # Default depth in CatBoost is 6\n",
    "        non_leaf_nodes = 2**approx_depth - 1\n",
    "        leaf_nodes = 2**approx_depth\n",
    "\n",
    "        # Total parameters per tree\n",
    "        params_per_tree = (\n",
    "            non_leaf_nodes * 2 + leaf_nodes\n",
    "        )  # split values + feature indices + leaf values\n",
    "        return tree_count * params_per_tree\n",
    "    \n",
    "\n",
    "class GRANDEStudentModel(StudentModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a GRANDE teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments. The `device` parameter is popped from kwargs and\n",
    "            defaults to 'cpu' if not provided.\n",
    "        \"\"\"\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "        os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        self.cat_cols = kwargs.pop(\"cat_cols\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the GRANDE teacher model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the GRANDE model's fit method.\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        # Determine categorical indices\n",
    "        cat_indices = [i for i, is_cat in enumerate(self.cat_cols) if is_cat]\n",
    "\n",
    "        training_params = {\n",
    "            \"epochs\": 1000,\n",
    "            \"early_stopping_epochs\": 25,\n",
    "            \"batch_size\": 64,\n",
    "            \"cat_idx\": cat_indices,\n",
    "            \"random_seed\": random_state,\n",
    "        }\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            training_params[\"objective\"] = \"binary\"\n",
    "        else:\n",
    "            training_params[\"objective\"] = \"regression\"\n",
    "\n",
    "        # Instantiate the GRANDE teacher model.\n",
    "        self.model = GRANDE(params=self.hyperparams, args=training_params)\n",
    "\n",
    "        # Split the data into training and validation sets.\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        self.model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given input data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like\n",
    "            The predicted target values.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict(X)\n",
    "        else:\n",
    "            return self.model.predict(X).squeeze()\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the GRANDE teacher model based on the\n",
    "        dense representation of a single tree and the number of trees in the ensemble.\n",
    "\n",
    "        The number of parameters for a single tree is computed as:\n",
    "            leaf parameters: 2^d\n",
    "            split thresholds: (2^d - 1) * n\n",
    "            feature selection (one-hot): (2^d - 1) * n\n",
    "        so that:\n",
    "            params_per_tree = 2^d + 2 * n * (2^d - 1)\n",
    "        The total is then:\n",
    "            total_params = n_estimators * params_per_tree\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained/initialized yet.\")\n",
    "\n",
    "        # These attributes must be set when the GRANDE model is instantiated.\n",
    "        # Adjust the attribute names if they are different in your GRANDE implementation.\n",
    "        d = self.model.depth  # Depth of each decision tree.\n",
    "        n = self.model.number_of_variables  # Number of features used in the tree.\n",
    "        E = self.model.n_estimators  # Number of trees in the ensemble.\n",
    "\n",
    "        # Calculate the number of parameters for one tree.\n",
    "        params_per_tree = (2**d) + 2 * n * ((2**d) - 1)\n",
    "        total_params = E * params_per_tree\n",
    "\n",
    "        return total_params\n",
    "    \n",
    "class TabMStudentModel(StudentModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a TabM teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Set up AMP if CUDA is available.\n",
    "        if torch.cuda.is_available():\n",
    "            self.amp_dtype = (\n",
    "                torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "            )\n",
    "            self.amp_enabled = True\n",
    "        else:\n",
    "            self.amp_dtype = None\n",
    "            self.amp_enabled = False\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the TabM model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the TabM model's fit method.\n",
    "        \"\"\"\n",
    "        # Get parameters\n",
    "        n_blocks = self.hyperparams.get(\"n_blocks\")\n",
    "        d_block = self.hyperparams.get(\"d_block\")\n",
    "        dropout = self.hyperparams.get(\"dropout\")\n",
    "        lr = self.hyperparams.get(\"learning_rate\")\n",
    "        weight_decay = self.hyperparams.get(\"weight_decay\")\n",
    "\n",
    "        # Set model architecture\n",
    "        arch_type = \"tabm\"\n",
    "        bins = None\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            n_classes = len(np.unique(y))\n",
    "            self.n_classes = n_classes\n",
    "            cat_idx = []  # Assumes all features are continuous\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=cat_idx,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=32,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        else:\n",
    "            if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "                # Multiclass logits\n",
    "                n_outputs = y.shape[1]\n",
    "            else:\n",
    "                # Binary or single-output regression\n",
    "                n_outputs = 1\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=[],  # Assumes all features are continuous\n",
    "                n_classes=n_outputs,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=32,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            make_parameter_groups(self.model), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        self.evaluation_mode = torch.no_grad if compile_model else torch.inference_mode\n",
    "\n",
    "        # Prepare data\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        if self.task_type == \"binary\":\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long, device=self.device)\n",
    "        else:\n",
    "            y_tensor = torch.tensor(y, dtype=torch.float32, device=self.device)\n",
    "        n_samples = X_tensor.size(0)\n",
    "        indices = torch.randperm(n_samples)\n",
    "        train_end = int(0.8 * n_samples)\n",
    "        train_idx, val_idx = indices[:train_end], indices[train_end:]\n",
    "        self.data = {\n",
    "            \"train\": {\"x_cont\": X_tensor[train_idx], \"y\": y_tensor[train_idx]},\n",
    "            \"val\": {\"x_cont\": X_tensor[val_idx], \"y\": y_tensor[val_idx]},\n",
    "        }\n",
    "        Y_train = self.data[\"train\"][\"y\"]\n",
    "\n",
    "        # Training parameters\n",
    "        n_epochs = 100000\n",
    "        patience = 16\n",
    "        batch_size = 256\n",
    "        train_size = len(Y_train)\n",
    "        best = {\"val\": -float(\"inf\"), \"epoch\": -1}\n",
    "        remaining_patience = patience\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            batches = torch.randperm(train_size, device=self.device).split(batch_size)\n",
    "            for batch_idx in batches:\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_fn(\n",
    "                    self.apply_model(\"train\", batch_idx), Y_train[batch_idx]\n",
    "                )\n",
    "                if self.amp_enabled and self.amp_dtype == torch.float16:\n",
    "                    scaler = torch.cuda.amp.GradScaler()\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            val_score = self.evaluate_tabm(\"val\")\n",
    "            if val_score > best[\"val\"]:\n",
    "                best = {\"val\": val_score, \"epoch\": epoch}\n",
    "                remaining_patience = patience\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "\n",
    "    def apply_model(self, part: str, idx: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply the model to a batch of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "        idx : torch.Tensor\n",
    "            The indices of the samples to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The model output.\n",
    "        \"\"\"\n",
    "        with torch.autocast(\n",
    "            self.device.type, enabled=self.amp_enabled, dtype=self.amp_dtype\n",
    "        ):\n",
    "            x_cont = self.data[part][\"x_cont\"][idx]\n",
    "            x_cat = self.data[part].get(\"x_cat\")\n",
    "            if self.task_type == \"binary\":\n",
    "                return self.model(x_cont, x_cat).float()\n",
    "            else:\n",
    "                return (\n",
    "                    self.model(x_cont, x_cat)\n",
    "                    .squeeze(-1)  # Remove the last dimension for regression tasks\n",
    "                    .float()\n",
    "                )\n",
    "\n",
    "    def loss_fn(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            The predicted outputs.\n",
    "        y_true : torch.Tensor\n",
    "            The ground truth.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss value.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            # Use the second-to-last dimension for averaging over k heads.\n",
    "            k = y_pred.shape[-2]\n",
    "            target = y_true.repeat_interleave(k)\n",
    "            return F.cross_entropy(y_pred.flatten(0, 1), target)\n",
    "        else:\n",
    "            # TabM produces k predictions. Each of them must be trained separately.\n",
    "            # For student model (regression on logits), y_pred.shape == (batch_size, k)\n",
    "            k = y_pred.shape[-1 if len(y_pred.shape) <= 2 else -2]\n",
    "\n",
    "            # Flatten the predictions and repeat the targets\n",
    "            return F.mse_loss(\n",
    "                y_pred.flatten(0, 1),\n",
    "                (\n",
    "                    y_true.repeat_interleave(k)\n",
    "                    if self.model.share_training_batches\n",
    "                    else y_true\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def evaluate_tabm(self, part: str) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model on a data partition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The accuracy score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with self.evaluation_mode():\n",
    "            eval_batch_size = 8096\n",
    "\n",
    "            if self.task_type == \"binary\":\n",
    "                indices = torch.arange(\n",
    "                    len(self.data[part][\"y\"]), device=self.device\n",
    "                ).split(eval_batch_size)\n",
    "                y_pred = torch.cat(\n",
    "                    [self.apply_model(part, idx) for idx in indices]\n",
    "                ).cpu()\n",
    "                y_pred = torch.softmax(y_pred, dim=-1).mean(1)\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "                return float(accuracy_score(y_true, y_pred.argmax(1)))\n",
    "            else:\n",
    "                y_pred = (\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            self.apply_model(part, idx)\n",
    "                            for idx in torch.arange(\n",
    "                                len(self.data[part][\"y\"]), device=self.device\n",
    "                            ).split(eval_batch_size)\n",
    "                        ]\n",
    "                    )\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "                # Transform the predictions back to the original label space\n",
    "                if hasattr(self, \"regression_label_stats\"):\n",
    "                    y_pred = (\n",
    "                        y_pred * self.regression_label_stats[\"std\"]\n",
    "                        + self.regression_label_stats[\"mean\"]\n",
    "                    )\n",
    "\n",
    "                # Compute the mean of the k predictions\n",
    "                y_pred = y_pred.mean(1)\n",
    "\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "\n",
    "                # For student model, we want to minimize MSE, so return negative MSE\n",
    "                # The higher the value, the better (consistent with example.ipynb)\n",
    "                score = -(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "                return float(score)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples,)\n",
    "            The predicted class indices.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(X_tensor)\n",
    "                # Since share_training_batches is True, average over the second dimension.\n",
    "                probs = torch.softmax(logits, dim=-1).mean(1)\n",
    "                return probs.cpu().numpy()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                # TabM produces output with shape (batch_size, k) or (batch_size, k, n_outputs)\n",
    "                logits = self.model(X_tensor)\n",
    "\n",
    "                # For student model (regression), we need to average over the k predictions\n",
    "                # Check the dimensions of logits and average appropriately\n",
    "                if logits.ndim > 2:  # Case: (batch_size, k, n_outputs)\n",
    "                    logits = logits.mean(1)  # Average over k dimension\n",
    "                elif (\n",
    "                    logits.shape[1] > 1\n",
    "                    and hasattr(self.model, \"k\")\n",
    "                    and self.model.k > 1\n",
    "                ):\n",
    "                    # Case: (batch_size, k) for single output regression\n",
    "                    logits = logits.mean(\n",
    "                        1, keepdim=True\n",
    "                    )  # Average and keep output dimension\n",
    "\n",
    "                return logits.cpu().numpy().squeeze(-1)  # Squeeze to remove last dimension if needed\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained yet\")\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)    \n",
    "\n",
    "\n",
    "class MLPStudentModel(StudentModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a TabM teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Set up AMP if CUDA is available.\n",
    "        if torch.cuda.is_available():\n",
    "            self.amp_dtype = (\n",
    "                torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "            )\n",
    "            self.amp_enabled = True\n",
    "        else:\n",
    "            self.amp_dtype = None\n",
    "            self.amp_enabled = False\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the TabM model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the TabM model's fit method.\n",
    "        \"\"\"\n",
    "        # Get parameters\n",
    "        n_blocks = self.hyperparams.get(\"n_blocks\")\n",
    "        d_block = self.hyperparams.get(\"d_block\")\n",
    "        dropout = self.hyperparams.get(\"dropout\")\n",
    "        lr = self.hyperparams.get(\"learning_rate\")\n",
    "        weight_decay = self.hyperparams.get(\"weight_decay\")\n",
    "\n",
    "        # Set model architecture\n",
    "        arch_type = \"plain\"\n",
    "        bins = None\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            n_classes = len(np.unique(y))\n",
    "            self.n_classes = n_classes\n",
    "            cat_idx = []  # Assumes all features are continuous\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=cat_idx,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=None,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        else:\n",
    "            if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "                # Multiclass logits\n",
    "                n_outputs = y.shape[1]\n",
    "            else:\n",
    "                # Binary or single-output regression\n",
    "                n_outputs = 1\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=[],  # Assumes all features are continuous\n",
    "                n_classes=n_outputs,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=None,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            make_parameter_groups(self.model), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        self.evaluation_mode = torch.no_grad if compile_model else torch.inference_mode\n",
    "\n",
    "        # Prepare data\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        if self.task_type == \"binary\":\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long, device=self.device)\n",
    "        else:\n",
    "            y_tensor = torch.tensor(y, dtype=torch.float32, device=self.device)\n",
    "        n_samples = X_tensor.size(0)\n",
    "        indices = torch.randperm(n_samples)\n",
    "        train_end = int(0.8 * n_samples)\n",
    "        train_idx, val_idx = indices[:train_end], indices[train_end:]\n",
    "        self.data = {\n",
    "            \"train\": {\"x_cont\": X_tensor[train_idx], \"y\": y_tensor[train_idx]},\n",
    "            \"val\": {\"x_cont\": X_tensor[val_idx], \"y\": y_tensor[val_idx]},\n",
    "        }\n",
    "        Y_train = self.data[\"train\"][\"y\"]\n",
    "\n",
    "        # Training parameters\n",
    "        n_epochs = 100000\n",
    "        patience = 16\n",
    "        batch_size = 256\n",
    "        train_size = len(Y_train)\n",
    "        best = {\"val\": -float(\"inf\"), \"epoch\": -1}\n",
    "        remaining_patience = patience\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            batches = torch.randperm(train_size, device=self.device).split(batch_size)\n",
    "            for batch_idx in batches:\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_fn(\n",
    "                    self.apply_model(\"train\", batch_idx), Y_train[batch_idx]\n",
    "                )\n",
    "                if self.amp_enabled and self.amp_dtype == torch.float16:\n",
    "                    scaler = torch.cuda.amp.GradScaler()\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            val_score = self.evaluate_tabm(\"val\")\n",
    "            if val_score > best[\"val\"]:\n",
    "                best = {\"val\": val_score, \"epoch\": epoch}\n",
    "                remaining_patience = patience\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "\n",
    "    def apply_model(self, part: str, idx: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply the model to a batch of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "        idx : torch.Tensor\n",
    "            The indices of the samples to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The model output.\n",
    "        \"\"\"\n",
    "        with torch.autocast(\n",
    "            self.device.type, enabled=self.amp_enabled, dtype=self.amp_dtype\n",
    "        ):\n",
    "            x_cont = self.data[part][\"x_cont\"][idx]\n",
    "            x_cat = self.data[part].get(\"x_cat\")\n",
    "            if self.task_type == \"binary\":\n",
    "                return self.model(x_cont, x_cat).float()\n",
    "            else:\n",
    "                return (\n",
    "                    self.model(x_cont, x_cat)\n",
    "                    .squeeze(-1)  # Remove the last dimension for regression tasks\n",
    "                    .float()\n",
    "                )\n",
    "\n",
    "    def loss_fn(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            The predicted outputs.\n",
    "        y_true : torch.Tensor\n",
    "            The ground truth.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss value.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            # Use the second-to-last dimension for averaging over k heads.\n",
    "            k = y_pred.shape[-2]\n",
    "            target = y_true.repeat_interleave(k)\n",
    "            return F.cross_entropy(y_pred.flatten(0, 1), target)\n",
    "        else:\n",
    "            # TabM produces k predictions. Each of them must be trained separately.\n",
    "            # For student model (regression on logits), y_pred.shape == (batch_size, k)\n",
    "            k = y_pred.shape[-1 if len(y_pred.shape) <= 2 else -2]\n",
    "\n",
    "            # Flatten the predictions and repeat the targets\n",
    "            return F.mse_loss(\n",
    "                y_pred.flatten(0, 1),\n",
    "                (\n",
    "                    y_true.repeat_interleave(k)\n",
    "                    if self.model.share_training_batches\n",
    "                    else y_true\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def evaluate_tabm(self, part: str) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model on a data partition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The accuracy score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with self.evaluation_mode():\n",
    "            eval_batch_size = 8096\n",
    "\n",
    "            if self.task_type == \"binary\":\n",
    "                indices = torch.arange(\n",
    "                    len(self.data[part][\"y\"]), device=self.device\n",
    "                ).split(eval_batch_size)\n",
    "                y_pred = torch.cat(\n",
    "                    [self.apply_model(part, idx) for idx in indices]\n",
    "                ).cpu()\n",
    "                y_pred = torch.softmax(y_pred, dim=-1).mean(1)\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "                return float(accuracy_score(y_true, y_pred.argmax(1)))\n",
    "            else:\n",
    "                y_pred = (\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            self.apply_model(part, idx)\n",
    "                            for idx in torch.arange(\n",
    "                                len(self.data[part][\"y\"]), device=self.device\n",
    "                            ).split(eval_batch_size)\n",
    "                        ]\n",
    "                    )\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "                # Transform the predictions back to the original label space\n",
    "                if hasattr(self, \"regression_label_stats\"):\n",
    "                    y_pred = (\n",
    "                        y_pred * self.regression_label_stats[\"std\"]\n",
    "                        + self.regression_label_stats[\"mean\"]\n",
    "                    )\n",
    "\n",
    "                # Compute the mean of the k predictions\n",
    "                y_pred = y_pred.mean(1)\n",
    "\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "\n",
    "                # For student model, we want to minimize MSE, so return negative MSE\n",
    "                # The higher the value, the better (consistent with example.ipynb)\n",
    "                score = -(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "                return float(score)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples,)\n",
    "            The predicted class indices.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(X_tensor)\n",
    "                # Since share_training_batches is True, average over the second dimension.\n",
    "                probs = torch.softmax(logits, dim=-1).mean(1)\n",
    "                return probs.cpu().numpy()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                # TabM produces output with shape (batch_size, k) or (batch_size, k, n_outputs)\n",
    "                logits = self.model(X_tensor)\n",
    "\n",
    "                # For student model (regression), we need to average over the k predictions\n",
    "                # Check the dimensions of logits and average appropriately\n",
    "                if logits.ndim > 2:  # Case: (batch_size, k, n_outputs)\n",
    "                    logits = logits.mean(1)  # Average over k dimension\n",
    "                elif (\n",
    "                    logits.shape[1] > 1\n",
    "                    and hasattr(self.model, \"k\")\n",
    "                    and self.model.k > 1\n",
    "                ):\n",
    "                    # Case: (batch_size, k) for single output regression\n",
    "                    logits = logits.mean(\n",
    "                        1, keepdim=True\n",
    "                    )  # Average and keep output dimension\n",
    "\n",
    "                return logits.cpu().numpy().squeeze(-1)  # Squeeze to remove last dimension if needed\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained yet\")\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "\n",
    "class RandomForestStudentModel(StudentModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a RandomForest teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the RandomForest teacher model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters (not used for RandomForest).\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            # Initialize the RandomForest model with the provided hyperparameters\n",
    "            self.model = RandomForestClassifier(\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,  # Use all available CPU cores\n",
    "                **self.hyperparams,\n",
    "            )\n",
    "        else:\n",
    "            self.model = RandomForestRegressor(\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,  # Use all available CPU cores\n",
    "                **self.hyperparams,\n",
    "            )\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make probability predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples, n_classes)\n",
    "            The predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of parameters in the trained RandomForest model.\n",
    "\n",
    "        For each tree, we count:\n",
    "        - The feature indices at each node (1 parameter per node except leaf nodes)\n",
    "        - The thresholds at each node (1 parameter per node except leaf nodes)\n",
    "        - The values at each leaf node (1 parameter per leaf node)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of parameters in the model.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\") or self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet.\")\n",
    "\n",
    "        n_params = 0\n",
    "        for tree in self.model.estimators_:\n",
    "            tree = tree.tree_\n",
    "            # Number of nodes in the tree\n",
    "            n_nodes = tree.node_count\n",
    "            # Number of leaf nodes\n",
    "            n_leaves = tree.n_leaves\n",
    "            # Number of internal nodes\n",
    "            n_internal = n_nodes - n_leaves\n",
    "            # Each internal node has a feature index and a threshold\n",
    "            n_params += 2 * n_internal\n",
    "\n",
    "            # Each leaf node has value(s) - depends on task type\n",
    "            if self.task_type == \"binary\":\n",
    "                # For classification, each leaf stores class distribution\n",
    "                n_params += n_leaves * self.model.n_classes_\n",
    "            else:\n",
    "                # For regression, each leaf stores a single value\n",
    "                n_params += n_leaves\n",
    "\n",
    "        return n_params\n",
    "    \n",
    "def get_student_model(config: dict, task_type: Literal[\"binary\", \"regression\"], device, hyperparams, cat_cols=None) -> StudentModelBase:\n",
    "    \"\"\"\n",
    "    Returns an instance of the teacher model based on the configuration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict\n",
    "        Configuration dictionary containing model and dataset details.\n",
    "    device : torch.device\n",
    "        The device to use for training (CPU or GPU).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TeacherModelBase\n",
    "        An instance of the teacher model.\n",
    "    \"\"\"\n",
    "    model_type = config[\"model\"][\"student_model\"]\n",
    "    if model_type == \"catboost\":\n",
    "        return CatBoostStudentModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"grande\":\n",
    "        return GRANDEStudentModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams, cat_cols=cat_cols)\n",
    "    elif model_type == \"tabm\":\n",
    "        return TabMStudentModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"mlp\":\n",
    "        return MLPStudentModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"random_forest\":\n",
    "        return RandomForestStudentModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown teacher type: {config['model']['student_model']}. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d7a3c",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab890760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_hyperparameters(trial: optuna.Trial, model_type: str, task_type: str, use_hpo: bool) -> dict:\n",
    "    \"\"\"\n",
    "    Suggest hyperparameters for the given model type using Optuna.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trial : optuna.Trial\n",
    "        Optuna trial object for suggesting hyperparameters.\n",
    "    model_type : str\n",
    "        Type of model ('tabpfn', 'catboost', etc.).\n",
    "    task_type : str\n",
    "        Type of task ('binary', 'regression').\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of suggested hyperparameters.\n",
    "    \"\"\"\n",
    "    hyperparameter = {}\n",
    "    \n",
    "    if model_type == \"catboost\":\n",
    "        if use_hpo:\n",
    "            hyperparameter = {\n",
    "                \"iterations\": trial.suggest_int(\"iterations\", 512, 4096),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 2, 12),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "                \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.5, 30),\n",
    "                \"boosting_type\": \"Plain\",\n",
    "            }\n",
    "        else:\n",
    "            hyperparameter = {\n",
    "                \"iterations\": 1000,\n",
    "                \"max_depth\": 6,\n",
    "                \"l2_leaf_reg\": 3,\n",
    "                \"boosting_type\": \"Plain\",\n",
    "            }\n",
    "        if task_type == \"binary\":\n",
    "            hyperparameter[\"loss_function\"] = \"Logloss\"\n",
    "        else:\n",
    "            hyperparameter[\"loss_function\"] = \"RMSE\"\n",
    "    \n",
    "    elif model_type == \"grande\":\n",
    "        if use_hpo:\n",
    "            hyperparameter = {\n",
    "                \"depth\": trial.suggest_int(\"depth\", 3, 7),\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 512, 4096),\n",
    "                \"learning_rate_weights\": trial.suggest_float(\"learning_rate_weights\", 0.0001, 0.05, log=True),\n",
    "                \"learning_rate_index\": trial.suggest_float(\"learning_rate_index\", 0.001, 0.2, log=True),\n",
    "                \"learning_rate_values\": trial.suggest_float(\"learning_rate_values\", 0.001, 0.2, log=True),\n",
    "                \"learning_rate_leaf\": trial.suggest_float(\"learning_rate_leaf\", 0.001, 0.2, log=True),\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"cosine_decay_steps\": trial.suggest_categorical(\"cosine_decay_steps\", [0.0, 0.1, 1.0, 100.0, 1000.0]),\n",
    "                \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.75),\n",
    "                \"selected_variables\": trial.suggest_float(\"selected_variables\", 0.0, 1.0),\n",
    "                \"data_subset_fraction\": trial.suggest_float(\"data_subset_fraction\", 0.1, 1.0),\n",
    "                \"focal_loss\": False,\n",
    "                \"temperature\": 0.0,\n",
    "                \"from_logits\": True,\n",
    "                \"use_class_weights\": True,\n",
    "            }\n",
    "        else:\n",
    "            hyperparameter = {\n",
    "                \"depth\": 5,\n",
    "                \"n_estimators\": 2048,\n",
    "                \"learning_rate_weights\": 0.005,\n",
    "                \"learning_rate_index\": 0.01,\n",
    "                \"learning_rate_values\": 0.01,\n",
    "                \"learning_rate_leaf\": 0.01,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"cosine_decay_steps\": 0,\n",
    "                \"dropout\": 0.0,\n",
    "                \"selected_variables\": 0.8,\n",
    "                \"data_subset_fraction\": 1.0,\n",
    "                \"focal_loss\": False,\n",
    "                \"temperature\": 0.0,\n",
    "                \"from_logits\": True,\n",
    "                \"use_class_weights\": True,\n",
    "            }\n",
    "        if task_type == \"binary\":\n",
    "            hyperparameter[\"loss\"] = \"crossentropy\"\n",
    "        else:\n",
    "            hyperparameter[\"loss\"] = \"mse\"\n",
    "\n",
    "    elif model_type == \"tabm\":\n",
    "        if use_hpo:\n",
    "            hyperparameter = {\n",
    "                \"n_blocks\": trial.suggest_int(\"n_blocks\", 1, 5),\n",
    "                \"d_block\": trial.suggest_int(\"d_block\", 64, 1024),\n",
    "                \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.5),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.0001, 0.005, log=True),\n",
    "                \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0001, 0.1, log=True),\n",
    "            }\n",
    "        else:\n",
    "            hyperparameter = {\n",
    "                \"n_blocks\": 3,\n",
    "                \"d_block\": 512,\n",
    "                \"dropout\": 0.1,\n",
    "                \"learning_rate\": 0.002,\n",
    "                \"weight_decay\": 0.0003,\n",
    "            }\n",
    "\n",
    "    elif model_type == \"mlp\":\n",
    "        if use_hpo:\n",
    "            hyperparameter = {\n",
    "                \"n_blocks\": trial.suggest_int(\"n_blocks\", 1, 5),\n",
    "                \"d_block\": trial.suggest_int(\"d_block\", 64, 1024),\n",
    "                \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.5),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.0001, 0.005, log=True),\n",
    "                \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0001, 0.1, log=True),\n",
    "            }\n",
    "        else:\n",
    "            hyperparameter = {\n",
    "                \"n_blocks\": 3,\n",
    "                \"d_block\": 512,\n",
    "                \"dropout\": 0.1,\n",
    "                \"learning_rate\": 0.002,\n",
    "                \"weight_decay\": 0.0003,\n",
    "            }\n",
    "\n",
    "    elif model_type == \"random_forest\":\n",
    "        if use_hpo:\n",
    "            hyperparameter = {\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 4096),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 5, 100),\n",
    "                \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "                \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "                \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", 0.3, 0.5, 0.7, 1.0]),\n",
    "                \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "            }\n",
    "            if task_type == \"binary\":\n",
    "                hyperparameter[\"criterion\"] = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "            else:\n",
    "                hyperparameter[\"criterion\"] = trial.suggest_categorical(\"criterion\", [\"squared_error\", \"absolute_error\", \"poisson\", \"friedman_mse\"])\n",
    "        else:\n",
    "            hyperparameter = {\n",
    "                \"n_estimators\": 1000,\n",
    "                \"max_depth\": 40,\n",
    "                \"min_samples_split\": 2,\n",
    "                \"min_samples_leaf\": 1,\n",
    "            }\n",
    "            if task_type == \"binary\":\n",
    "                hyperparameter[\"criterion\"] = \"gini\"\n",
    "                hyperparameter[\"max_features\"] = \"sqrt\"\n",
    "            else:\n",
    "                hyperparameter[\"criterion\"] = \"squared_error\"\n",
    "                hyperparameter[\"max_features\"] = 1.0\n",
    "\n",
    "    return hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad02857a",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59b406d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"datasets\": [\n",
    "                     23381, # Binary classification datasets\n",
    "                       197, # Regression datasets\n",
    "                     ],  \n",
    "        \"cache_dir_path\": \"data/cache/\",\n",
    "        \"fold_indices_path\": \"data/fold_indices/\",\n",
    "        \"optuna_db_path\": \"data/optuna_db/\",\n",
    "        \"output_dir_path\": \"data/output/\",\n",
    "        \"outer_folds_path\": \"data/outer_fold/\",\n",
    "        \"results_dir_path\": \"results/\",\n",
    "    },\n",
    "\n",
    "    \"preprocessing\": {\n",
    "        \"threshold_high_cardinality\": 10,  \n",
    "    },\n",
    "\n",
    "    \"model\": {\n",
    "        \"teacher_model\": \"tabpfn\",   # Options: 'tabpfn', 'grande', 'catboost', 'tabm', 'mlp', 'random_forest'\n",
    "        \"student_model\": \"grande\", # Options: 'grande', 'catboost', 'tabm', 'mlp', 'random_forest'\n",
    "    },\n",
    "\n",
    "    \"training\": {\n",
    "        \"use_hpo\": False,\n",
    "        \"train_on_logits\": True,\n",
    "        \"trials\": 5,\n",
    "        \"random_state\": 42,\n",
    "        \"outer_folds\": 5,\n",
    "        \"inner_folds\": 2,\n",
    "    },\n",
    "\n",
    "    \"teacher_models\": {\n",
    "        \"tabpfn\": {\n",
    "            \"preprocessing\": \"nn\",  \n",
    "        },\n",
    "        \"catboost\": {\n",
    "            \"preprocessing\": \"tree\", \n",
    "        },\n",
    "        \"grande\": {\n",
    "            \"preprocessing\": \"grande\",  \n",
    "        },\n",
    "        \"tabm\": {\n",
    "            \"preprocessing\": \"nn\",  \n",
    "        },\n",
    "        \"mlp\": {\n",
    "            \"preprocessing\": \"nn\",  \n",
    "        },\n",
    "        \"random_forest\": {\n",
    "            \"preprocessing\": \"tree\",  \n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"student_models\": {\n",
    "        \"catboost\": {\n",
    "            \"preprocessing\": \"tree\",  \n",
    "        },\n",
    "        \"grande\": {\n",
    "            \"preprocessing\": \"grande\",  \n",
    "        },\n",
    "        \"tabm\": {\n",
    "            \"preprocessing\": \"nn\",  \n",
    "        },\n",
    "        \"mlp\": {\n",
    "            \"preprocessing\": \"nn\",  \n",
    "        },\n",
    "        \"random_forest\": {\n",
    "            \"preprocessing\": \"tree\",  \n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17729927",
   "metadata": {},
   "source": [
    "# Train Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dce1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 12:55:06,462 - __main__ - INFO - Loading configuration...\n",
      "2025-06-20 12:55:06,463 - __main__ - INFO - Loading dataset 23381 from cache at 'data/cache/openml_dataset_23381.pkl'...\n",
      "2025-06-20 12:55:06,464 - __main__ - INFO - Dataset 23381 loaded successfully with task type: binary\n",
      "2025-06-20 12:55:06,465 - __main__ - INFO - Using GPU: NVIDIA RTX A6000\n",
      "2025-06-20 12:55:06,466 - __main__ - INFO - Random seed set to 42\n",
      "2025-06-20 12:55:06,467 - __main__ - INFO - Outer Fold 1 - Train Indices: [ 1  3  5  6  7  8  9 10 11 12], Test Indices: [ 0  2  4 18 19 27 35 39 57 59]\n",
      "2025-06-20 12:55:06,468 - __main__ - INFO - -------------------- Outer Fold 1 --------------------\n",
      "2025-06-20 12:55:06,469 - __main__ - INFO - Starting hyperparameter optimization for outer fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-20 12:55:06,508] Using an existing study with name '23381.1.random_forest' instead of creating a new one.\n",
      "2025-06-20 12:55:06,634 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 2, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:08,389 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 1...\n",
      "2025-06-20 12:55:09,107 - __main__ - INFO - \t Balanced Accuracy: 0.5546, F1 Score: 0.5484, ROC AUC: 0.5235\n",
      "2025-06-20 12:55:09,131 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 3, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:10,137 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 2...\n",
      "2025-06-20 12:55:10,852 - __main__ - INFO - \t Balanced Accuracy: 0.5829, F1 Score: 0.5833, ROC AUC: 0.5733\n",
      "[I 2025-06-20 12:55:10,949] Trial 1 finished with value: 0.5658537401311388 and parameters: {'n_estimators': 1000, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 1 with value: 0.5658537401311388.\n",
      "2025-06-20 12:55:11,057 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 2, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:11,083 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 1...\n",
      "2025-06-20 12:55:13,961 - __main__ - INFO - \t Balanced Accuracy: 0.5408, F1 Score: 0.5409, ROC AUC: 0.5416\n",
      "2025-06-20 12:55:13,994 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 3, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:14,021 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 2...\n",
      "2025-06-20 12:55:16,900 - __main__ - INFO - \t Balanced Accuracy: 0.5330, F1 Score: 0.5265, ROC AUC: 0.5633\n",
      "[I 2025-06-20 12:55:17,003] Trial 2 finished with value: 0.5337424117952307 and parameters: {'n_estimators': 3025, 'max_depth': 62, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 1.0, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.5658537401311388.\n",
      "2025-06-20 12:55:17,088 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 2, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:17,114 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 1...\n",
      "2025-06-20 12:55:18,051 - __main__ - INFO - \t Balanced Accuracy: 0.4965, F1 Score: 0.4958, ROC AUC: 0.5179\n",
      "2025-06-20 12:55:18,072 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 3, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:18,098 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 2...\n",
      "2025-06-20 12:55:19,034 - __main__ - INFO - \t Balanced Accuracy: 0.5544, F1 Score: 0.5543, ROC AUC: 0.5638\n",
      "[I 2025-06-20 12:55:19,130] Trial 3 finished with value: 0.525060377833219 and parameters: {'n_estimators': 1316, 'max_depth': 55, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1.0, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 1 with value: 0.5658537401311388.\n",
      "2025-06-20 12:55:19,227 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 2, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:19,252 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 1...\n",
      "2025-06-20 12:55:20,996 - __main__ - INFO - \t Balanced Accuracy: 0.5203, F1 Score: 0.5203, ROC AUC: 0.5350\n",
      "2025-06-20 12:55:21,024 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 3, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:21,051 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 2...\n",
      "2025-06-20 12:55:22,844 - __main__ - INFO - \t Balanced Accuracy: 0.5862, F1 Score: 0.5583, ROC AUC: 0.5780\n",
      "[I 2025-06-20 12:55:22,936] Trial 4 finished with value: 0.5393229390989749 and parameters: {'n_estimators': 2528, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.5658537401311388.\n",
      "2025-06-20 12:55:22,945 - __main__ - INFO - Best hyperparameters for fold 1: {'n_estimators': 1000, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}\n",
      "2025-06-20 12:55:22,953 - __main__ - INFO - Best score: 0.5659\n",
      "2025-06-20 12:55:22,954 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "2025-06-20 12:55:22,979 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 12:55:22,980 - __main__ - INFO - Retraining Model on Outer Fold 1\n",
      "2025-06-20 12:55:23,790 - __main__ - INFO - \t Inference Time: 0.16435 seconds\n",
      "2025-06-20 12:55:23,794 - __main__ - INFO - \t Balanced Accuracy: 0.5452, F1 Score: 0.5453, ROC AUC: 0.6392\n",
      "2025-06-20 12:55:23,804 - __main__ - INFO - Outer Fold 2 - Train Indices: [ 0  1  2  3  4  5  7  8  9 13], Test Indices: [ 6 10 11 12 15 16 20 21 36 45]\n",
      "2025-06-20 12:55:23,804 - __main__ - INFO - -------------------- Outer Fold 2 --------------------\n",
      "2025-06-20 12:55:23,806 - __main__ - INFO - Starting hyperparameter optimization for outer fold 2...\n",
      "[I 2025-06-20 12:55:23,993] A new study created in RDB with name: 23381.2.random_forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "[[0.718 0.282]\n",
      " [0.568 0.432]\n",
      " [0.728 0.272]\n",
      " [0.879 0.121]\n",
      " [0.778 0.222]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 12:55:24,106 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 2, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:24,132 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 1...\n",
      "2025-06-20 12:55:24,836 - __main__ - INFO - \t Balanced Accuracy: 0.5948, F1 Score: 0.5954, ROC AUC: 0.6338\n",
      "2025-06-20 12:55:24,857 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 2, 3, 4, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:24,893 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 2...\n",
      "2025-06-20 12:55:25,595 - __main__ - INFO - \t Balanced Accuracy: 0.5429, F1 Score: 0.5418, ROC AUC: 0.5917\n",
      "[I 2025-06-20 12:55:25,823] Trial 0 finished with value: 0.568598765671143 and parameters: {'n_estimators': 1000, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 0 with value: 0.568598765671143.\n",
      "2025-06-20 12:55:25,908 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 2, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:25,934 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 1...\n",
      "2025-06-20 12:55:28,814 - __main__ - INFO - \t Balanced Accuracy: 0.5386, F1 Score: 0.5376, ROC AUC: 0.6045\n",
      "2025-06-20 12:55:28,846 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 2, 3, 4, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:28,873 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 2...\n",
      "2025-06-20 12:55:31,780 - __main__ - INFO - \t Balanced Accuracy: 0.5796, F1 Score: 0.5797, ROC AUC: 0.6226\n",
      "[I 2025-06-20 12:55:31,871] Trial 1 finished with value: 0.5586380832282472 and parameters: {'n_estimators': 3025, 'max_depth': 62, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 1.0, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 0 with value: 0.568598765671143.\n",
      "2025-06-20 12:55:31,961 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 2, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:31,987 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 1...\n",
      "2025-06-20 12:55:32,917 - __main__ - INFO - \t Balanced Accuracy: 0.5402, F1 Score: 0.5397, ROC AUC: 0.5655\n",
      "2025-06-20 12:55:32,938 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 2, 3, 4, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:32,964 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 2...\n",
      "2025-06-20 12:55:33,896 - __main__ - INFO - \t Balanced Accuracy: 0.6061, F1 Score: 0.6068, ROC AUC: 0.6240\n",
      "[I 2025-06-20 12:55:33,985] Trial 2 finished with value: 0.573263157342278 and parameters: {'n_estimators': 1316, 'max_depth': 55, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1.0, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 2 with value: 0.573263157342278.\n",
      "2025-06-20 12:55:34,085 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 2, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:34,110 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 1...\n",
      "2025-06-20 12:55:35,846 - __main__ - INFO - \t Balanced Accuracy: 0.5556, F1 Score: 0.5438, ROC AUC: 0.6347\n",
      "2025-06-20 12:55:35,875 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 2, 3, 4, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:35,901 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 2...\n",
      "2025-06-20 12:55:37,633 - __main__ - INFO - \t Balanced Accuracy: 0.6106, F1 Score: 0.5985, ROC AUC: 0.6723\n",
      "[I 2025-06-20 12:55:37,732] Trial 3 finished with value: 0.5711743915457694 and parameters: {'n_estimators': 2528, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 2 with value: 0.573263157342278.\n",
      "2025-06-20 12:55:37,887 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 2, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:37,912 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 1...\n",
      "2025-06-20 12:55:38,711 - __main__ - INFO - \t Balanced Accuracy: 0.5946, F1 Score: 0.5918, ROC AUC: 0.6634\n",
      "2025-06-20 12:55:38,731 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 2, 3, 4, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:38,757 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 2...\n",
      "2025-06-20 12:55:39,551 - __main__ - INFO - \t Balanced Accuracy: 0.5764, F1 Score: 0.5756, ROC AUC: 0.6590\n",
      "[I 2025-06-20 12:55:39,642] Trial 4 finished with value: 0.5836998117787955 and parameters: {'n_estimators': 1134, 'max_depth': 68, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 0.3, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 4 with value: 0.5836998117787955.\n",
      "2025-06-20 12:55:39,653 - __main__ - INFO - Best hyperparameters for fold 2: {'n_estimators': 1134, 'max_depth': 68, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 0.3, 'bootstrap': False, 'criterion': 'entropy'}\n",
      "2025-06-20 12:55:39,664 - __main__ - INFO - Best score: 0.5837\n",
      "2025-06-20 12:55:39,666 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "2025-06-20 12:55:39,691 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 12:55:39,691 - __main__ - INFO - Retraining Model on Outer Fold 2\n",
      "2025-06-20 12:55:40,609 - __main__ - INFO - \t Inference Time: 0.19319 seconds\n",
      "2025-06-20 12:55:40,613 - __main__ - INFO - \t Balanced Accuracy: 0.5546, F1 Score: 0.5464, ROC AUC: 0.5172\n",
      "2025-06-20 12:55:40,622 - __main__ - INFO - Outer Fold 3 - Train Indices: [ 0  2  3  4  5  6  7  9 10 11], Test Indices: [ 1  8 14 25 28 30 32 34 42 44]\n",
      "2025-06-20 12:55:40,622 - __main__ - INFO - -------------------- Outer Fold 3 --------------------\n",
      "2025-06-20 12:55:40,623 - __main__ - INFO - Starting hyperparameter optimization for outer fold 3...\n",
      "[I 2025-06-20 12:55:40,674] A new study created in RDB with name: 23381.3.random_forest\n",
      "2025-06-20 12:55:40,802 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "[[0.69411224 0.30588776]\n",
      " [0.42107445 0.57892555]\n",
      " [0.5047971  0.4952029 ]\n",
      " [0.56456505 0.43543495]\n",
      " [0.62189013 0.37810987]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:40,827 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 1...\n",
      "2025-06-20 12:55:41,521 - __main__ - INFO - \t Balanced Accuracy: 0.5942, F1 Score: 0.5945, ROC AUC: 0.6077\n",
      "2025-06-20 12:55:41,543 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [2, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:41,579 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 2...\n",
      "2025-06-20 12:55:42,274 - __main__ - INFO - \t Balanced Accuracy: 0.5359, F1 Score: 0.5355, ROC AUC: 0.5747\n",
      "[I 2025-06-20 12:55:42,356] Trial 0 finished with value: 0.5649742646709535 and parameters: {'n_estimators': 1000, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 0 with value: 0.5649742646709535.\n",
      "2025-06-20 12:55:42,443 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:42,468 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 1...\n",
      "2025-06-20 12:55:45,345 - __main__ - INFO - \t Balanced Accuracy: 0.6246, F1 Score: 0.6248, ROC AUC: 0.6453\n",
      "2025-06-20 12:55:45,378 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [2, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:45,404 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 2...\n",
      "2025-06-20 12:55:48,267 - __main__ - INFO - \t Balanced Accuracy: 0.5640, F1 Score: 0.5643, ROC AUC: 0.5710\n",
      "[I 2025-06-20 12:55:48,361] Trial 1 finished with value: 0.594527458869464 and parameters: {'n_estimators': 3025, 'max_depth': 62, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 1.0, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 1 with value: 0.594527458869464.\n",
      "2025-06-20 12:55:48,451 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:48,476 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 1...\n",
      "2025-06-20 12:55:49,409 - __main__ - INFO - \t Balanced Accuracy: 0.5798, F1 Score: 0.5784, ROC AUC: 0.5953\n",
      "2025-06-20 12:55:49,431 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [2, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:49,456 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 2...\n",
      "2025-06-20 12:55:50,389 - __main__ - INFO - \t Balanced Accuracy: 0.5232, F1 Score: 0.5207, ROC AUC: 0.5431\n",
      "[I 2025-06-20 12:55:50,467] Trial 2 finished with value: 0.5495433910086147 and parameters: {'n_estimators': 1316, 'max_depth': 55, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1.0, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 1 with value: 0.594527458869464.\n",
      "2025-06-20 12:55:50,554 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:50,579 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 1...\n",
      "2025-06-20 12:55:52,317 - __main__ - INFO - \t Balanced Accuracy: 0.5907, F1 Score: 0.5816, ROC AUC: 0.6336\n",
      "2025-06-20 12:55:52,347 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [2, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:52,374 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 2...\n",
      "2025-06-20 12:55:54,111 - __main__ - INFO - \t Balanced Accuracy: 0.5881, F1 Score: 0.5807, ROC AUC: 0.6059\n",
      "[I 2025-06-20 12:55:54,196] Trial 3 finished with value: 0.5811750282321952 and parameters: {'n_estimators': 2528, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.594527458869464.\n",
      "2025-06-20 12:55:54,283 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [0, 1, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:54,308 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 1...\n",
      "2025-06-20 12:55:55,106 - __main__ - INFO - \t Balanced Accuracy: 0.5965, F1 Score: 0.5969, ROC AUC: 0.6031\n",
      "2025-06-20 12:55:55,125 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [2, 4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:55,151 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 2...\n",
      "2025-06-20 12:55:55,953 - __main__ - INFO - \t Balanced Accuracy: 0.5587, F1 Score: 0.5587, ROC AUC: 0.6012\n",
      "[I 2025-06-20 12:55:56,036] Trial 4 finished with value: 0.577821838062248 and parameters: {'n_estimators': 1134, 'max_depth': 68, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 0.3, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 1 with value: 0.594527458869464.\n",
      "2025-06-20 12:55:56,045 - __main__ - INFO - Best hyperparameters for fold 3: {'n_estimators': 3025, 'max_depth': 62, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 1.0, 'bootstrap': True, 'criterion': 'entropy'}\n",
      "2025-06-20 12:55:56,054 - __main__ - INFO - Best score: 0.5945\n",
      "2025-06-20 12:55:56,055 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:56,080 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 12:55:56,081 - __main__ - INFO - Retraining Model on Outer Fold 3\n",
      "2025-06-20 12:55:59,310 - __main__ - INFO - \t Inference Time: 0.49536 seconds\n",
      "2025-06-20 12:55:59,314 - __main__ - INFO - \t Balanced Accuracy: 0.5222, F1 Score: 0.5098, ROC AUC: 0.5090\n",
      "2025-06-20 12:55:59,338 - __main__ - INFO - Outer Fold 4 - Train Indices: [ 0  1  2  3  4  6  8  9 10 11], Test Indices: [ 5  7 13 22 24 26 33 38 43 46]\n",
      "2025-06-20 12:55:59,338 - __main__ - INFO - -------------------- Outer Fold 4 --------------------\n",
      "2025-06-20 12:55:59,340 - __main__ - INFO - Starting hyperparameter optimization for outer fold 4...\n",
      "[I 2025-06-20 12:55:59,385] A new study created in RDB with name: 23381.4.random_forest\n",
      "2025-06-20 12:55:59,499 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 3, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:55:59,524 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "[[0.57535734 0.42464266]\n",
      " [0.42788587 0.57211413]\n",
      " [0.4520063  0.5479937 ]\n",
      " [0.64527548 0.35472452]\n",
      " [0.75331248 0.24668752]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 12:56:00,235 - __main__ - INFO - \t Balanced Accuracy: 0.5181, F1 Score: 0.5166, ROC AUC: 0.5655\n",
      "2025-06-20 12:56:00,256 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "2025-06-20 12:56:00,292 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 2...\n",
      "2025-06-20 12:56:01,001 - __main__ - INFO - \t Balanced Accuracy: 0.5423, F1 Score: 0.5388, ROC AUC: 0.5588\n",
      "[I 2025-06-20 12:56:01,094] Trial 0 finished with value: 0.5277140768944049 and parameters: {'n_estimators': 1000, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'}. Best is trial 0 with value: 0.5277140768944049.\n",
      "2025-06-20 12:56:01,193 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 3, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:56:01,218 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 1...\n",
      "2025-06-20 12:56:04,093 - __main__ - INFO - \t Balanced Accuracy: 0.5018, F1 Score: 0.4997, ROC AUC: 0.5420\n",
      "2025-06-20 12:56:04,126 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "2025-06-20 12:56:04,153 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 2...\n",
      "2025-06-20 12:56:07,020 - __main__ - INFO - \t Balanced Accuracy: 0.5542, F1 Score: 0.5520, ROC AUC: 0.5595\n",
      "[I 2025-06-20 12:56:07,109] Trial 1 finished with value: 0.525835418038183 and parameters: {'n_estimators': 3025, 'max_depth': 62, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 1.0, 'bootstrap': True, 'criterion': 'entropy'}. Best is trial 0 with value: 0.5277140768944049.\n",
      "2025-06-20 12:56:07,193 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 3, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:56:07,218 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 1...\n",
      "2025-06-20 12:56:08,147 - __main__ - INFO - \t Balanced Accuracy: 0.5148, F1 Score: 0.5119, ROC AUC: 0.4993\n",
      "2025-06-20 12:56:08,167 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "2025-06-20 12:56:08,193 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 2...\n",
      "2025-06-20 12:56:09,117 - __main__ - INFO - \t Balanced Accuracy: 0.5090, F1 Score: 0.5090, ROC AUC: 0.5353\n",
      "[I 2025-06-20 12:56:09,202] Trial 2 finished with value: 0.510417978367253 and parameters: {'n_estimators': 1316, 'max_depth': 55, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1.0, 'bootstrap': False, 'criterion': 'gini'}. Best is trial 0 with value: 0.5277140768944049.\n",
      "2025-06-20 12:56:09,294 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 3, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:56:09,319 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 1...\n",
      "2025-06-20 12:56:11,052 - __main__ - INFO - \t Balanced Accuracy: 0.5376, F1 Score: 0.4950, ROC AUC: 0.5638\n",
      "2025-06-20 12:56:11,084 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "2025-06-20 12:56:11,110 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 2...\n",
      "2025-06-20 12:56:12,847 - __main__ - INFO - \t Balanced Accuracy: 0.6176, F1 Score: 0.6031, ROC AUC: 0.5796\n",
      "[I 2025-06-20 12:56:12,939] Trial 3 finished with value: 0.5490327690552959 and parameters: {'n_estimators': 2528, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 3 with value: 0.5490327690552959.\n",
      "2025-06-20 12:56:13,030 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [1, 3, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:56:13,065 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 1...\n",
      "2025-06-20 12:56:13,871 - __main__ - INFO - \t Balanced Accuracy: 0.5273, F1 Score: 0.5270, ROC AUC: 0.5297\n",
      "2025-06-20 12:56:13,890 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "2025-06-20 12:56:13,926 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 2...\n",
      "2025-06-20 12:56:14,720 - __main__ - INFO - \t Balanced Accuracy: 0.5413, F1 Score: 0.5396, ROC AUC: 0.5530\n",
      "[I 2025-06-20 12:56:14,797] Trial 4 finished with value: 0.5332938247480432 and parameters: {'n_estimators': 1134, 'max_depth': 68, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 0.3, 'bootstrap': False, 'criterion': 'entropy'}. Best is trial 3 with value: 0.5490327690552959.\n",
      "2025-06-20 12:56:14,806 - __main__ - INFO - Best hyperparameters for fold 4: {'n_estimators': 2528, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'entropy'}\n",
      "2025-06-20 12:56:14,814 - __main__ - INFO - Best score: 0.5490\n",
      "2025-06-20 12:56:14,815 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [2, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:56:14,840 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 12:56:14,841 - __main__ - INFO - Retraining Model on Outer Fold 4\n",
      "2025-06-20 12:56:16,830 - __main__ - INFO - \t Inference Time: 0.41142 seconds\n",
      "2025-06-20 12:56:16,834 - __main__ - INFO - \t Balanced Accuracy: 0.6268, F1 Score: 0.6177, ROC AUC: 0.6154\n",
      "2025-06-20 12:56:16,853 - __main__ - INFO - Outer Fold 5 - Train Indices: [ 0  1  2  4  5  6  7  8 10 11], Test Indices: [ 3  9 17 23 29 31 37 40 41 54]\n",
      "2025-06-20 12:56:16,853 - __main__ - INFO - -------------------- Outer Fold 5 --------------------\n",
      "2025-06-20 12:56:16,854 - __main__ - INFO - Starting hyperparameter optimization for outer fold 5...\n",
      "[I 2025-06-20 12:56:16,912] A new study created in RDB with name: 23381.5.random_forest\n",
      "2025-06-20 12:56:17,026 - __main__ - INFO - Preprocessing pipeline for Decision Tree model.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "2025-06-20 12:56:17,051 - __main__ - INFO - Training Model on Outer Fold 5, Inner Fold 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "[[0.48244703 0.51755297]\n",
      " [0.75778255 0.24221745]\n",
      " [0.70486685 0.29513315]\n",
      " [0.66219377 0.33780623]\n",
      " [0.53412511 0.46587489]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-20 12:56:17,684] Trial 0 failed with parameters: {'n_estimators': 1000, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'criterion': 'gini'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_919100/2794929685.py\", line 187, in objective\n",
      "    model.train(X_inner_train, y_inner_train)\n",
      "  File \"/tmp/ipykernel_919100/2686699944.py\", line 1107, in train\n",
      "    self.model.fit(X, y)\n",
      "  File \"/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/mherre/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/home/mherre/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"/home/mherre/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-20 12:56:17,694] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 248\u001b[0m\n\u001b[1;32m    246\u001b[0m     default_hyperparams \u001b[38;5;241m=\u001b[39m suggest_hyperparameters(\u001b[38;5;28;01mNone\u001b[39;00m, model_type, task_type, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    247\u001b[0m     study\u001b[38;5;241m.\u001b[39menqueue_trial(default_hyperparams)\n\u001b[0;32m--> 248\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_hpo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe study has already reached the maximum number of trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[103], line 187\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    185\u001b[0m model \u001b[38;5;241m=\u001b[39m get_teacher_model(config\u001b[38;5;241m=\u001b[39mconfig, task_type\u001b[38;5;241m=\u001b[39mtask_type, device\u001b[38;5;241m=\u001b[39mdevice, hyperparams\u001b[38;5;241m=\u001b[39mhyperparams, cat_cols\u001b[38;5;241m=\u001b[39mcat_cols)\n\u001b[1;32m    186\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Model on Outer Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mouter_fold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Inner Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 187\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_inner_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_inner_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# VALIDATION: Evaluate model performance on inner validation set\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    192\u001b[0m val_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_inner_val)\n",
      "Cell \u001b[0;32mIn[99], line 1107\u001b[0m, in \u001b[0;36mRandomForestTeacherModel.train\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[1;32m   1101\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[1;32m   1102\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Use all available CPU cores\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparams,\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m-> 1107\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get list of datasets to process from configuration\n",
    "datasets = config[\"data\"][\"datasets\"]\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN TRAINING LOOP - Process each dataset independently\n",
    "# =============================================================================\n",
    "for dataset_id in datasets:\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SETUP AND INITIALIZATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    logger = setup_logging()\n",
    "    logger.info(\"Loading configuration...\")\n",
    "\n",
    "    # Extract model configuration for this run\n",
    "    model_type = config[\"model\"][\"teacher_model\"]\n",
    "    preprocessing_type = config[\"teacher_models\"][model_type][\"preprocessing\"]\n",
    "    use_hpo = config[\"training\"][\"use_hpo\"]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 0: DATA LOADING\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Load dataset from OpenML with caching for efficiency\n",
    "    X, y, cat_cols, _, task_type = load_dataset(\n",
    "        dataset_id=dataset_id,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 1: INFRASTRUCTURE SETUP\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Note: Checking for existing results is placeholder for future implementation\n",
    "    summary_file = os.path.join(config[\"data\"][\"results_dir_path\"], \"teacher\", f\"{dataset_id}_results.json\")\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file, 'r') as f:\n",
    "            existing_results = json.load(f)\n",
    "        \n",
    "        # Check if we already have results with the same configuration\n",
    "        config_exists = False\n",
    "        for key, result in existing_results.items():\n",
    "            if (result.get('model_type') == model_type and \n",
    "                result.get('use_hpo') == use_hpo and \n",
    "                result.get('seed') == config[\"training\"][\"random_state\"]):\n",
    "                config_exists = True\n",
    "                logger.info(f\"Results already exist for dataset {dataset_id} with model {model_type}, HPO: {use_hpo}, seed: {config['training']['random_state']}\")\n",
    "                break\n",
    "        \n",
    "        if config_exists:\n",
    "            logger.info(f\"Skipping dataset {dataset_id} - results already computed\")\n",
    "            continue\n",
    "\n",
    "    # Configure GPU/CPU usage for training\n",
    "    device = check_GPU_availability()\n",
    "\n",
    "    # Set random seed for reproducibility across all libraries\n",
    "    set_seed(config[\"training\"][\"random_state\"])\n",
    "    logger.info(f\"Random seed set to {config['training']['random_state']}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 2: INITIALIZE DATA STRUCTURES\n",
    "    # -------------------------------------------------------------------------\n",
    "    # List to store predictions from each outer fold\n",
    "    outer_fold_scores = []\n",
    "    \n",
    "    # Dictionary to store all fold indices for reproducibility and student training\n",
    "    # Structure: {\"outer_folds\": {fold_id: {train_idx, test_idx}},\n",
    "    #            \"inner_folds\": {outer_fold_id: {inner_fold_id: {train_idx, val_idx}}}}\n",
    "    fold_indices = {\n",
    "        \"outer_folds\": {},\n",
    "        \"inner_folds\": {}\n",
    "    }\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 3: OUTER CROSS-VALIDATION SETUP\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Choose appropriate CV strategy based on task type to maintain class balance\n",
    "    if task_type == \"binary\":\n",
    "        outer_cv = StratifiedKFold(\n",
    "            n_splits=config[\"training\"][\"outer_folds\"],\n",
    "            shuffle=True,\n",
    "            random_state=config[\"training\"][\"random_state\"],\n",
    "        )\n",
    "    else:\n",
    "        outer_cv = KFold(\n",
    "            n_splits=config[\"training\"][\"outer_folds\"],\n",
    "            shuffle=True,\n",
    "            random_state=config[\"training\"][\"random_state\"],\n",
    "        )\n",
    "\n",
    "    # =========================================================================\n",
    "    # STEP 4: OUTER CROSS-VALIDATION LOOP\n",
    "    # =========================================================================\n",
    "    # Each iteration provides one unbiased performance estimate\n",
    "    for outer_fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), start=1):\n",
    "\n",
    "        # Log the first 10 indices of the outer fold for debugging\n",
    "        logger.info(f\"Outer Fold {outer_fold} - Train Indices: {train_idx[:10]}, Test Indices: {test_idx[:10]}\")\n",
    "\n",
    "        logger.info(f\"-------------------- Outer Fold {outer_fold} --------------------\")\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # FOLD INDEX MANAGEMENT\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Store outer fold indices for later use in student training and validation\n",
    "        fold_indices[\"outer_folds\"][f\"fold_{outer_fold}\"] = {\n",
    "            \"train_idx\": train_idx.tolist(),\n",
    "            \"test_idx\": test_idx.tolist()\n",
    "        }\n",
    "\n",
    "        # Split data according to current outer fold\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # INNER CROSS-VALIDATION SETUP (for model validation)\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Choose appropriate CV strategy for inner folds\n",
    "        if task_type == \"binary\":\n",
    "            inner_cv = StratifiedKFold(\n",
    "                n_splits=config[\"training\"][\"inner_folds\"],\n",
    "                shuffle=True,\n",
    "                random_state=config[\"training\"][\"random_state\"],\n",
    "            )\n",
    "        else:\n",
    "            inner_cv = KFold(\n",
    "                n_splits=config[\"training\"][\"inner_folds\"],\n",
    "                shuffle=True,\n",
    "                random_state=config[\"training\"][\"random_state\"],\n",
    "            )\n",
    "        \n",
    "        # Initialize storage for inner fold indices within this outer fold\n",
    "        fold_indices[\"inner_folds\"][f\"outer_fold_{outer_fold}\"] = {}\n",
    "\n",
    "        # =====================================================================\n",
    "        # STEP 5: INNER CROSS-VALIDATION LOOP (hyperparameter validation) \n",
    "        # =====================================================================\n",
    "        def objective(trial):\n",
    "\n",
    "            hyperparams = suggest_hyperparameters(\n",
    "                trial=trial,\n",
    "                model_type=model_type,\n",
    "                task_type=task_type,\n",
    "                use_hpo=use_hpo,\n",
    "            )\n",
    "\n",
    "            inner_fold_scores = []\n",
    "            val_metrics_list = []\n",
    "\n",
    "            # This loop would typically be used for hyperparameter optimization\n",
    "            for inner_fold, (inner_train_index, inner_val_index) in enumerate(inner_cv.split(X_train, y_train), start=1):\n",
    "                \n",
    "                # -----------------------------------------------------------------\n",
    "                # INDEX MANAGEMENT (Critical for avoiding data leakage)\n",
    "                # -----------------------------------------------------------------\n",
    "                # Convert relative indices (within outer training set) to absolute indices\n",
    "                absolute_inner_train_idx = train_idx[inner_train_index]\n",
    "                absolute_inner_val_idx = train_idx[inner_val_index]\n",
    "                \n",
    "                # Store inner fold indices using absolute indices for consistency\n",
    "                # Only store indices for the first trial\n",
    "                if trial.number == 0:  \n",
    "                    fold_indices[\"inner_folds\"][f\"outer_fold_{outer_fold}\"][f\"inner_fold_{inner_fold}\"] = {\n",
    "                        \"train_idx\": absolute_inner_train_idx.tolist(),\n",
    "                        \"val_idx\": absolute_inner_val_idx.tolist()\n",
    "                    }\n",
    "\n",
    "                # Split inner training data using relative indices\n",
    "                X_inner_train, X_inner_val = X_train.iloc[inner_train_index], X_train.iloc[inner_val_index]\n",
    "                y_inner_train, y_inner_val = y_train[inner_train_index], y_train[inner_val_index]\n",
    "\n",
    "                # -----------------------------------------------------------------\n",
    "                # PREPROCESSING: Apply model-specific data transformations\n",
    "                # -----------------------------------------------------------------\n",
    "                X_inner_train, X_inner_val = preprocess(\n",
    "                    X_inner_train,\n",
    "                    y_inner_train,\n",
    "                    X_inner_val, \n",
    "                    cat_cols,\n",
    "                    config,\n",
    "                    preprocessing_type=preprocessing_type,\n",
    "                )\n",
    "\n",
    "                # -----------------------------------------------------------------\n",
    "                # MODEL TRAINING: Train teacher model on inner training data\n",
    "                # -----------------------------------------------------------------\n",
    "                model = get_teacher_model(config=config, task_type=task_type, device=device, hyperparams=hyperparams, cat_cols=cat_cols)\n",
    "                logger.info(f\"Training Model on Outer Fold {outer_fold}, Inner Fold {inner_fold}...\")\n",
    "                model.train(X_inner_train, y_inner_train)\n",
    "\n",
    "                # -----------------------------------------------------------------\n",
    "                # VALIDATION: Evaluate model performance on inner validation set\n",
    "                # -----------------------------------------------------------------\n",
    "                val_preds = model.predict(X_inner_val)\n",
    "                val_metrics = model.evaluate(val_preds, y_inner_val)\n",
    "\n",
    "                # Store metrics from this fold for later mean calculation\n",
    "                val_metrics_list.append(val_metrics)\n",
    "\n",
    "                if task_type == \"binary\":\n",
    "                    inner_fold_scores.append(val_metrics[\"f1\"])\n",
    "                    trial.report(np.mean(inner_fold_scores), step=inner_fold)\n",
    "                else:\n",
    "                    inner_fold_scores.append(-val_metrics[\"mae\"])\n",
    "                    trial.report(np.mean(inner_fold_scores), step=inner_fold)\n",
    "\n",
    "                # Check if the trial should be pruned (With 2 inner folds, pruning not recommended)\n",
    "                # if trial.should_prune():\n",
    "                #     logger.info(\"Trial pruned.\")\n",
    "                #     raise optuna.TrialPruned()\n",
    "\n",
    "            # Calculate and set mean metrics as user attributes after all inner folds\n",
    "            if val_metrics_list:\n",
    "                # Get all metric keys from the first fold\n",
    "                metric_keys = val_metrics_list[0].keys()\n",
    "                \n",
    "                for metric_key in metric_keys:\n",
    "                    # Calculate mean across all inner folds for this metric\n",
    "                    metric_values = [fold_metrics[metric_key] for fold_metrics in val_metrics_list]\n",
    "                    mean_metric = np.mean(metric_values)\n",
    "                    trial.set_user_attr(f\"mean_{metric_key}\", mean_metric)\n",
    "\n",
    "            return np.mean(inner_fold_scores)\n",
    "            \n",
    "        logger.info(f\"Starting hyperparameter optimization for outer fold {outer_fold}...\")\n",
    "\n",
    "        study_kwargs = dict(\n",
    "            direction=\"maximize\",\n",
    "            study_name=f\"{dataset_id}.{outer_fold}.{model_type}\",\n",
    "            load_if_exists=True,\n",
    "            sampler=optuna.samplers.TPESampler(seed=config[\"training\"][\"random_state\"]),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=1),\n",
    "        )\n",
    "\n",
    "        if use_hpo:\n",
    "            os.makedirs(config[\"data\"][\"optuna_db_path\"], exist_ok=True)\n",
    "            study_kwargs[\"storage\"] = f\"sqlite:///{config['data']['optuna_db_path']}/optuna.db\"\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            **study_kwargs,\n",
    "        )\n",
    "\n",
    "        # Optimize\n",
    "        completed_trials = len(study.trials)\n",
    "        remaining_trials = config[\"training\"][\"trials\"] - completed_trials\n",
    "\n",
    "        if remaining_trials > 0:\n",
    "            default_hyperparams = suggest_hyperparameters(None, model_type, task_type, False)\n",
    "            study.enqueue_trial(default_hyperparams)\n",
    "            study.optimize(\n",
    "                objective, \n",
    "                n_trials=remaining_trials if use_hpo else 1,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"The study has already reached the maximum number of trials.\")\n",
    "\n",
    "        if use_hpo:\n",
    "            # When HPO is used, trial.suggest_ methods are called, populating trial.params\n",
    "            best_hyperparams = study.best_trial.params \n",
    "        else:\n",
    "            # When not using HPO, a single trial runs with default parameters.\n",
    "            best_hyperparams = suggest_hyperparameters(trial=None, model_type=model_type, task_type=task_type, use_hpo=False)\n",
    "\n",
    "        logger.info(f\"Best hyperparameters for fold {outer_fold}: {best_hyperparams}\")\n",
    "        logger.info(f\"Best score: {study.best_value:.4f}\")\n",
    "\n",
    "        # =====================================================================\n",
    "        # STEP 6: FINAL MODEL TRAINING (on complete outer training set)\n",
    "        # =====================================================================        \n",
    "        # Apply same preprocessing to outer training and test sets\n",
    "        X_train, X_test = preprocess(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            cat_cols,\n",
    "            config,\n",
    "            preprocessing_type=preprocessing_type,  \n",
    "        )\n",
    "        \n",
    "        # Train final model on complete outer training set\n",
    "        logger.info(\"------------------------------------------------------\")\n",
    "        logger.info(f\"Retraining Model on Outer Fold {outer_fold}\")\n",
    "\n",
    "        model = get_teacher_model(\n",
    "            config=config,\n",
    "            task_type=task_type,\n",
    "            device=device,\n",
    "            hyperparams=best_hyperparams,  # Use best hyperparameters from HPO\n",
    "            cat_cols=cat_cols,  \n",
    "        )\n",
    "        model.train(X_train, y_train)\n",
    "\n",
    "        # =====================================================================\n",
    "        # STEP 7: FINAL EVALUATION (unbiased performance on outer test set)\n",
    "        # =====================================================================\n",
    "        # This provides the unbiased performance estimate for this fold\n",
    "        start_time = time.time()\n",
    "        test_preds = model.predict(X_test)\n",
    "        train_preds = model.predict(X_train)\n",
    "        end_time = time.time() - start_time\n",
    "        logger.info(f\"\\t Inference Time: {end_time:.5f} seconds\")\n",
    "        test_metrics = model.evaluate(test_preds, y_test)\n",
    "\n",
    "        # Store outer fold score for later analysis\n",
    "        outer_fold_results = {\n",
    "            \"fold\": outer_fold,\n",
    "            \"seed\": config[\"training\"][\"random_state\"],\n",
    "            \"inference_time\": end_time,\n",
    "            **test_metrics,\n",
    "        }\n",
    "        outer_fold_scores.append(outer_fold_results)\n",
    "\n",
    "        # Store predictions in fold indices\n",
    "        fold_indices[\"outer_folds\"][f\"fold_{outer_fold}\"][\"train_preds\"] = train_preds[:, 1].tolist() if task_type == \"binary\" else train_preds.tolist()\n",
    "        fold_indices[\"outer_folds\"][f\"fold_{outer_fold}\"][\"test_preds\"] = test_preds[:, 1].tolist() if task_type == \"binary\" else test_preds.tolist()\n",
    "\n",
    "    # =========================================================================\n",
    "    # STEP 9: SAVE RESULTS AND METADATA\n",
    "    # =========================================================================\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE OUTER FOLD METRICS\n",
    "    # -------------------------------------------------------------------------\n",
    "    outer_fold_df = pd.DataFrame(outer_fold_scores)\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    output_dir = os.path.join(config[\"data\"][\"outer_folds_path\"], \"teacher\", sub_folder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    metrics_file = os.path.join(output_dir, f\"{dataset_id}_{model_type}.csv\")\n",
    "    outer_fold_df.to_csv(metrics_file, index=False)\n",
    "    logger.info(f\"Outer fold metrics saved to: {metrics_file}\")\n",
    "\n",
    "    # Calculate and log overall performance across all folds\n",
    "    mean_inference_time = outer_fold_df['inference_time'].mean()\n",
    "    std_inference_time = outer_fold_df['inference_time'].std()\n",
    "    mean_parameters = outer_fold_df['parameters'].mean()\n",
    "    std_parameters = outer_fold_df['parameters'].std()\n",
    "\n",
    "    if task_type == \"binary\":\n",
    "        mean_acc = outer_fold_df['acc'].mean()\n",
    "        std_acc = outer_fold_df['acc'].std()\n",
    "        mean_f1 = outer_fold_df['f1'].mean()\n",
    "        std_f1 = outer_fold_df['f1'].std()\n",
    "        mean_roc = outer_fold_df['roc'].mean()\n",
    "        std_roc = outer_fold_df['roc'].std()\n",
    "        \n",
    "        logger.info(f\"=== FINAL RESULTS FOR DATASET {dataset_id} ===\")\n",
    "        logger.info(f\"Balanced Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "        logger.info(f\"F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "        logger.info(f\"ROC AUC: {mean_roc:.4f} ± {std_roc:.4f}\")\n",
    "    else:\n",
    "        mean_mae = outer_fold_df['mae'].mean()\n",
    "        std_mae = outer_fold_df['mae'].std()\n",
    "        mean_mse = outer_fold_df['mse'].mean()\n",
    "        std_mse = outer_fold_df['mse'].std()\n",
    "        mean_rmse = outer_fold_df['rmse'].mean()\n",
    "        std_rmse = outer_fold_df['rmse'].std()\n",
    "        mean_r2 = outer_fold_df['r2'].mean()\n",
    "        std_r2 = outer_fold_df['r2'].std()\n",
    "\n",
    "        \n",
    "        logger.info(f\"=== FINAL RESULTS FOR DATASET {dataset_id} ===\")\n",
    "        logger.info(f\"MAE: {mean_mae:.4f} ± {std_mae:.4f}\")\n",
    "        logger.info(f\"MSE: {mean_mse:.4f} ± {std_mse:.4f}\")\n",
    "        logger.info(f\"RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "        logger.info(f\"R2: {mean_r2:.4f} ± {std_r2:.4f}\")\n",
    "    \n",
    "    logger.info(f\"Mean Inference Time: {mean_inference_time:.4f} ± {std_inference_time:.4f}\")\n",
    "    logger.info(f\"Mean Parameters: {mean_parameters:.4f} ± {std_parameters:.4f}\")\n",
    "\n",
    "    # Save summary statistics as well\n",
    "    summary_stats = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"task_type\": task_type,\n",
    "        \"seed\": config[\"training\"][\"random_state\"],\n",
    "        \"use_hpo\": config[\"training\"][\"use_hpo\"],\n",
    "        \"mean_inference_time\": mean_inference_time,\n",
    "        \"std_inference_time\": std_inference_time,\n",
    "        \"mean_parameters\": mean_parameters,\n",
    "        \"std_parameters\": std_parameters,\n",
    "    }\n",
    "\n",
    "    if task_type == \"binary\":\n",
    "        summary_stats.update({\n",
    "            \"mean_acc\": mean_acc,\n",
    "            \"std_acc\": std_acc,\n",
    "            \"mean_f1\": mean_f1,\n",
    "            \"std_f1\": std_f1,\n",
    "            \"mean_roc\": mean_roc,\n",
    "            \"std_roc\": std_roc,\n",
    "        })\n",
    "    else:\n",
    "        summary_stats.update({\n",
    "            \"mean_mae\": mean_mae,\n",
    "            \"std_mae\": std_mae,\n",
    "            \"mean_mse\": mean_mse,\n",
    "            \"std_mse\": std_mse,\n",
    "            \"mean_rmse\": mean_rmse,\n",
    "            \"std_rmse\": std_rmse,\n",
    "            \"mean_r2\": mean_r2,\n",
    "            \"std_r2\": std_r2,\n",
    "        })\n",
    "\n",
    "    # Load existing summary file if it exists, otherwise create new\n",
    "    summary_file = os.path.join(config[\"data\"][\"results_dir_path\"], \"teacher\", f\"{dataset_id}_results.json\")\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(summary_file), exist_ok=True)\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file, 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "    else:\n",
    "        all_results = {}\n",
    "\n",
    "    # Add current model results to the dataset summary\n",
    "    # Use simple incremental numbering\n",
    "    next_num = len(all_results) + 1\n",
    "    model_key = str(next_num)\n",
    "\n",
    "    # Add current model results to the dataset summary\n",
    "    all_results[model_key] = summary_stats\n",
    "\n",
    "    # Save updated summary\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    logger.info(f\"Summary statistics saved to: {summary_file}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE FOLD INDICES (for reproducibility and student training)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Create the full directory structure\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    output_dir = os.path.join(config[\"data\"][\"fold_indices_path\"], sub_folder, \"teacher\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_file = os.path.join(output_dir, f\"{dataset_id}_{model_type}.json\")\n",
    "\n",
    "    if not os.path.exists(output_file):\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(fold_indices, f, indent=2)\n",
    "        logger.info(f\"Fold indices saved to: {output_file}\")\n",
    "    else:\n",
    "        logger.info(f\"Fold indices file already exists: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1e150",
   "metadata": {},
   "source": [
    "# Train Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1289fc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 13:10:51,366 - __main__ - INFO - Loading configuration...\n",
      "2025-06-20 13:10:51,367 - __main__ - INFO - Loading dataset 23381 from cache at 'data/cache/openml_dataset_23381.pkl'...\n",
      "2025-06-20 13:10:51,369 - __main__ - INFO - Dataset 23381 loaded successfully with task type: binary\n",
      "2025-06-20 13:10:51,369 - __main__ - INFO - Using GPU: NVIDIA RTX A6000\n",
      "2025-06-20 13:10:51,371 - __main__ - INFO - Random seed set to 42\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/fold_indices/dataset_23381.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 68\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# STEP 2: LOAD PREVIOUSLY SAVED FOLD INDICES AND TEACHER PREDICTIONS\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Load the saved fold indices \u001b[39;00m\n\u001b[1;32m     67\u001b[0m fold_indices_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_indices_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfold_indices_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     69\u001b[0m     fold_indices \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     70\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded fold indices from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_indices_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/fold_indices/dataset_23381.json'"
     ]
    }
   ],
   "source": [
    "# Get list of datasets to process from configuration\n",
    "datasets = config[\"data\"][\"datasets\"]\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN TRAINING LOOP - Process each dataset independently\n",
    "# =============================================================================\n",
    "for dataset_id in datasets:\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SETUP AND INITIALIZATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    logger = setup_logging()\n",
    "    logger.info(\"Loading configuration...\")\n",
    "\n",
    "    # Extract model configuration for this run\n",
    "    student_model_type = config[\"model\"][\"student_model\"]\n",
    "    teacher_model_type = config[\"model\"][\"teacher_model\"]\n",
    "    preprocessing_type = config[\"student_models\"][student_model_type][\"preprocessing\"]\n",
    "    use_hpo = config[\"training\"][\"use_hpo\"]\n",
    "    train_on_logits = config[\"training\"][\"train_on_logits\"]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 0: DATA LOADING\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Load dataset from OpenML with caching for efficiency\n",
    "    X, y, cat_cols, _, original_task_type = load_dataset(\n",
    "        dataset_id=dataset_id,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 1: INFRASTRUCTURE SETUP\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Note: Checking for existing results is placeholder for future implementation\n",
    "    model_task_type = \"binary\" if (original_task_type == \"binary\" and not train_on_logits) else \"regression\"\n",
    "    summary_file = os.path.join(config[\"data\"][\"results_dir_path\"], \"student\", f\"{dataset_id}_results.json\")\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file, 'r') as f:\n",
    "            existing_results = json.load(f)\n",
    "        \n",
    "        # Check if we already have results with the same configuration\n",
    "        config_exists = False\n",
    "        for key, result in existing_results.items():\n",
    "            if (result.get('student_model_type') == student_model_type and \n",
    "                result.get('teacher_model_type') == teacher_model_type and\n",
    "                result.get('student_task_type') == model_task_type and\n",
    "                result.get('use_hpo') == use_hpo and \n",
    "                result.get('seed') == config[\"training\"][\"random_state\"]):\n",
    "                config_exists = True\n",
    "                logger.info(f\"Results already exist for dataset {dataset_id} with model {student_model_type}({teacher_model_type}), HPO: {use_hpo}, seed: {config['training']['random_state']}\")\n",
    "                break\n",
    "        \n",
    "        if config_exists:\n",
    "            logger.info(f\"Skipping dataset {dataset_id} - results already computed\")\n",
    "            continue\n",
    "\n",
    "    # Configure GPU/CPU usage for training\n",
    "    device = check_GPU_availability()\n",
    "\n",
    "    # Set random seed for reproducibility across all libraries\n",
    "    set_seed(config[\"training\"][\"random_state\"])\n",
    "    logger.info(f\"Random seed set to {config['training']['random_state']}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 2: LOAD PREVIOUSLY SAVED FOLD INDICES AND TEACHER PREDICTIONS\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Load the saved fold indices \n",
    "    fold_indices_file = os.path.join(config[\"data\"][\"fold_indices_path\"], f\"dataset_{dataset_id}.json\")\n",
    "    with open(fold_indices_file, 'r') as f:\n",
    "        fold_indices = json.load(f)\n",
    "    logger.info(f\"Loaded fold indices from: {fold_indices_file}\") \n",
    "\n",
    "    # Load the TabPFN outputs (teacher predictions)\n",
    "    subfolder = \"hpo\" if config[\"training\"][\"use_hpo\"] else \"default\"\n",
    "    directory = os.path.join(config[\"data\"][\"output_dir_path\"], subfolder, \"teacher\")\n",
    "    teacher_outputs_file = os.path.join(directory, f\"{dataset_id}_{teacher_model_type}.csv\")\n",
    "    teacher_outputs_df = pd.read_csv(teacher_outputs_file)\n",
    "    logger.info(f\"Loaded {teacher_model_type} outputs from: {teacher_outputs_file}\")\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # STEP 3: PREPROCESS TEACHER OUTPUTS\n",
    "    # --------------------------------------------------------------------------\n",
    "    if original_task_type == \"regression\":\n",
    "        model_task_type = \"regression\"\n",
    "        # For regression, we can use the outputs directly as they are already numeric\n",
    "        teacher_preds = teacher_outputs_df['output'].astype(float)\n",
    "        # Create a mapping from index to outputs for easy lookup\n",
    "        index_to_outputs = dict(zip(teacher_outputs_df['index'].values, teacher_preds))\n",
    "\n",
    "    else:\n",
    "        if train_on_logits:\n",
    "            model_task_type = \"regression\"\n",
    "            # Convert probabilities to logits\n",
    "            # Clip probabilities to avoid log(0) or log(1)\n",
    "            eps = 1e-7\n",
    "            teacher_probs = np.clip(teacher_outputs_df['output'].values, eps, 1 - eps)\n",
    "            teacher_logits = np.log(teacher_probs / (1 - teacher_probs))\n",
    "            # Create a mapping from index to logits for easy lookup\n",
    "            index_to_outputs = dict(zip(teacher_outputs_df['index'].values, teacher_logits))\n",
    "        else:\n",
    "            model_task_type = \"binary\"\n",
    "            # Convert probabilities to binary predictions\n",
    "            teacher_preds = (teacher_outputs_df['output'].values > 0.5).astype(int)\n",
    "            # Create a mapping from index to predictions for easy lookup\n",
    "            index_to_outputs = dict(zip(teacher_outputs_df['index'].values, teacher_preds))\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 4: INITIALIZE DATA STRUCTURES\n",
    "    # -------------------------------------------------------------------------\n",
    "    output_dfs = []\n",
    "\n",
    "    outer_fold_scores = []\n",
    "\n",
    "    # =========================================================================\n",
    "    # STEP 5: OUTER CROSS-VALIDATION LOOP\n",
    "    # =========================================================================\n",
    "    # Each iteration provides one unbiased performance estimate\n",
    "    for fold_key, fold_data in fold_indices[\"outer_folds\"].items():\n",
    "\n",
    "        # Extract outer fold number and indices from the fold key\n",
    "        outer_fold = int(fold_key.split('_')[1])\n",
    "        train_idx = np.array(fold_data[\"train_idx\"])\n",
    "        test_idx = np.array(fold_data[\"test_idx\"])\n",
    "\n",
    "        # Log the first 10 indices of the outer fold for debugging\n",
    "        logger.info(f\"Outer Fold {outer_fold} - Train Indices: {train_idx[:10]}, Test Indices: {test_idx[:10]}\")\n",
    "\n",
    "        logger.info(f\"-------------------- Outer Fold {outer_fold} --------------------\")\n",
    "\n",
    "        # Split data according to current outer fold\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # INNER CROSS-VALIDATION SETUP (for model validation)\n",
    "        # ---------------------------------------------------------------------\n",
    "        inner_folds_data = fold_indices[\"inner_folds\"][f\"outer_fold_{outer_fold}\"]\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 6: INNER CROSS-VALIDATION LOOP (hyperparameter validation)\n",
    "        # =========================================================================\n",
    "        def objective(trial):\n",
    "            \n",
    "            hyperparams = suggest_hyperparameters(\n",
    "                trial=trial,\n",
    "                model_type=student_model_type,\n",
    "                task_type=model_task_type,\n",
    "                use_hpo=use_hpo,\n",
    "            )\n",
    "\n",
    "            inner_fold_scores = []\n",
    "            val_metrics_list = []\n",
    "\n",
    "            # This loop would typically be used for hyperparameter optimization\n",
    "            for inner_fold_key, inner_fold_data in inner_folds_data.items():\n",
    "                inner_fold = int(inner_fold_key.split('_')[2])\n",
    "                \n",
    "                # -----------------------------------------------------------------\n",
    "                # INDEX MANAGEMENT (Critical for avoiding data leakage)\n",
    "                # -----------------------------------------------------------------\n",
    "                # Get absolute indices from saved data\n",
    "                absolute_inner_train_idx = np.array(inner_fold_data[\"train_idx\"])\n",
    "                absolute_inner_val_idx = np.array(inner_fold_data[\"val_idx\"])\n",
    "                \n",
    "                # Convert absolute indices to relative indices for the current outer training set\n",
    "                inner_train_relative = np.where(np.isin(train_idx, absolute_inner_train_idx))[0]\n",
    "                inner_val_relative = np.where(np.isin(train_idx, absolute_inner_val_idx))[0] \n",
    "\n",
    "                # Split inner training data using relative indices\n",
    "                X_inner_train, X_inner_val = X_train.iloc[inner_train_relative], X_train.iloc[inner_val_relative]\n",
    "                y_inner_train, y_inner_val = y_train[inner_train_relative], y_train[inner_val_relative] # Hard labels or Regression targets\n",
    "\n",
    "                # Get teacher outputs for inner training and validation sets\n",
    "                teacher_outputs_inner_train = np.array([index_to_outputs[idx] for idx in absolute_inner_train_idx])\n",
    "                teacher_outputs_inner_val = np.array([index_to_outputs[idx] for idx in absolute_inner_val_idx]) # Probs or Regression logits\n",
    "\n",
    "                # ---------------------------------------------------------------------\n",
    "                # PREPROCESSING: Apply model-specific data transformations\n",
    "                # ---------------------------------------------------------------------\n",
    "                X_inner_train, X_inner_val = preprocess(\n",
    "                    X_inner_train,\n",
    "                    y_inner_train,\n",
    "                    X_inner_val, \n",
    "                    cat_cols,\n",
    "                    config,\n",
    "                    preprocessing_type=preprocessing_type,\n",
    "                )\n",
    "                # ----------------------------------------------------------------------\n",
    "                # MODEL TRAINING: Train student model on inner training data\n",
    "                # ----------------------------------------------------------------------\n",
    "                model = get_student_model(config=config, task_type=model_task_type, device=device, hyperparams=hyperparams, cat_cols=cat_cols)\n",
    "                logger.info(f\"Training Model on Outer Fold {outer_fold}, Inner Fold {inner_fold}...\")\n",
    "                model.train(X_inner_train, teacher_outputs_inner_train)\n",
    "\n",
    "                # ----------------------------------------------------------------------\n",
    "                # VALIDATION: Evaluate model performance on inner validation set\n",
    "                # ----------------------------------------------------------------------\n",
    "                val_preds = model.predict(X_inner_val) # Probs or Regression logits\n",
    "                val_metrics = model.evaluate(y_pred=val_preds, y_true=y_inner_val, y_teacher_true=teacher_outputs_inner_val, original_task_type=original_task_type)\n",
    "\n",
    "                # Store metrics from this fold for later mean calculation\n",
    "                val_metrics_list.append(val_metrics)\n",
    "\n",
    "                if model_task_type == \"binary\":\n",
    "                    inner_fold_scores.append(val_metrics[\"fidelity_f1\"])\n",
    "                    trial.report(np.mean(inner_fold_scores), step=inner_fold)\n",
    "                else:\n",
    "                    inner_fold_scores.append(-val_metrics[\"fidelity_mae\"])\n",
    "                    trial.report(np.mean(inner_fold_scores), step=inner_fold)\n",
    "\n",
    "            # Calculate mean metrics as user attributes after all inner folds\n",
    "            if val_metrics_list:\n",
    "                # Get all metric keys from the first fold\n",
    "                metric_keys = val_metrics_list[0].keys()\n",
    "                \n",
    "                for metric_key in metric_keys:\n",
    "                    # Calculate mean across all inner folds for this metric\n",
    "                    metric_values = [fold_metrics[metric_key] for fold_metrics in val_metrics_list]\n",
    "                    mean_metric = np.mean(metric_values)\n",
    "                    trial.set_user_attr(f\"mean_{metric_key}\", mean_metric)\n",
    "\n",
    "            return np.mean(inner_fold_scores)\n",
    "        \n",
    "        logger.info(f\"Starting hyperparameter optimization for outer fold {outer_fold}...\")\n",
    "\n",
    "        study_kwargs = dict(\n",
    "            direction=\"maximize\",\n",
    "            study_name=f\"{dataset_id}.{outer_fold}.{student_model_type}({teacher_model_type}).{model_task_type[:2]}.{original_task_type[:2]}\",\n",
    "            load_if_exists=True,\n",
    "            sampler=optuna.samplers.TPESampler(seed=config[\"training\"][\"random_state\"]),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=1),\n",
    "        )\n",
    "\n",
    "        if use_hpo:\n",
    "            os.makedirs(config[\"data\"][\"optuna_db_path\"], exist_ok=True)\n",
    "            study_kwargs[\"storage\"] = f\"sqlite:///{config['data']['optuna_db_path']}/optuna.db\"\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            **study_kwargs,\n",
    "        )\n",
    "\n",
    "        # Optimize\n",
    "        completed_trials = len(study.trials)\n",
    "        remaining_trials = config[\"training\"][\"trials\"] - completed_trials\n",
    "\n",
    "\n",
    "        if remaining_trials > 0:\n",
    "            default_hyperparams = suggest_hyperparameters(None, student_model_type, model_task_type, False)\n",
    "            study.enqueue_trial(default_hyperparams)\n",
    "            study.optimize(\n",
    "                objective, \n",
    "                n_trials=remaining_trials if use_hpo else 1,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"The study has already reached the maximum number of trials.\")\n",
    "\n",
    "        if use_hpo:\n",
    "            # When HPO is used, trial.suggest_ methods are called, populating trial.params\n",
    "            best_hyperparams = study.best_trial.params\n",
    "        else:\n",
    "            # When not using HPO, a single trial runs with default parameters.\n",
    "            best_hyperparams = suggest_hyperparameters(trial=None, model_type=student_model_type, task_type=model_task_type, use_hpo=False)\n",
    "\n",
    "        logger.info(f\"Best hyperparameters for fold {outer_fold}: {best_hyperparams}\")\n",
    "        logger.info(f\"Best score: {study.best_value:.4f}\")\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 7: FINAL MODEL TRAINING (on complete outer training set)\n",
    "        # =========================================================================\n",
    "        # Get teacher logits for outer training set\n",
    "        teacher_outputs_train = np.array([index_to_outputs[idx] for idx in train_idx])\n",
    "        # Preprocess the outer training and test sets\n",
    "        X_train, X_test = preprocess(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            cat_cols,\n",
    "            config,\n",
    "            preprocessing_type=preprocessing_type,  \n",
    "        )\n",
    "        \n",
    "        # Train final model on complete outer training set\n",
    "        logger.info(\"------------------------------------------------------\")\n",
    "        logger.info(f\"Retraining Model on Outer Fold {outer_fold}\")\n",
    "        model = get_student_model(\n",
    "            config=config,\n",
    "            task_type=model_task_type,\n",
    "            device=device,\n",
    "            hyperparams=best_hyperparams,  # Use best hyperparameters from HPO\n",
    "            cat_cols=cat_cols,  \n",
    "        )\n",
    "        model.train(X_train, teacher_outputs_train)\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 8: FINAL EVALUATION (unbiased performance on outer test set)\n",
    "        # =========================================================================\n",
    "        # This provides the unbiased performance estimate for this fold\n",
    "        start_time = time.time()\n",
    "        test_preds = model.predict(X_test)  # Predicted logits or probabilities\n",
    "        end_time = time.time() - start_time\n",
    "        logger.info(f\"\\t Inference Time: {end_time:.5f} seconds\")\n",
    "        teacher_outputs_test = np.array([index_to_outputs[idx] for idx in test_idx])\n",
    "        test_metrics = model.evaluate(test_preds, y_test, teacher_outputs_test, original_task_type)\n",
    "\n",
    "        # Store outer fold score for later analysis\n",
    "        outer_fold_results = {\n",
    "            \"fold\": outer_fold,\n",
    "            \"seed\": config[\"training\"][\"random_state\"],\n",
    "            \"inference_time\": end_time,\n",
    "            **test_metrics,\n",
    "        }\n",
    "        outer_fold_scores.append(outer_fold_results)\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 9: STORE PREDICTIONS FOR STUDENT TRAINING\n",
    "        # =========================================================================\n",
    "        # Save predictions with their corresponding dataset indices\n",
    "        output_dfs.append(pd.DataFrame({\n",
    "            \"index\": test_idx,\n",
    "            \"output\": test_preds[:, 1] if model_task_type == \"binary\" else test_preds  \n",
    "        }))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 10: SAVE RESULTS AND METADATA\n",
    "    # =========================================================================\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE OUTER FOLD METRICS\n",
    "    # -------------------------------------------------------------------------\n",
    "    outer_fold_df = pd.DataFrame(outer_fold_scores)\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    output_dir = os.path.join(config[\"data\"][\"outer_folds_path\"], \"student\", sub_folder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    metrics_file = os.path.join(output_dir, f\"{dataset_id}_{student_model_type}({teacher_model_type})_{model_task_type[:2]}.csv\")\n",
    "    outer_fold_df.to_csv(metrics_file, index=False)\n",
    "    logger.info(f\"Outer fold metrics saved to: {metrics_file}\")\n",
    "\n",
    "    # Calculate and log overall performance across all folds\n",
    "    mean_inference_time = outer_fold_df['inference_time'].mean()\n",
    "    std_inference_time = outer_fold_df['inference_time'].std()\n",
    "    mean_parameters = outer_fold_df['parameters'].mean()\n",
    "    std_parameters = outer_fold_df['parameters'].std()\n",
    "\n",
    "    if original_task_type == \"binary\":\n",
    "        mean_acc = outer_fold_df['acc'].mean()\n",
    "        std_acc = outer_fold_df['acc'].std()\n",
    "        mean_f1 = outer_fold_df['f1'].mean()\n",
    "        std_f1 = outer_fold_df['f1'].std()\n",
    "        mean_roc = outer_fold_df['roc'].mean()\n",
    "        std_roc = outer_fold_df['roc'].std()\n",
    "        \n",
    "        mean_fidelity_acc = outer_fold_df['fidelity_acc'].mean()\n",
    "        std_fidelity_acc = outer_fold_df['fidelity_acc'].std()\n",
    "        mean_fidelity_f1 = outer_fold_df['fidelity_f1'].mean()\n",
    "        std_fidelity_f1 = outer_fold_df['fidelity_f1'].std()\n",
    "        mean_fidelity_roc = outer_fold_df['fidelity_roc'].mean()\n",
    "        std_fidelity_roc = outer_fold_df['fidelity_roc'].std()\n",
    "        mean_fidelity_kl_div = outer_fold_df['fidelity_kl_div'].mean()\n",
    "        std_fidelity_kl_div = outer_fold_df['fidelity_kl_div'].std()\n",
    "        \n",
    "        logger.info(f\"=== FINAL RESULTS FOR DATASET {dataset_id} ===\")\n",
    "        logger.info(f\"Balanced Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "        logger.info(f\"F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "        logger.info(f\"ROC AUC: {mean_roc:.4f} ± {std_roc:.4f}\")\n",
    "        logger.info(f\"Fidelity Accuracy: {mean_fidelity_acc:.4f} ± {std_fidelity_acc:.4f}\")\n",
    "        logger.info(f\"Fidelity F1 Score: {mean_fidelity_f1:.4f} ± {std_fidelity_f1:.4f}\")\n",
    "        logger.info(f\"Fidelity ROC AUC: {mean_fidelity_roc:.4f} ± {std_fidelity_roc:.4f}\")\n",
    "        logger.info(f\"Fidelity KL Divergence: {mean_fidelity_kl_div:.4f} ± {std_fidelity_kl_div:.4f}\")\n",
    "\n",
    "        if model_task_type == \"regression\":\n",
    "            mean_fidelity_mae = outer_fold_df['fidelity_mae'].mean()\n",
    "            std_fidelity_mae = outer_fold_df['fidelity_mae'].std()\n",
    "            mean_fidelity_mse = outer_fold_df['fidelity_mse'].mean()\n",
    "            std_fidelity_mse = outer_fold_df['fidelity_mse'].std()\n",
    "            mean_fidelity_rmse = outer_fold_df['fidelity_rmse'].mean()\n",
    "            std_fidelity_rmse = outer_fold_df['fidelity_rmse'].std()\n",
    "            mean_fidelity_r2 = outer_fold_df['fidelity_r2'].mean()\n",
    "            std_fidelity_r2 = outer_fold_df['fidelity_r2'].std()\n",
    "\n",
    "            logger.info(f\"Fidelity MAE: {mean_fidelity_mae:.4f} ± {std_fidelity_mae:.4f}\")\n",
    "            logger.info(f\"Fidelity MSE: {mean_fidelity_mse:.4f} ± {std_fidelity_mse:.4f}\")\n",
    "            logger.info(f\"Fidelity RMSE: {mean_fidelity_rmse:.4f} ± {std_fidelity_rmse:.4f}\")\n",
    "            logger.info(f\"Fidelity R2: {mean_fidelity_r2:.4f} ± {std_fidelity_r2:.4f}\")\n",
    "\n",
    "    else:\n",
    "        mean_mae = outer_fold_df['mae'].mean()\n",
    "        std_mae = outer_fold_df['mae'].std()\n",
    "        mean_mse = outer_fold_df['mse'].mean()\n",
    "        std_mse = outer_fold_df['mse'].std()\n",
    "        mean_rmse = outer_fold_df['rmse'].mean()\n",
    "        std_rmse = outer_fold_df['rmse'].std()\n",
    "        mean_r2 = outer_fold_df['r2'].mean()\n",
    "        std_r2 = outer_fold_df['r2'].std()\n",
    "\n",
    "        logger.info(f\"=== FINAL RESULTS FOR DATASET {dataset_id} ===\")\n",
    "        logger.info(f\"MAE: {mean_mae:.4f} ± {std_mae:.4f}\")\n",
    "        logger.info(f\"MSE: {mean_mse:.4f} ± {std_mse:.4f}\")\n",
    "        logger.info(f\"RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "        logger.info(f\"R2: {mean_r2:.4f} ± {std_r2:.4f}\")\n",
    "\n",
    "        mean_fidelity_mae = outer_fold_df['fidelity_mae'].mean()\n",
    "        std_fidelity_mae = outer_fold_df['fidelity_mae'].std()\n",
    "        mean_fidelity_mse = outer_fold_df['fidelity_mse'].mean()\n",
    "        std_fidelity_mse = outer_fold_df['fidelity_mse'].std()\n",
    "        mean_fidelity_rmse = outer_fold_df['fidelity_rmse'].mean()\n",
    "        std_fidelity_rmse = outer_fold_df['fidelity_rmse'].std()\n",
    "        mean_fidelity_r2 = outer_fold_df['fidelity_r2'].mean()\n",
    "        std_fidelity_r2 = outer_fold_df['fidelity_r2'].std()\n",
    "\n",
    "        logger.info(f\"Fidelity MAE: {mean_fidelity_mae:.4f} ± {std_fidelity_mae:.4f}\")\n",
    "        logger.info(f\"Fidelity MSE: {mean_fidelity_mse:.4f} ± {std_fidelity_mse:.4f}\")\n",
    "        logger.info(f\"Fidelity RMSE: {mean_fidelity_rmse:.4f} ± {std_fidelity_rmse:.4f}\")\n",
    "        logger.info(f\"Fidelity R2: {mean_fidelity_r2:.4f} ± {std_fidelity_r2:.4f}\")\n",
    "\n",
    "    logger.info(f\"Mean Inference Time: {mean_inference_time:.4f} ± {std_inference_time:.4f}\")\n",
    "    logger.info(f\"Mean Parameters: {mean_parameters:.4f} ± {std_parameters:.4f}\")\n",
    "\n",
    "    # Save summary statistics as well\n",
    "    summary_stats = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"student_model_type\": student_model_type,\n",
    "        \"teacher_model_type\": teacher_model_type,\n",
    "        \"original_task_type\": original_task_type,\n",
    "        \"student_task_type\": model_task_type,\n",
    "        \"seed\": config[\"training\"][\"random_state\"],\n",
    "        \"use_hpo\": config[\"training\"][\"use_hpo\"],\n",
    "        \"mean_inference_time\": mean_inference_time,\n",
    "        \"std_inference_time\": std_inference_time,\n",
    "        \"mean_parameters\": mean_parameters,\n",
    "        \"std_parameters\": std_parameters,\n",
    "    }\n",
    "\n",
    "    if original_task_type == \"binary\":\n",
    "        summary_stats.update({\n",
    "            \"mean_acc\": mean_acc,\n",
    "            \"std_acc\": std_acc,\n",
    "            \"mean_f1\": mean_f1,\n",
    "            \"std_f1\": std_f1,\n",
    "            \"mean_roc\": mean_roc,\n",
    "            \"std_roc\": std_roc,\n",
    "            \"mean_fidelity_acc\": mean_fidelity_acc,\n",
    "            \"std_fidelity_acc\": std_fidelity_acc,\n",
    "            \"mean_fidelity_f1\": mean_fidelity_f1,\n",
    "            \"std_fidelity_f1\": std_fidelity_f1,\n",
    "            \"mean_fidelity_roc\": mean_fidelity_roc,\n",
    "            \"std_fidelity_roc\": std_fidelity_roc,\n",
    "            \"mean_fidelity_kl_div\": mean_fidelity_kl_div,\n",
    "            \"std_fidelity_kl_div\": std_fidelity_kl_div,\n",
    "        })\n",
    "        if model_task_type == \"regression\":\n",
    "            summary_stats.update({\n",
    "                \"mean_fidelity_mae\": mean_fidelity_mae,\n",
    "                \"std_fidelity_mae\": std_fidelity_mae,\n",
    "                \"mean_fidelity_mse\": mean_fidelity_mse,\n",
    "                \"std_fidelity_mse\": std_fidelity_mse,\n",
    "                \"mean_fidelity_rmse\": mean_fidelity_rmse,\n",
    "                \"std_fidelity_rmse\": std_fidelity_rmse,\n",
    "                \"mean_fidelity_r2\": mean_fidelity_r2,\n",
    "                \"std_fidelity_r2\": std_fidelity_r2,\n",
    "            })\n",
    "    else:\n",
    "        summary_stats.update({\n",
    "            \"mean_mae\": mean_mae,\n",
    "            \"std_mae\": std_mae,\n",
    "            \"mean_mse\": mean_mse,\n",
    "            \"std_mse\": std_mse,\n",
    "            \"mean_rmse\": mean_rmse,\n",
    "            \"std_rmse\": std_rmse,\n",
    "            \"mean_r2\": mean_r2,\n",
    "            \"std_r2\": std_r2,\n",
    "            \"mean_fidelity_mae\": mean_fidelity_mae,\n",
    "            \"std_fidelity_mae\": std_fidelity_mae,\n",
    "            \"mean_fidelity_mse\": mean_fidelity_mse,\n",
    "            \"std_fidelity_mse\": std_fidelity_mse,\n",
    "            \"mean_fidelity_rmse\": mean_fidelity_rmse,\n",
    "            \"std_fidelity_rmse\": std_fidelity_rmse,\n",
    "            \"mean_fidelity_r2\": mean_fidelity_r2,\n",
    "            \"std_fidelity_r2\": std_fidelity_r2,\n",
    "        })\n",
    "\n",
    "    # Load existing summary file if it exists, otherwise create new\n",
    "    summary_file = os.path.join(config[\"data\"][\"results_dir_path\"], \"student\", f\"{dataset_id}_results.json\")\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(summary_file), exist_ok=True)\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file, 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "    else:\n",
    "        all_results = {}\n",
    "\n",
    "    # Add current model results to the dataset summary\n",
    "    # Use simple incremental numbering\n",
    "    next_num = len(all_results) + 1\n",
    "    model_key = str(next_num)\n",
    "\n",
    "    # Add current model results to the dataset summary\n",
    "    all_results[model_key] = summary_stats\n",
    "\n",
    "    # Save updated summary\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    logger.info(f\"Summary statistics saved to: {summary_file}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE STUDENT PREDICTIONS\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Combine predictions from all outer folds\n",
    "    if output_dfs:  # Check if we have any DataFrames to concatenate\n",
    "        output_df = pd.concat(output_dfs, ignore_index=True)\n",
    "    else:\n",
    "        output_df = pd.DataFrame(columns=[\"index\", \"output\"])\n",
    "    output_df = output_df.sort_values(by=\"index\")\n",
    "    \n",
    "    # Create the full directory structure\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    output_dir = os.path.join(config[\"data\"][\"output_dir_path\"], sub_folder, \"student\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_file = os.path.join(output_dir, f\"{dataset_id}_{student_model_type}({teacher_model_type})_{model_task_type[:2]}.csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    logger.info(f\"{config['model']['student_model']} outputs saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5eb74b",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b272a1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 13:54:35,132 - __main__ - INFO - Loading configuration...\n",
      "2025-06-20 13:54:35,133 - __main__ - INFO - Loading dataset 23381 from cache at 'data/cache/openml_dataset_23381.pkl'...\n",
      "2025-06-20 13:54:35,134 - __main__ - INFO - Dataset 23381 loaded successfully with task type: binary\n",
      "2025-06-20 13:54:35,136 - __main__ - INFO - Using GPU: NVIDIA RTX A6000\n",
      "2025-06-20 13:54:35,137 - __main__ - INFO - Random seed set to 42\n",
      "2025-06-20 13:54:35,139 - __main__ - INFO - Loaded fold indices from: data/fold_indices/default/teacher/23381_tabpfn.json\n",
      "2025-06-20 13:54:35,140 - __main__ - INFO - Outer Fold 1 - Train Indices: [ 1  3  5  6  7  8  9 10 11 12], Test Indices: [ 0  2  4 18 19 27 35 39 57 59]\n",
      "2025-06-20 13:54:35,140 - __main__ - INFO - -------------------- Outer Fold 1 --------------------\n",
      "2025-06-20 13:54:35,141 - __main__ - INFO - Starting hyperparameter optimization for outer fold 1...\n",
      "[I 2025-06-20 13:54:35,142] A new study created in memory with name: 23381.1.grande(tabpfn).re.bi\n",
      "2025-06-20 13:54:35,143 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:54:35,144 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 1...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "2025-06-20 13:54:35.254237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46743 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:61:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750420478.621903 1720608 service.cc:145] XLA service 0x7fd708014d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750420478.621976 1720608 service.cc:153]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2025-06-20 13:54:38.683596: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-20 13:54:39.060549: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1750420479.805180 1720608 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "2025-06-20 13:54:44,783 - __main__ - INFO - \t Balanced Accuracy: 0.6112, F1 Score: 0.6043, ROC AUC: 0.6938\n",
      "2025-06-20 13:54:44,787 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.8694, F1 Score: 0.8940, ROC AUC: 0.9948, KL Divergence: 0.0032\n",
      "2025-06-20 13:54:44,788 - __main__ - INFO - \t Fidelity - MAE: 0.1147, MSE: 0.0269, RMSE: 0.1640, R^2: 0.8639\n",
      "2025-06-20 13:54:44,789 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:54:44,789 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 2...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "2025-06-20 13:54:51,925 - __main__ - INFO - \t Balanced Accuracy: 0.6100, F1 Score: 0.5913, ROC AUC: 0.6848\n",
      "2025-06-20 13:54:51,929 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.9359, F1 Score: 0.9581, ROC AUC: 0.9992, KL Divergence: 0.0015\n",
      "2025-06-20 13:54:51,930 - __main__ - INFO - \t Fidelity - MAE: 0.0865, MSE: 0.0130, RMSE: 0.1140, R^2: 0.9116\n",
      "[I 2025-06-20 13:54:51,931] Trial 0 finished with value: -0.10056783770746057 and parameters: {}. Best is trial 0 with value: -0.10056783770746057.\n",
      "2025-06-20 13:54:51,931 - __main__ - INFO - Best hyperparameters for fold 1: {'depth': 5, 'n_estimators': 2048, 'learning_rate_weights': 0.005, 'learning_rate_index': 0.01, 'learning_rate_values': 0.01, 'learning_rate_leaf': 0.01, 'optimizer': 'adam', 'cosine_decay_steps': 0, 'dropout': 0.0, 'selected_variables': 0.8, 'data_subset_fraction': 1.0, 'focal_loss': False, 'temperature': 0.0, 'from_logits': True, 'use_class_weights': True, 'loss': 'mse'}\n",
      "2025-06-20 13:54:51,931 - __main__ - INFO - Best score: -0.1006\n",
      "2025-06-20 13:54:51,932 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:54:51,932 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 13:54:51,932 - __main__ - INFO - Retraining Model on Outer Fold 1\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fe45c34aca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 13:54:58,904 - tensorflow - WARNING - 5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fe45c34aca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fe45c34aca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 13:54:59,485 - tensorflow - WARNING - 6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fe45c34aca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2025-06-20 13:54:59,509 - __main__ - INFO - \t Inference Time: 0.95064 seconds\n",
      "2025-06-20 13:54:59,513 - __main__ - INFO - \t Balanced Accuracy: 0.5936, F1 Score: 0.5924, ROC AUC: 0.6388\n",
      "2025-06-20 13:54:59,516 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 1.0000, F1 Score: 1.0000, ROC AUC: 1.0000, KL Divergence: 0.0006\n",
      "2025-06-20 13:54:59,517 - __main__ - INFO - \t Fidelity - MAE: 0.0569, MSE: 0.0048, RMSE: 0.0690, R^2: 0.9798\n",
      "2025-06-20 13:54:59,518 - __main__ - INFO - Outer Fold 2 - Train Indices: [ 0  1  2  3  4  5  7  8  9 13], Test Indices: [ 6 10 11 12 15 16 20 21 36 45]\n",
      "2025-06-20 13:54:59,518 - __main__ - INFO - -------------------- Outer Fold 2 --------------------\n",
      "2025-06-20 13:54:59,519 - __main__ - INFO - Starting hyperparameter optimization for outer fold 2...\n",
      "[I 2025-06-20 13:54:59,519] A new study created in memory with name: 23381.2.grande(tabpfn).re.bi\n",
      "2025-06-20 13:54:59,521 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:54:59,521 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 1...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "2025-06-20 13:55:06,553 - __main__ - INFO - \t Balanced Accuracy: 0.6578, F1 Score: 0.6592, ROC AUC: 0.7201\n",
      "2025-06-20 13:55:06,556 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.9919, F1 Score: 0.9941, ROC AUC: 1.0000, KL Divergence: 0.0035\n",
      "2025-06-20 13:55:06,557 - __main__ - INFO - \t Fidelity - MAE: 0.1369, MSE: 0.0314, RMSE: 0.1771, R^2: 0.9253\n",
      "2025-06-20 13:55:06,558 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:55:06,559 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 2...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "2025-06-20 13:55:14,338 - __main__ - INFO - \t Balanced Accuracy: 0.6271, F1 Score: 0.6268, ROC AUC: 0.7282\n",
      "2025-06-20 13:55:14,342 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.9882, F1 Score: 0.9882, ROC AUC: 0.9980, KL Divergence: 0.0039\n",
      "2025-06-20 13:55:14,343 - __main__ - INFO - \t Fidelity - MAE: 0.1439, MSE: 0.0354, RMSE: 0.1882, R^2: 0.9240\n",
      "[I 2025-06-20 13:55:14,344] Trial 0 finished with value: -0.14039789896504468 and parameters: {}. Best is trial 0 with value: -0.14039789896504468.\n",
      "2025-06-20 13:55:14,344 - __main__ - INFO - Best hyperparameters for fold 2: {'depth': 5, 'n_estimators': 2048, 'learning_rate_weights': 0.005, 'learning_rate_index': 0.01, 'learning_rate_values': 0.01, 'learning_rate_leaf': 0.01, 'optimizer': 'adam', 'cosine_decay_steps': 0, 'dropout': 0.0, 'selected_variables': 0.8, 'data_subset_fraction': 1.0, 'focal_loss': False, 'temperature': 0.0, 'from_logits': True, 'use_class_weights': True, 'loss': 'mse'}\n",
      "2025-06-20 13:55:14,344 - __main__ - INFO - Best score: -0.1404\n",
      "2025-06-20 13:55:14,345 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:55:14,345 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 13:55:14,345 - __main__ - INFO - Retraining Model on Outer Fold 2\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "2025-06-20 13:55:21,404 - __main__ - INFO - \t Inference Time: 0.78590 seconds\n",
      "2025-06-20 13:55:21,408 - __main__ - INFO - \t Balanced Accuracy: 0.5103, F1 Score: 0.4950, ROC AUC: 0.4992\n",
      "2025-06-20 13:55:21,410 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.9733, F1 Score: 0.9733, ROC AUC: 0.9995, KL Divergence: 0.0023\n",
      "2025-06-20 13:55:21,411 - __main__ - INFO - \t Fidelity - MAE: 0.1117, MSE: 0.0208, RMSE: 0.1443, R^2: 0.9459\n",
      "2025-06-20 13:55:21,412 - __main__ - INFO - Outer Fold 3 - Train Indices: [ 0  2  3  4  5  6  7  9 10 11], Test Indices: [ 1  8 14 25 28 30 32 34 42 44]\n",
      "2025-06-20 13:55:21,412 - __main__ - INFO - -------------------- Outer Fold 3 --------------------\n",
      "2025-06-20 13:55:21,413 - __main__ - INFO - Starting hyperparameter optimization for outer fold 3...\n",
      "[I 2025-06-20 13:55:21,414] A new study created in memory with name: 23381.3.grande(tabpfn).re.bi\n",
      "2025-06-20 13:55:21,415 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:55:21,416 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 1...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "2025-06-20 13:55:28,597 - __main__ - INFO - \t Balanced Accuracy: 0.5874, F1 Score: 0.5749, ROC AUC: 0.6458\n",
      "2025-06-20 13:55:28,601 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.9000, F1 Score: 0.9262, ROC AUC: 0.9987, KL Divergence: 0.0021\n",
      "2025-06-20 13:55:28,602 - __main__ - INFO - \t Fidelity - MAE: 0.0974, MSE: 0.0178, RMSE: 0.1334, R^2: 0.9188\n",
      "2025-06-20 13:55:28,604 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:55:28,604 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 2...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "2025-06-20 13:55:35,277 - __main__ - INFO - \t Balanced Accuracy: 0.6248, F1 Score: 0.6212, ROC AUC: 0.6802\n",
      "2025-06-20 13:55:35,281 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.9214, F1 Score: 0.9380, ROC AUC: 0.9980, KL Divergence: 0.0026\n",
      "2025-06-20 13:55:35,282 - __main__ - INFO - \t Fidelity - MAE: 0.1169, MSE: 0.0223, RMSE: 0.1494, R^2: 0.9173\n",
      "[I 2025-06-20 13:55:35,283] Trial 0 finished with value: -0.10712599711488607 and parameters: {}. Best is trial 0 with value: -0.10712599711488607.\n",
      "2025-06-20 13:55:35,283 - __main__ - INFO - Best hyperparameters for fold 3: {'depth': 5, 'n_estimators': 2048, 'learning_rate_weights': 0.005, 'learning_rate_index': 0.01, 'learning_rate_values': 0.01, 'learning_rate_leaf': 0.01, 'optimizer': 'adam', 'cosine_decay_steps': 0, 'dropout': 0.0, 'selected_variables': 0.8, 'data_subset_fraction': 1.0, 'focal_loss': False, 'temperature': 0.0, 'from_logits': True, 'use_class_weights': True, 'loss': 'mse'}\n",
      "2025-06-20 13:55:35,284 - __main__ - INFO - Best score: -0.1071\n",
      "2025-06-20 13:55:35,284 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:55:35,284 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 13:55:35,284 - __main__ - INFO - Retraining Model on Outer Fold 3\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "2025-06-20 13:55:41,653 - __main__ - INFO - \t Inference Time: 0.66412 seconds\n",
      "2025-06-20 13:55:41,658 - __main__ - INFO - \t Balanced Accuracy: 0.6076, F1 Score: 0.6044, ROC AUC: 0.6248\n",
      "2025-06-20 13:55:41,661 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.9828, F1 Score: 0.9877, ROC AUC: 1.0000, KL Divergence: 0.0007\n",
      "2025-06-20 13:55:41,662 - __main__ - INFO - \t Fidelity - MAE: 0.0590, MSE: 0.0063, RMSE: 0.0794, R^2: 0.9662\n",
      "2025-06-20 13:55:41,663 - __main__ - INFO - Outer Fold 4 - Train Indices: [ 0  1  2  3  4  6  8  9 10 11], Test Indices: [ 5  7 13 22 24 26 33 38 43 46]\n",
      "2025-06-20 13:55:41,664 - __main__ - INFO - -------------------- Outer Fold 4 --------------------\n",
      "2025-06-20 13:55:41,665 - __main__ - INFO - Starting hyperparameter optimization for outer fold 4...\n",
      "[I 2025-06-20 13:55:41,666] A new study created in memory with name: 23381.4.grande(tabpfn).re.bi\n",
      "2025-06-20 13:55:41,667 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:55:41,667 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 1...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "2025-06-20 13:55:48,917 - __main__ - INFO - \t Balanced Accuracy: 0.5792, F1 Score: 0.5552, ROC AUC: 0.6865\n",
      "2025-06-20 13:55:48,920 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.8200, F1 Score: 0.8529, ROC AUC: 0.9879, KL Divergence: 0.0014\n",
      "2025-06-20 13:55:48,921 - __main__ - INFO - \t Fidelity - MAE: 0.0830, MSE: 0.0123, RMSE: 0.1107, R^2: 0.9321\n",
      "2025-06-20 13:55:48,922 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:55:48,922 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 2...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "2025-06-20 13:55:56,866 - __main__ - INFO - \t Balanced Accuracy: 0.5603, F1 Score: 0.5357, ROC AUC: 0.6691\n",
      "2025-06-20 13:55:56,869 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.8984, F1 Score: 0.9204, ROC AUC: 0.9864, KL Divergence: 0.0017\n",
      "2025-06-20 13:55:56,870 - __main__ - INFO - \t Fidelity - MAE: 0.0872, MSE: 0.0139, RMSE: 0.1178, R^2: 0.9092\n",
      "[I 2025-06-20 13:55:56,871] Trial 0 finished with value: -0.08507353817628449 and parameters: {}. Best is trial 0 with value: -0.08507353817628449.\n",
      "2025-06-20 13:55:56,872 - __main__ - INFO - Best hyperparameters for fold 4: {'depth': 5, 'n_estimators': 2048, 'learning_rate_weights': 0.005, 'learning_rate_index': 0.01, 'learning_rate_values': 0.01, 'learning_rate_leaf': 0.01, 'optimizer': 'adam', 'cosine_decay_steps': 0, 'dropout': 0.0, 'selected_variables': 0.8, 'data_subset_fraction': 1.0, 'focal_loss': False, 'temperature': 0.0, 'from_logits': True, 'use_class_weights': True, 'loss': 'mse'}\n",
      "2025-06-20 13:55:56,872 - __main__ - INFO - Best score: -0.0851\n",
      "2025-06-20 13:55:56,872 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:55:56,872 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 13:55:56,873 - __main__ - INFO - Retraining Model on Outer Fold 4\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "2025-06-20 13:56:04,171 - __main__ - INFO - \t Inference Time: 0.67319 seconds\n",
      "2025-06-20 13:56:04,175 - __main__ - INFO - \t Balanced Accuracy: 0.6486, F1 Score: 0.6484, ROC AUC: 0.6819\n",
      "2025-06-20 13:56:04,178 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.9828, F1 Score: 0.9877, ROC AUC: 1.0000, KL Divergence: 0.0009\n",
      "2025-06-20 13:56:04,179 - __main__ - INFO - \t Fidelity - MAE: 0.0625, MSE: 0.0080, RMSE: 0.0896, R^2: 0.9456\n",
      "2025-06-20 13:56:04,180 - __main__ - INFO - Outer Fold 5 - Train Indices: [ 0  1  2  4  5  6  7  8 10 11], Test Indices: [ 3  9 17 23 29 31 37 40 41 54]\n",
      "2025-06-20 13:56:04,180 - __main__ - INFO - -------------------- Outer Fold 5 --------------------\n",
      "2025-06-20 13:56:04,181 - __main__ - INFO - Starting hyperparameter optimization for outer fold 5...\n",
      "[I 2025-06-20 13:56:04,181] A new study created in memory with name: 23381.5.grande(tabpfn).re.bi\n",
      "2025-06-20 13:56:04,183 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:56:04,183 - __main__ - INFO - Training Model on Outer Fold 5, Inner Fold 1...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "2025-06-20 13:56:11,085 - __main__ - INFO - \t Balanced Accuracy: 0.6139, F1 Score: 0.6053, ROC AUC: 0.6951\n",
      "2025-06-20 13:56:11,089 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.9276, F1 Score: 0.9370, ROC AUC: 0.9944, KL Divergence: 0.0019\n",
      "2025-06-20 13:56:11,090 - __main__ - INFO - \t Fidelity - MAE: 0.0963, MSE: 0.0161, RMSE: 0.1270, R^2: 0.8990\n",
      "2025-06-20 13:56:11,091 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:56:11,092 - __main__ - INFO - Training Model on Outer Fold 5, Inner Fold 2...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/category_encoders/ordinal.py:210: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[column].fillna(-1, inplace=True)\n",
      "2025-06-20 13:56:18,392 - __main__ - INFO - \t Balanced Accuracy: 0.5950, F1 Score: 0.5857, ROC AUC: 0.6774\n",
      "2025-06-20 13:56:18,396 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.9567, F1 Score: 0.9660, ROC AUC: 0.9979, KL Divergence: 0.0021\n",
      "2025-06-20 13:56:18,397 - __main__ - INFO - \t Fidelity - MAE: 0.0994, MSE: 0.0181, RMSE: 0.1344, R^2: 0.8820\n",
      "[I 2025-06-20 13:56:18,398] Trial 0 finished with value: -0.09784692106147186 and parameters: {}. Best is trial 0 with value: -0.09784692106147186.\n",
      "2025-06-20 13:56:18,398 - __main__ - INFO - Best hyperparameters for fold 5: {'depth': 5, 'n_estimators': 2048, 'learning_rate_weights': 0.005, 'learning_rate_index': 0.01, 'learning_rate_values': 0.01, 'learning_rate_leaf': 0.01, 'optimizer': 'adam', 'cosine_decay_steps': 0, 'dropout': 0.0, 'selected_variables': 0.8, 'data_subset_fraction': 1.0, 'focal_loss': False, 'temperature': 0.0, 'from_logits': True, 'use_class_weights': True, 'loss': 'mse'}\n",
      "2025-06-20 13:56:18,398 - __main__ - INFO - Best score: -0.0978\n",
      "2025-06-20 13:56:18,399 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:56:18,399 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 13:56:18,399 - __main__ - INFO - Retraining Model on Outer Fold 5\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.cat_columns] = X[self.cat_columns].fillna(self.mode_train_cat)\n",
      "2025-06-20 13:56:27,127 - __main__ - INFO - \t Inference Time: 0.66887 seconds\n",
      "2025-06-20 13:56:27,131 - __main__ - INFO - \t Balanced Accuracy: 0.6170, F1 Score: 0.5951, ROC AUC: 0.6786\n",
      "2025-06-20 13:56:27,135 - __main__ - INFO - \t Fidelity - Balanced Accuracy: 0.8703, F1 Score: 0.8884, ROC AUC: 0.9865, KL Divergence: 0.0007\n",
      "2025-06-20 13:56:27,136 - __main__ - INFO - \t Fidelity - MAE: 0.0594, MSE: 0.0062, RMSE: 0.0787, R^2: 0.9368\n",
      "2025-06-20 13:56:27,138 - __main__ - INFO - Outer fold metrics saved to: data/outer_fold/student/default/23381_grande(tabpfn)_re.csv\n",
      "2025-06-20 13:56:27,140 - __main__ - INFO - === FINAL RESULTS FOR DATASET 23381 ===\n",
      "2025-06-20 13:56:27,140 - __main__ - INFO - Balanced Accuracy: 0.5954 ± 0.0517\n",
      "2025-06-20 13:56:27,140 - __main__ - INFO - F1 Score: 0.5871 ± 0.0562\n",
      "2025-06-20 13:56:27,140 - __main__ - INFO - ROC AUC: 0.6246 ± 0.0744\n",
      "2025-06-20 13:56:27,141 - __main__ - INFO - Fidelity Accuracy: 0.9618 ± 0.0521\n",
      "2025-06-20 13:56:27,141 - __main__ - INFO - Fidelity F1 Score: 0.9674 ± 0.0452\n",
      "2025-06-20 13:56:27,141 - __main__ - INFO - Fidelity ROC AUC: 0.9972 ± 0.0060\n",
      "2025-06-20 13:56:27,141 - __main__ - INFO - Fidelity KL Divergence: 0.0011 ± 0.0007\n",
      "2025-06-20 13:56:27,142 - __main__ - INFO - Fidelity MAE: 0.0699 ± 0.0234\n",
      "2025-06-20 13:56:27,142 - __main__ - INFO - Fidelity MSE: 0.0092 ± 0.0066\n",
      "2025-06-20 13:56:27,142 - __main__ - INFO - Fidelity RMSE: 0.0922 ± 0.0300\n",
      "2025-06-20 13:56:27,143 - __main__ - INFO - Fidelity R2: 0.9549 ± 0.0176\n",
      "2025-06-20 13:56:27,143 - __main__ - INFO - Mean Inference Time: 0.7485 ± 0.1239\n",
      "2025-06-20 13:56:27,143 - __main__ - INFO - Mean Parameters: 1690828.8000 ± 139095.2389\n",
      "2025-06-20 13:56:27,146 - __main__ - INFO - Summary statistics saved to: results/student/23381_results.json\n",
      "2025-06-20 13:56:27,148 - __main__ - INFO - grande outputs saved to: data/output/default/student/23381_grande(tabpfn)_re.csv\n",
      "2025-06-20 13:56:27,148 - __main__ - INFO - Loading configuration...\n",
      "2025-06-20 13:56:27,149 - __main__ - INFO - Loading dataset 197 from cache at 'data/cache/openml_dataset_197.pkl'...\n",
      "2025-06-20 13:56:27,152 - __main__ - INFO - Dataset 197 loaded successfully with task type: regression\n",
      "2025-06-20 13:56:27,152 - __main__ - INFO - Using GPU: NVIDIA RTX A6000\n",
      "2025-06-20 13:56:27,157 - __main__ - INFO - Random seed set to 42\n",
      "2025-06-20 13:56:27,176 - __main__ - INFO - Loaded fold indices from: data/fold_indices/default/teacher/197_tabpfn.json\n",
      "2025-06-20 13:56:27,177 - __main__ - INFO - Outer Fold 1 - Train Indices: [0 1 2 3 4 5 6 7 8 9], Test Indices: [17 19 23 26 31 33 37 41 48 50]\n",
      "2025-06-20 13:56:27,177 - __main__ - INFO - -------------------- Outer Fold 1 --------------------\n",
      "2025-06-20 13:56:27,178 - __main__ - INFO - Starting hyperparameter optimization for outer fold 1...\n",
      "[I 2025-06-20 13:56:27,179] A new study created in memory with name: 197.1.grande(tabpfn).re.re\n",
      "2025-06-20 13:56:27,181 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:56:27,181 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 1...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:56:43,211 - __main__ - INFO - \t MAE: 1.9174, MSE: 8.2986, RMSE: 2.8807, R^2: 0.9765\n",
      "2025-06-20 13:56:43,212 - __main__ - INFO - \t Fidelity - MAE: 0.7879, MSE: 1.2429, RMSE: 1.1148, R^2: 0.9958\n",
      "2025-06-20 13:56:43,214 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:56:43,214 - __main__ - INFO - Training Model on Outer Fold 1, Inner Fold 2...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:56:59,726 - __main__ - INFO - \t MAE: 1.8628, MSE: 7.7571, RMSE: 2.7852, R^2: 0.9774\n",
      "2025-06-20 13:56:59,728 - __main__ - INFO - \t Fidelity - MAE: 0.7440, MSE: 1.1132, RMSE: 1.0551, R^2: 0.9961\n",
      "[I 2025-06-20 13:56:59,728] Trial 0 finished with value: -0.7659387020738865 and parameters: {}. Best is trial 0 with value: -0.7659387020738865.\n",
      "2025-06-20 13:56:59,729 - __main__ - INFO - Best hyperparameters for fold 1: {'depth': 5, 'n_estimators': 2048, 'learning_rate_weights': 0.005, 'learning_rate_index': 0.01, 'learning_rate_values': 0.01, 'learning_rate_leaf': 0.01, 'optimizer': 'adam', 'cosine_decay_steps': 0, 'dropout': 0.0, 'selected_variables': 0.8, 'data_subset_fraction': 1.0, 'focal_loss': False, 'temperature': 0.0, 'from_logits': True, 'use_class_weights': True, 'loss': 'mse'}\n",
      "2025-06-20 13:56:59,729 - __main__ - INFO - Best score: -0.7659\n",
      "2025-06-20 13:56:59,729 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:56:59,730 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 13:56:59,730 - __main__ - INFO - Retraining Model on Outer Fold 1\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:57:20,151 - __main__ - INFO - \t Inference Time: 1.12282 seconds\n",
      "2025-06-20 13:57:20,153 - __main__ - INFO - \t MAE: 1.8557, MSE: 7.6963, RMSE: 2.7742, R^2: 0.9743\n",
      "2025-06-20 13:57:20,154 - __main__ - INFO - \t Fidelity - MAE: 0.5313, MSE: 0.5195, RMSE: 0.7208, R^2: 0.9979\n",
      "2025-06-20 13:57:20,155 - __main__ - INFO - Outer Fold 2 - Train Indices: [ 1  2  3  4  5  6  7  9 10 11], Test Indices: [ 0  8 12 14 15 29 30 43 44 45]\n",
      "2025-06-20 13:57:20,156 - __main__ - INFO - -------------------- Outer Fold 2 --------------------\n",
      "2025-06-20 13:57:20,157 - __main__ - INFO - Starting hyperparameter optimization for outer fold 2...\n",
      "[I 2025-06-20 13:57:20,158] A new study created in memory with name: 197.2.grande(tabpfn).re.re\n",
      "2025-06-20 13:57:20,159 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:57:20,160 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 1...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:57:35,353 - __main__ - INFO - \t MAE: 1.9215, MSE: 8.8811, RMSE: 2.9801, R^2: 0.9739\n",
      "2025-06-20 13:57:35,355 - __main__ - INFO - \t Fidelity - MAE: 0.8006, MSE: 1.5424, RMSE: 1.2419, R^2: 0.9946\n",
      "2025-06-20 13:57:35,356 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:57:35,356 - __main__ - INFO - Training Model on Outer Fold 2, Inner Fold 2...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:57:49,958 - __main__ - INFO - \t MAE: 1.8591, MSE: 7.8735, RMSE: 2.8060, R^2: 0.9771\n",
      "2025-06-20 13:57:49,960 - __main__ - INFO - \t Fidelity - MAE: 0.7368, MSE: 1.0836, RMSE: 1.0410, R^2: 0.9962\n",
      "[I 2025-06-20 13:57:49,961] Trial 0 finished with value: -0.7686734984745496 and parameters: {}. Best is trial 0 with value: -0.7686734984745496.\n",
      "2025-06-20 13:57:49,961 - __main__ - INFO - Best hyperparameters for fold 2: {'depth': 5, 'n_estimators': 2048, 'learning_rate_weights': 0.005, 'learning_rate_index': 0.01, 'learning_rate_values': 0.01, 'learning_rate_leaf': 0.01, 'optimizer': 'adam', 'cosine_decay_steps': 0, 'dropout': 0.0, 'selected_variables': 0.8, 'data_subset_fraction': 1.0, 'focal_loss': False, 'temperature': 0.0, 'from_logits': True, 'use_class_weights': True, 'loss': 'mse'}\n",
      "2025-06-20 13:57:49,961 - __main__ - INFO - Best score: -0.7687\n",
      "2025-06-20 13:57:49,962 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:57:49,962 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 13:57:49,962 - __main__ - INFO - Retraining Model on Outer Fold 2\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:58:10,935 - __main__ - INFO - \t Inference Time: 1.01125 seconds\n",
      "2025-06-20 13:58:10,937 - __main__ - INFO - \t MAE: 1.8224, MSE: 7.5759, RMSE: 2.7524, R^2: 0.9767\n",
      "2025-06-20 13:58:10,939 - __main__ - INFO - \t Fidelity - MAE: 0.5777, MSE: 0.6349, RMSE: 0.7968, R^2: 0.9977\n",
      "2025-06-20 13:58:10,940 - __main__ - INFO - Outer Fold 3 - Train Indices: [ 0  1  2  3  4  5  7  8  9 10], Test Indices: [ 6 18 24 25 32 39 49 52 62 67]\n",
      "2025-06-20 13:58:10,940 - __main__ - INFO - -------------------- Outer Fold 3 --------------------\n",
      "2025-06-20 13:58:10,941 - __main__ - INFO - Starting hyperparameter optimization for outer fold 3...\n",
      "[I 2025-06-20 13:58:10,942] A new study created in memory with name: 197.3.grande(tabpfn).re.re\n",
      "2025-06-20 13:58:10,944 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:58:10,944 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 1...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:58:24,562 - __main__ - INFO - \t MAE: 1.9258, MSE: 8.4314, RMSE: 2.9037, R^2: 0.9760\n",
      "2025-06-20 13:58:24,563 - __main__ - INFO - \t Fidelity - MAE: 0.8069, MSE: 1.2983, RMSE: 1.1394, R^2: 0.9955\n",
      "2025-06-20 13:58:24,565 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:58:24,565 - __main__ - INFO - Training Model on Outer Fold 3, Inner Fold 2...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:58:40,332 - __main__ - INFO - \t MAE: 1.9215, MSE: 8.8525, RMSE: 2.9753, R^2: 0.9742\n",
      "2025-06-20 13:58:40,334 - __main__ - INFO - \t Fidelity - MAE: 0.7683, MSE: 1.2515, RMSE: 1.1187, R^2: 0.9956\n",
      "[I 2025-06-20 13:58:40,334] Trial 0 finished with value: -0.7875978029243532 and parameters: {}. Best is trial 0 with value: -0.7875978029243532.\n",
      "2025-06-20 13:58:40,335 - __main__ - INFO - Best hyperparameters for fold 3: {'depth': 5, 'n_estimators': 2048, 'learning_rate_weights': 0.005, 'learning_rate_index': 0.01, 'learning_rate_values': 0.01, 'learning_rate_leaf': 0.01, 'optimizer': 'adam', 'cosine_decay_steps': 0, 'dropout': 0.0, 'selected_variables': 0.8, 'data_subset_fraction': 1.0, 'focal_loss': False, 'temperature': 0.0, 'from_logits': True, 'use_class_weights': True, 'loss': 'mse'}\n",
      "2025-06-20 13:58:40,335 - __main__ - INFO - Best score: -0.7876\n",
      "2025-06-20 13:58:40,335 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:58:40,336 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 13:58:40,336 - __main__ - INFO - Retraining Model on Outer Fold 3\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:59:00,880 - __main__ - INFO - \t Inference Time: 1.13130 seconds\n",
      "2025-06-20 13:59:00,882 - __main__ - INFO - \t MAE: 1.8030, MSE: 7.3918, RMSE: 2.7188, R^2: 0.9756\n",
      "2025-06-20 13:59:00,883 - __main__ - INFO - \t Fidelity - MAE: 0.5687, MSE: 0.6143, RMSE: 0.7837, R^2: 0.9976\n",
      "2025-06-20 13:59:00,884 - __main__ - INFO - Outer Fold 4 - Train Indices: [ 0  3  4  5  6  8  9 12 14 15], Test Indices: [ 1  2  7 10 11 13 20 21 22 27]\n",
      "2025-06-20 13:59:00,885 - __main__ - INFO - -------------------- Outer Fold 4 --------------------\n",
      "2025-06-20 13:59:00,886 - __main__ - INFO - Starting hyperparameter optimization for outer fold 4...\n",
      "[I 2025-06-20 13:59:00,887] A new study created in memory with name: 197.4.grande(tabpfn).re.re\n",
      "2025-06-20 13:59:00,888 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:59:00,889 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 1...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:59:15,194 - __main__ - INFO - \t MAE: 1.8300, MSE: 7.4372, RMSE: 2.7271, R^2: 0.9756\n",
      "2025-06-20 13:59:15,196 - __main__ - INFO - \t Fidelity - MAE: 0.7755, MSE: 1.1874, RMSE: 1.0897, R^2: 0.9953\n",
      "2025-06-20 13:59:15,198 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:59:15,198 - __main__ - INFO - Training Model on Outer Fold 4, Inner Fold 2...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:59:32,228 - __main__ - INFO - \t MAE: 1.8701, MSE: 8.2223, RMSE: 2.8675, R^2: 0.9772\n",
      "2025-06-20 13:59:32,229 - __main__ - INFO - \t Fidelity - MAE: 0.6963, MSE: 1.0006, RMSE: 1.0003, R^2: 0.9967\n",
      "[I 2025-06-20 13:59:32,230] Trial 0 finished with value: -0.735913832667109 and parameters: {}. Best is trial 0 with value: -0.735913832667109.\n",
      "2025-06-20 13:59:32,230 - __main__ - INFO - Best hyperparameters for fold 4: {'depth': 5, 'n_estimators': 2048, 'learning_rate_weights': 0.005, 'learning_rate_index': 0.01, 'learning_rate_values': 0.01, 'learning_rate_leaf': 0.01, 'optimizer': 'adam', 'cosine_decay_steps': 0, 'dropout': 0.0, 'selected_variables': 0.8, 'data_subset_fraction': 1.0, 'focal_loss': False, 'temperature': 0.0, 'from_logits': True, 'use_class_weights': True, 'loss': 'mse'}\n",
      "2025-06-20 13:59:32,231 - __main__ - INFO - Best score: -0.7359\n",
      "2025-06-20 13:59:32,231 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:59:32,232 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 13:59:32,232 - __main__ - INFO - Retraining Model on Outer Fold 4\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 13:59:54,520 - __main__ - INFO - \t Inference Time: 1.00376 seconds\n",
      "2025-06-20 13:59:54,522 - __main__ - INFO - \t MAE: 1.9179, MSE: 8.3594, RMSE: 2.8913, R^2: 0.9770\n",
      "2025-06-20 13:59:54,523 - __main__ - INFO - \t Fidelity - MAE: 0.5490, MSE: 0.5900, RMSE: 0.7681, R^2: 0.9980\n",
      "2025-06-20 13:59:54,524 - __main__ - INFO - Outer Fold 5 - Train Indices: [ 0  1  2  6  7  8 10 11 12 13], Test Indices: [ 3  4  5  9 16 34 54 55 64 66]\n",
      "2025-06-20 13:59:54,525 - __main__ - INFO - -------------------- Outer Fold 5 --------------------\n",
      "2025-06-20 13:59:54,526 - __main__ - INFO - Starting hyperparameter optimization for outer fold 5...\n",
      "[I 2025-06-20 13:59:54,527] A new study created in memory with name: 197.5.grande(tabpfn).re.re\n",
      "2025-06-20 13:59:54,528 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 13:59:54,529 - __main__ - INFO - Training Model on Outer Fold 5, Inner Fold 1...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 14:00:13,534 - __main__ - INFO - \t MAE: 1.9166, MSE: 9.6594, RMSE: 3.1080, R^2: 0.9714\n",
      "2025-06-20 14:00:13,536 - __main__ - INFO - \t Fidelity - MAE: 0.7571, MSE: 1.5408, RMSE: 1.2413, R^2: 0.9945\n",
      "2025-06-20 14:00:13,538 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 14:00:13,538 - __main__ - INFO - Training Model on Outer Fold 5, Inner Fold 2...\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 14:00:29,838 - __main__ - INFO - \t MAE: 1.8639, MSE: 8.0448, RMSE: 2.8363, R^2: 0.9738\n",
      "2025-06-20 14:00:29,840 - __main__ - INFO - \t Fidelity - MAE: 0.7704, MSE: 1.2842, RMSE: 1.1332, R^2: 0.9950\n",
      "[I 2025-06-20 14:00:29,841] Trial 0 finished with value: -0.7637231059652078 and parameters: {}. Best is trial 0 with value: -0.7637231059652078.\n",
      "2025-06-20 14:00:29,841 - __main__ - INFO - Best hyperparameters for fold 5: {'depth': 5, 'n_estimators': 2048, 'learning_rate_weights': 0.005, 'learning_rate_index': 0.01, 'learning_rate_values': 0.01, 'learning_rate_leaf': 0.01, 'optimizer': 'adam', 'cosine_decay_steps': 0, 'dropout': 0.0, 'selected_variables': 0.8, 'data_subset_fraction': 1.0, 'focal_loss': False, 'temperature': 0.0, 'from_logits': True, 'use_class_weights': True, 'loss': 'mse'}\n",
      "2025-06-20 14:00:29,841 - __main__ - INFO - Best score: -0.7637\n",
      "2025-06-20 14:00:29,842 - __main__ - INFO - No preprocessing required for Grande model.\n",
      "2025-06-20 14:00:29,842 - __main__ - INFO - ------------------------------------------------------\n",
      "2025-06-20 14:00:29,842 - __main__ - INFO - Retraining Model on Outer Fold 5\n",
      "/home/mherre/miniconda3/envs/thesis/lib/python3.9/site-packages/GRANDE/GRANDE.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.num_columns] = X[self.num_columns].fillna(self.mean_train_num)\n",
      "2025-06-20 14:00:53,110 - __main__ - INFO - \t Inference Time: 1.01785 seconds\n",
      "2025-06-20 14:00:53,112 - __main__ - INFO - \t MAE: 1.9351, MSE: 8.9796, RMSE: 2.9966, R^2: 0.9776\n",
      "2025-06-20 14:00:53,113 - __main__ - INFO - \t Fidelity - MAE: 0.5588, MSE: 0.7214, RMSE: 0.8494, R^2: 0.9978\n",
      "2025-06-20 14:00:53,116 - __main__ - INFO - Outer fold metrics saved to: data/outer_fold/student/default/197_grande(tabpfn)_re.csv\n",
      "2025-06-20 14:00:53,117 - __main__ - INFO - === FINAL RESULTS FOR DATASET 197 ===\n",
      "2025-06-20 14:00:53,117 - __main__ - INFO - MAE: 1.8668 ± 0.0580\n",
      "2025-06-20 14:00:53,117 - __main__ - INFO - MSE: 8.0006 ± 0.6578\n",
      "2025-06-20 14:00:53,118 - __main__ - INFO - RMSE: 2.8267 ± 0.1151\n",
      "2025-06-20 14:00:53,118 - __main__ - INFO - R2: 0.9762 ± 0.0013\n",
      "2025-06-20 14:00:53,119 - __main__ - INFO - Fidelity MAE: 0.5571 ± 0.0180\n",
      "2025-06-20 14:00:53,119 - __main__ - INFO - Fidelity MSE: 0.6160 ± 0.0732\n",
      "2025-06-20 14:00:53,119 - __main__ - INFO - Fidelity RMSE: 0.7838 ± 0.0466\n",
      "2025-06-20 14:00:53,119 - __main__ - INFO - Fidelity R2: 0.9978 ± 0.0002\n",
      "2025-06-20 14:00:53,119 - __main__ - INFO - Mean Inference Time: 1.0574 ± 0.0639\n",
      "2025-06-20 14:00:53,120 - __main__ - INFO - Mean Parameters: 2732032.0000 ± 0.0000\n",
      "2025-06-20 14:00:53,123 - __main__ - INFO - Summary statistics saved to: results/student/197_results.json\n",
      "2025-06-20 14:00:53,131 - __main__ - INFO - grande outputs saved to: data/output/default/student/197_grande(tabpfn)_re.csv\n"
     ]
    }
   ],
   "source": [
    "# Get list of datasets to process from configuration\n",
    "datasets = config[\"data\"][\"datasets\"]\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN TRAINING LOOP - Process each dataset independently\n",
    "# =============================================================================\n",
    "for dataset_id in datasets:\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SETUP AND INITIALIZATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    logger = setup_logging()\n",
    "    logger.info(\"Loading configuration...\")\n",
    "\n",
    "    # Extract model configuration for this run\n",
    "    student_model_type = config[\"model\"][\"student_model\"]\n",
    "    teacher_model_type = config[\"model\"][\"teacher_model\"]\n",
    "    preprocessing_type = config[\"student_models\"][student_model_type][\"preprocessing\"]\n",
    "    use_hpo = config[\"training\"][\"use_hpo\"]\n",
    "    train_on_logits = config[\"training\"][\"train_on_logits\"]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 0: DATA LOADING\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Load dataset from OpenML with caching for efficiency\n",
    "    X, y, cat_cols, _, original_task_type = load_dataset(\n",
    "        dataset_id=dataset_id,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 1: INFRASTRUCTURE SETUP\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Note: Checking for existing results is placeholder for future implementation\n",
    "    model_task_type = \"binary\" if (original_task_type == \"binary\" and not train_on_logits) else \"regression\"\n",
    "    summary_file = os.path.join(config[\"data\"][\"results_dir_path\"], \"student\", f\"{dataset_id}_results.json\")\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file, 'r') as f:\n",
    "            existing_results = json.load(f)\n",
    "        \n",
    "        # Check if we already have results with the same configuration\n",
    "        config_exists = False\n",
    "        for key, result in existing_results.items():\n",
    "            if (result.get('student_model_type') == student_model_type and \n",
    "                result.get('teacher_model_type') == teacher_model_type and\n",
    "                result.get('student_task_type') == model_task_type and\n",
    "                result.get('use_hpo') == use_hpo and \n",
    "                result.get('seed') == config[\"training\"][\"random_state\"]):\n",
    "                config_exists = True\n",
    "                logger.info(f\"Results already exist for dataset {dataset_id} with model {student_model_type}({teacher_model_type}), HPO: {use_hpo}, seed: {config['training']['random_state']}\")\n",
    "                break\n",
    "        \n",
    "        if config_exists:\n",
    "            logger.info(f\"Skipping dataset {dataset_id} - results already computed\")\n",
    "            continue\n",
    "\n",
    "    # Configure GPU/CPU usage for training\n",
    "    device = check_GPU_availability()\n",
    "\n",
    "    # Set random seed for reproducibility across all libraries\n",
    "    set_seed(config[\"training\"][\"random_state\"])\n",
    "    logger.info(f\"Random seed set to {config['training']['random_state']}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 2: LOAD PREVIOUSLY SAVED FOLD INDICES AND TEACHER PREDICTIONS\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Load the saved fold indices\n",
    "    # Create the full directory structure\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    fold_indices_dir = os.path.join(config[\"data\"][\"fold_indices_path\"], sub_folder, \"teacher\")\n",
    "    fold_indices_file = os.path.join(fold_indices_dir, f\"{dataset_id}_{teacher_model_type}.json\")\n",
    "\n",
    "    with open(fold_indices_file, 'r') as f:\n",
    "        fold_indices = json.load(f)\n",
    "    logger.info(f\"Loaded fold indices from: {fold_indices_file}\") \n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 3: INITIALIZE DATA STRUCTURES\n",
    "    # -------------------------------------------------------------------------\n",
    "    output_dfs = []\n",
    "\n",
    "    outer_fold_scores = []\n",
    "\n",
    "    # =========================================================================\n",
    "    # STEP 4: OUTER CROSS-VALIDATION LOOP\n",
    "    # =========================================================================\n",
    "    # Each iteration provides one unbiased performance estimate\n",
    "    for fold_key, fold_data in fold_indices[\"outer_folds\"].items():\n",
    "        # Extract outer fold number and indices from the fold key\n",
    "        outer_fold = int(fold_key.split('_')[1])\n",
    "        train_idx = np.array(fold_data[\"train_idx\"])\n",
    "        test_idx = np.array(fold_data[\"test_idx\"])\n",
    "\n",
    "        # Log the first 10 indices of the outer fold for debugging\n",
    "        logger.info(f\"Outer Fold {outer_fold} - Train Indices: {train_idx[:10]}, Test Indices: {test_idx[:10]}\")\n",
    "\n",
    "        logger.info(f\"-------------------- Outer Fold {outer_fold} --------------------\")\n",
    "\n",
    "        # Split data according to current outer fold\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # --------------------------------------------------------------------------\n",
    "        # STEP 5: PREPROCESS TEACHER OUTPUTS\n",
    "        # --------------------------------------------------------------------------\n",
    "        if original_task_type == \"regression\":\n",
    "            model_task_type = \"regression\"\n",
    "            # For regression, we can use the outputs directly as they are already numeric\n",
    "            teacher_targets_train = np.array(fold_data[\"train_preds\"])\n",
    "            teacher_targets_test = np.array(fold_data[\"test_preds\"])\n",
    "        else:\n",
    "            if train_on_logits:\n",
    "                model_task_type = \"regression\"\n",
    "                # Convert probabilities to logits\n",
    "                # Clip probabilities to avoid log(0) or log(1)\n",
    "                eps = 1e-7\n",
    "                teacher_probs_train = np.clip(fold_data[\"train_preds\"], eps, 1 - eps)                \n",
    "                teacher_probs_test = np.clip(fold_data[\"test_preds\"], eps, 1 - eps)\n",
    "\n",
    "                teacher_targets_train = np.log(teacher_probs_train / (1 - teacher_probs_train))\n",
    "                teacher_targets_test = np.log(teacher_probs_test / (1 - teacher_probs_test))\n",
    "            else:\n",
    "                model_task_type = \"binary\"\n",
    "                # Prepare training targets (hard labels)\n",
    "                teacher_targets_train = (np.array(fold_data[\"train_preds\"]) > 0.5).astype(int)\n",
    "                # Prepare test targets (hard labels)\n",
    "                teacher_targets_test = (np.array(fold_data[\"test_preds\"]) > 0.5).astype(int)\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # INNER CROSS-VALIDATION SETUP (for model validation)\n",
    "        # ---------------------------------------------------------------------\n",
    "        inner_folds_data = fold_indices[\"inner_folds\"][f\"outer_fold_{outer_fold}\"]\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 6: INNER CROSS-VALIDATION LOOP (hyperparameter validation)\n",
    "        # =========================================================================\n",
    "        def objective(trial):\n",
    "            \n",
    "            hyperparams = suggest_hyperparameters(\n",
    "                trial=trial,\n",
    "                model_type=student_model_type,\n",
    "                task_type=model_task_type,\n",
    "                use_hpo=use_hpo,\n",
    "            )\n",
    "\n",
    "            inner_fold_scores = []\n",
    "            val_metrics_list = []\n",
    "\n",
    "            # This loop would typically be used for hyperparameter optimization\n",
    "            for inner_fold_key, inner_fold_data in inner_folds_data.items():\n",
    "                inner_fold = int(inner_fold_key.split('_')[2])\n",
    "                \n",
    "                # -----------------------------------------------------------------\n",
    "                # INDEX MANAGEMENT (Critical for avoiding data leakage)\n",
    "                # -----------------------------------------------------------------\n",
    "                # Get absolute indices from saved data\n",
    "                absolute_inner_train_idx = np.array(inner_fold_data[\"train_idx\"])\n",
    "                absolute_inner_val_idx = np.array(inner_fold_data[\"val_idx\"])\n",
    "                \n",
    "                # Convert absolute indices to relative indices for the current outer training set\n",
    "                inner_train_relative = np.where(np.isin(train_idx, absolute_inner_train_idx))[0]\n",
    "                inner_val_relative = np.where(np.isin(train_idx, absolute_inner_val_idx))[0] \n",
    "\n",
    "                # Split inner training data using relative indices\n",
    "                X_inner_train, X_inner_val = X_train.iloc[inner_train_relative], X_train.iloc[inner_val_relative]\n",
    "                y_inner_train, y_inner_val = y_train[inner_train_relative], y_train[inner_val_relative] # Hard labels or Regression targets\n",
    "\n",
    "                # Get teacher outputs for inner training and validation sets\n",
    "                teacher_outputs_inner_train = teacher_targets_train[inner_train_relative]\n",
    "                teacher_outputs_inner_val = teacher_targets_train[inner_val_relative]\n",
    "\n",
    "                # ---------------------------------------------------------------------\n",
    "                # PREPROCESSING: Apply model-specific data transformations\n",
    "                # ---------------------------------------------------------------------\n",
    "                X_inner_train, X_inner_val = preprocess(\n",
    "                    X_inner_train,\n",
    "                    y_inner_train,\n",
    "                    X_inner_val, \n",
    "                    cat_cols,\n",
    "                    config,\n",
    "                    preprocessing_type=preprocessing_type,\n",
    "                )\n",
    "                # ----------------------------------------------------------------------\n",
    "                # MODEL TRAINING: Train student model on inner training data\n",
    "                # ----------------------------------------------------------------------\n",
    "                model = get_student_model(config=config, task_type=model_task_type, device=device, hyperparams=hyperparams, cat_cols=cat_cols)\n",
    "                logger.info(f\"Training Model on Outer Fold {outer_fold}, Inner Fold {inner_fold}...\")\n",
    "                model.train(X_inner_train, teacher_outputs_inner_train)\n",
    "\n",
    "                # ----------------------------------------------------------------------\n",
    "                # VALIDATION: Evaluate model performance on inner validation set\n",
    "                # ----------------------------------------------------------------------\n",
    "                val_preds = model.predict(X_inner_val) # Probs or Regression logits\n",
    "                val_metrics = model.evaluate(y_pred=val_preds, y_true=y_inner_val, y_teacher_true=teacher_outputs_inner_val, original_task_type=original_task_type)\n",
    "\n",
    "                # Store metrics from this fold for later mean calculation\n",
    "                val_metrics_list.append(val_metrics)\n",
    "\n",
    "                if model_task_type == \"binary\":\n",
    "                    inner_fold_scores.append(val_metrics[\"fidelity_f1\"])\n",
    "                    trial.report(np.mean(inner_fold_scores), step=inner_fold)\n",
    "                else:\n",
    "                    inner_fold_scores.append(-val_metrics[\"fidelity_mae\"])\n",
    "                    trial.report(np.mean(inner_fold_scores), step=inner_fold)\n",
    "\n",
    "            # Calculate mean metrics as user attributes after all inner folds\n",
    "            if val_metrics_list:\n",
    "                # Get all metric keys from the first fold\n",
    "                metric_keys = val_metrics_list[0].keys()\n",
    "                \n",
    "                for metric_key in metric_keys:\n",
    "                    # Calculate mean across all inner folds for this metric\n",
    "                    metric_values = [fold_metrics[metric_key] for fold_metrics in val_metrics_list]\n",
    "                    mean_metric = np.mean(metric_values)\n",
    "                    trial.set_user_attr(f\"mean_{metric_key}\", mean_metric)\n",
    "\n",
    "            return np.mean(inner_fold_scores)\n",
    "        \n",
    "        logger.info(f\"Starting hyperparameter optimization for outer fold {outer_fold}...\")\n",
    "\n",
    "        study_kwargs = dict(\n",
    "            direction=\"maximize\",\n",
    "            study_name=f\"{dataset_id}.{outer_fold}.{student_model_type}({teacher_model_type}).{model_task_type[:2]}.{original_task_type[:2]}\",\n",
    "            load_if_exists=True,\n",
    "            sampler=optuna.samplers.TPESampler(seed=config[\"training\"][\"random_state\"]),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=1),\n",
    "        )\n",
    "\n",
    "        if use_hpo:\n",
    "            os.makedirs(config[\"data\"][\"optuna_db_path\"], exist_ok=True)\n",
    "            study_kwargs[\"storage\"] = f\"sqlite:///{config['data']['optuna_db_path']}/optuna.db\"\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            **study_kwargs,\n",
    "        )\n",
    "\n",
    "        # Optimize\n",
    "        completed_trials = len(study.trials)\n",
    "        remaining_trials = config[\"training\"][\"trials\"] - completed_trials\n",
    "\n",
    "\n",
    "        if remaining_trials > 0:\n",
    "            default_hyperparams = suggest_hyperparameters(None, student_model_type, model_task_type, False)\n",
    "            study.enqueue_trial(default_hyperparams)\n",
    "            study.optimize(\n",
    "                objective, \n",
    "                n_trials=remaining_trials if use_hpo else 1,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"The study has already reached the maximum number of trials.\")\n",
    "\n",
    "        if use_hpo:\n",
    "            # When HPO is used, trial.suggest_ methods are called, populating trial.params\n",
    "            best_hyperparams = study.best_trial.params\n",
    "        else:\n",
    "            # When not using HPO, a single trial runs with default parameters.\n",
    "            best_hyperparams = suggest_hyperparameters(trial=None, model_type=student_model_type, task_type=model_task_type, use_hpo=False)\n",
    "\n",
    "        logger.info(f\"Best hyperparameters for fold {outer_fold}: {best_hyperparams}\")\n",
    "        logger.info(f\"Best score: {study.best_value:.4f}\")\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 7: FINAL MODEL TRAINING (on complete outer training set)\n",
    "        # =========================================================================\n",
    "        # Preprocess the outer training and test sets\n",
    "        X_train, X_test = preprocess(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            cat_cols,\n",
    "            config,\n",
    "            preprocessing_type=preprocessing_type,  \n",
    "        )\n",
    "        \n",
    "        # Train final model on complete outer training set\n",
    "        logger.info(\"------------------------------------------------------\")\n",
    "        logger.info(f\"Retraining Model on Outer Fold {outer_fold}\")\n",
    "        model = get_student_model(\n",
    "            config=config,\n",
    "            task_type=model_task_type,\n",
    "            device=device,\n",
    "            hyperparams=best_hyperparams,  # Use best hyperparameters from HPO\n",
    "            cat_cols=cat_cols,  \n",
    "        )\n",
    "        model.train(X_train, teacher_targets_train)\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 8: FINAL EVALUATION (unbiased performance on outer test set)\n",
    "        # =========================================================================\n",
    "        # This provides the unbiased performance estimate for this fold\n",
    "        start_time = time.time()\n",
    "        test_preds = model.predict(X_test)  # Predicted logits or probabilities\n",
    "        end_time = time.time() - start_time\n",
    "        logger.info(f\"\\t Inference Time: {end_time:.5f} seconds\")\n",
    "        test_metrics = model.evaluate(test_preds, y_test, teacher_targets_test, original_task_type)\n",
    "\n",
    "        # Store outer fold score for later analysis\n",
    "        outer_fold_results = {\n",
    "            \"fold\": outer_fold,\n",
    "            \"seed\": config[\"training\"][\"random_state\"],\n",
    "            \"inference_time\": end_time,\n",
    "            **test_metrics,\n",
    "        }\n",
    "        outer_fold_scores.append(outer_fold_results)\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 9: STORE PREDICTIONS FOR STUDENT TRAINING\n",
    "        # =========================================================================\n",
    "        # Save predictions with their corresponding dataset indices\n",
    "        output_dfs.append(pd.DataFrame({\n",
    "            \"index\": test_idx,\n",
    "            \"output\": test_preds[:, 1] if model_task_type == \"binary\" else test_preds  \n",
    "        }))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 10: SAVE RESULTS AND METADATA\n",
    "    # =========================================================================\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE OUTER FOLD METRICS\n",
    "    # -------------------------------------------------------------------------\n",
    "    outer_fold_df = pd.DataFrame(outer_fold_scores)\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    output_dir = os.path.join(config[\"data\"][\"outer_folds_path\"], \"student\", sub_folder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    metrics_file = os.path.join(output_dir, f\"{dataset_id}_{student_model_type}({teacher_model_type})_{model_task_type[:2]}.csv\")\n",
    "    outer_fold_df.to_csv(metrics_file, index=False)\n",
    "    logger.info(f\"Outer fold metrics saved to: {metrics_file}\")\n",
    "\n",
    "    # Calculate and log overall performance across all folds\n",
    "    mean_inference_time = outer_fold_df['inference_time'].mean()\n",
    "    std_inference_time = outer_fold_df['inference_time'].std()\n",
    "    mean_parameters = outer_fold_df['parameters'].mean()\n",
    "    std_parameters = outer_fold_df['parameters'].std()\n",
    "\n",
    "    if original_task_type == \"binary\":\n",
    "        mean_acc = outer_fold_df['acc'].mean()\n",
    "        std_acc = outer_fold_df['acc'].std()\n",
    "        mean_f1 = outer_fold_df['f1'].mean()\n",
    "        std_f1 = outer_fold_df['f1'].std()\n",
    "        mean_roc = outer_fold_df['roc'].mean()\n",
    "        std_roc = outer_fold_df['roc'].std()\n",
    "        \n",
    "        mean_fidelity_acc = outer_fold_df['fidelity_acc'].mean()\n",
    "        std_fidelity_acc = outer_fold_df['fidelity_acc'].std()\n",
    "        mean_fidelity_f1 = outer_fold_df['fidelity_f1'].mean()\n",
    "        std_fidelity_f1 = outer_fold_df['fidelity_f1'].std()\n",
    "        mean_fidelity_roc = outer_fold_df['fidelity_roc'].mean()\n",
    "        std_fidelity_roc = outer_fold_df['fidelity_roc'].std()\n",
    "        mean_fidelity_kl_div = outer_fold_df['fidelity_kl_div'].mean()\n",
    "        std_fidelity_kl_div = outer_fold_df['fidelity_kl_div'].std()\n",
    "        \n",
    "        logger.info(f\"=== FINAL RESULTS FOR DATASET {dataset_id} ===\")\n",
    "        logger.info(f\"Balanced Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "        logger.info(f\"F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "        logger.info(f\"ROC AUC: {mean_roc:.4f} ± {std_roc:.4f}\")\n",
    "        logger.info(f\"Fidelity Accuracy: {mean_fidelity_acc:.4f} ± {std_fidelity_acc:.4f}\")\n",
    "        logger.info(f\"Fidelity F1 Score: {mean_fidelity_f1:.4f} ± {std_fidelity_f1:.4f}\")\n",
    "        logger.info(f\"Fidelity ROC AUC: {mean_fidelity_roc:.4f} ± {std_fidelity_roc:.4f}\")\n",
    "        logger.info(f\"Fidelity KL Divergence: {mean_fidelity_kl_div:.4f} ± {std_fidelity_kl_div:.4f}\")\n",
    "\n",
    "        if model_task_type == \"regression\":\n",
    "            mean_fidelity_mae = outer_fold_df['fidelity_mae'].mean()\n",
    "            std_fidelity_mae = outer_fold_df['fidelity_mae'].std()\n",
    "            mean_fidelity_mse = outer_fold_df['fidelity_mse'].mean()\n",
    "            std_fidelity_mse = outer_fold_df['fidelity_mse'].std()\n",
    "            mean_fidelity_rmse = outer_fold_df['fidelity_rmse'].mean()\n",
    "            std_fidelity_rmse = outer_fold_df['fidelity_rmse'].std()\n",
    "            mean_fidelity_r2 = outer_fold_df['fidelity_r2'].mean()\n",
    "            std_fidelity_r2 = outer_fold_df['fidelity_r2'].std()\n",
    "\n",
    "            logger.info(f\"Fidelity MAE: {mean_fidelity_mae:.4f} ± {std_fidelity_mae:.4f}\")\n",
    "            logger.info(f\"Fidelity MSE: {mean_fidelity_mse:.4f} ± {std_fidelity_mse:.4f}\")\n",
    "            logger.info(f\"Fidelity RMSE: {mean_fidelity_rmse:.4f} ± {std_fidelity_rmse:.4f}\")\n",
    "            logger.info(f\"Fidelity R2: {mean_fidelity_r2:.4f} ± {std_fidelity_r2:.4f}\")\n",
    "\n",
    "    else:\n",
    "        mean_mae = outer_fold_df['mae'].mean()\n",
    "        std_mae = outer_fold_df['mae'].std()\n",
    "        mean_mse = outer_fold_df['mse'].mean()\n",
    "        std_mse = outer_fold_df['mse'].std()\n",
    "        mean_rmse = outer_fold_df['rmse'].mean()\n",
    "        std_rmse = outer_fold_df['rmse'].std()\n",
    "        mean_r2 = outer_fold_df['r2'].mean()\n",
    "        std_r2 = outer_fold_df['r2'].std()\n",
    "\n",
    "        logger.info(f\"=== FINAL RESULTS FOR DATASET {dataset_id} ===\")\n",
    "        logger.info(f\"MAE: {mean_mae:.4f} ± {std_mae:.4f}\")\n",
    "        logger.info(f\"MSE: {mean_mse:.4f} ± {std_mse:.4f}\")\n",
    "        logger.info(f\"RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "        logger.info(f\"R2: {mean_r2:.4f} ± {std_r2:.4f}\")\n",
    "\n",
    "        mean_fidelity_mae = outer_fold_df['fidelity_mae'].mean()\n",
    "        std_fidelity_mae = outer_fold_df['fidelity_mae'].std()\n",
    "        mean_fidelity_mse = outer_fold_df['fidelity_mse'].mean()\n",
    "        std_fidelity_mse = outer_fold_df['fidelity_mse'].std()\n",
    "        mean_fidelity_rmse = outer_fold_df['fidelity_rmse'].mean()\n",
    "        std_fidelity_rmse = outer_fold_df['fidelity_rmse'].std()\n",
    "        mean_fidelity_r2 = outer_fold_df['fidelity_r2'].mean()\n",
    "        std_fidelity_r2 = outer_fold_df['fidelity_r2'].std()\n",
    "\n",
    "        logger.info(f\"Fidelity MAE: {mean_fidelity_mae:.4f} ± {std_fidelity_mae:.4f}\")\n",
    "        logger.info(f\"Fidelity MSE: {mean_fidelity_mse:.4f} ± {std_fidelity_mse:.4f}\")\n",
    "        logger.info(f\"Fidelity RMSE: {mean_fidelity_rmse:.4f} ± {std_fidelity_rmse:.4f}\")\n",
    "        logger.info(f\"Fidelity R2: {mean_fidelity_r2:.4f} ± {std_fidelity_r2:.4f}\")\n",
    "\n",
    "    logger.info(f\"Mean Inference Time: {mean_inference_time:.4f} ± {std_inference_time:.4f}\")\n",
    "    logger.info(f\"Mean Parameters: {mean_parameters:.4f} ± {std_parameters:.4f}\")\n",
    "\n",
    "    # Save summary statistics as well\n",
    "    summary_stats = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"student_model_type\": student_model_type,\n",
    "        \"teacher_model_type\": teacher_model_type,\n",
    "        \"original_task_type\": original_task_type,\n",
    "        \"student_task_type\": model_task_type,\n",
    "        \"seed\": config[\"training\"][\"random_state\"],\n",
    "        \"use_hpo\": config[\"training\"][\"use_hpo\"],\n",
    "        \"mean_inference_time\": mean_inference_time,\n",
    "        \"std_inference_time\": std_inference_time,\n",
    "        \"mean_parameters\": mean_parameters,\n",
    "        \"std_parameters\": std_parameters,\n",
    "    }\n",
    "\n",
    "    if original_task_type == \"binary\":\n",
    "        summary_stats.update({\n",
    "            \"mean_acc\": mean_acc,\n",
    "            \"std_acc\": std_acc,\n",
    "            \"mean_f1\": mean_f1,\n",
    "            \"std_f1\": std_f1,\n",
    "            \"mean_roc\": mean_roc,\n",
    "            \"std_roc\": std_roc,\n",
    "            \"mean_fidelity_acc\": mean_fidelity_acc,\n",
    "            \"std_fidelity_acc\": std_fidelity_acc,\n",
    "            \"mean_fidelity_f1\": mean_fidelity_f1,\n",
    "            \"std_fidelity_f1\": std_fidelity_f1,\n",
    "            \"mean_fidelity_roc\": mean_fidelity_roc,\n",
    "            \"std_fidelity_roc\": std_fidelity_roc,\n",
    "            \"mean_fidelity_kl_div\": mean_fidelity_kl_div,\n",
    "            \"std_fidelity_kl_div\": std_fidelity_kl_div,\n",
    "        })\n",
    "        if model_task_type == \"regression\":\n",
    "            summary_stats.update({\n",
    "                \"mean_fidelity_mae\": mean_fidelity_mae,\n",
    "                \"std_fidelity_mae\": std_fidelity_mae,\n",
    "                \"mean_fidelity_mse\": mean_fidelity_mse,\n",
    "                \"std_fidelity_mse\": std_fidelity_mse,\n",
    "                \"mean_fidelity_rmse\": mean_fidelity_rmse,\n",
    "                \"std_fidelity_rmse\": std_fidelity_rmse,\n",
    "                \"mean_fidelity_r2\": mean_fidelity_r2,\n",
    "                \"std_fidelity_r2\": std_fidelity_r2,\n",
    "            })\n",
    "    else:\n",
    "        summary_stats.update({\n",
    "            \"mean_mae\": mean_mae,\n",
    "            \"std_mae\": std_mae,\n",
    "            \"mean_mse\": mean_mse,\n",
    "            \"std_mse\": std_mse,\n",
    "            \"mean_rmse\": mean_rmse,\n",
    "            \"std_rmse\": std_rmse,\n",
    "            \"mean_r2\": mean_r2,\n",
    "            \"std_r2\": std_r2,\n",
    "            \"mean_fidelity_mae\": mean_fidelity_mae,\n",
    "            \"std_fidelity_mae\": std_fidelity_mae,\n",
    "            \"mean_fidelity_mse\": mean_fidelity_mse,\n",
    "            \"std_fidelity_mse\": std_fidelity_mse,\n",
    "            \"mean_fidelity_rmse\": mean_fidelity_rmse,\n",
    "            \"std_fidelity_rmse\": std_fidelity_rmse,\n",
    "            \"mean_fidelity_r2\": mean_fidelity_r2,\n",
    "            \"std_fidelity_r2\": std_fidelity_r2,\n",
    "        })\n",
    "\n",
    "    # Load existing summary file if it exists, otherwise create new\n",
    "    summary_file = os.path.join(config[\"data\"][\"results_dir_path\"], \"student\", f\"{dataset_id}_results.json\")\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(summary_file), exist_ok=True)\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file, 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "    else:\n",
    "        all_results = {}\n",
    "\n",
    "    # Add current model results to the dataset summary\n",
    "    # Use simple incremental numbering\n",
    "    next_num = len(all_results) + 1\n",
    "    model_key = str(next_num)\n",
    "\n",
    "    # Add current model results to the dataset summary\n",
    "    all_results[model_key] = summary_stats\n",
    "\n",
    "    # Save updated summary\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    logger.info(f\"Summary statistics saved to: {summary_file}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE STUDENT PREDICTIONS\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Combine predictions from all outer folds\n",
    "    if output_dfs:  # Check if we have any DataFrames to concatenate\n",
    "        output_df = pd.concat(output_dfs, ignore_index=True)\n",
    "    else:\n",
    "        output_df = pd.DataFrame(columns=[\"index\", \"output\"])\n",
    "    output_df = output_df.sort_values(by=\"index\")\n",
    "    \n",
    "    # Create the full directory structure\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    output_dir = os.path.join(config[\"data\"][\"output_dir_path\"], sub_folder, \"student\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_file = os.path.join(output_dir, f\"{dataset_id}_{student_model_type}({teacher_model_type})_{model_task_type[:2]}.csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    logger.info(f\"{config['model']['student_model']} outputs saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
