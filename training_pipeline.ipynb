{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eaf3d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 09:11:36.927838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-06 09:11:39.512703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mherre/.local/lib/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "/home/mherre/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, accuracy_score, f1_score, roc_auc_score,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, OneHotEncoder, LabelEncoder, TargetEncoder\n",
    ")\n",
    "\n",
    "# Deep learning imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model-specific imports\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "from GRANDE import GRANDE\n",
    "from packages.tabm_reference import Model, make_parameter_groups\n",
    "\n",
    "# Optimization imports\n",
    "import optuna\n",
    "\n",
    "# Data source imports\n",
    "import openml\n",
    "\n",
    "# Abstract base class imports\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Literal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae3463",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf7565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"\n",
    "    Set random seeds for reproducibility across Python, NumPy, PyTorch, and TensorFlow.\n",
    "\n",
    "    Args:\n",
    "        seed: Integer seed for random number generators\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "def setup_logging() -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Set up logging configuration.\n",
    "    This function configures the logging settings for the application, including\n",
    "    the logging level and format. It returns a logger instance that can be used\n",
    "    throughout the application.\n",
    "    Returns:\n",
    "        logging.Logger: Configured logger instance.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def check_GPU_availability():\n",
    "    \"\"\"\n",
    "    Checks if a GPU is available and configures TensorFlow to use it appropriately.\n",
    "\n",
    "    Sets up memory growth for TensorFlow GPU usage to avoid allocating all GPU memory at once.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: A torch device object ('cuda' if GPU is available, 'cpu' otherwise)\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "    if torch.cuda.is_available():\n",
    "        logger.info(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "        device = torch.device(\"cuda\")\n",
    "        gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        logger.info(\"Using CPU for training.\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14164da",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3635ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_target(y):\n",
    "    \"\"\"\n",
    "    Encode the target variable using LabelEncoder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array\n",
    "        The target variable to encode.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_encoded : np.array\n",
    "        The encoded target variable.\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    return y_encoded\n",
    "\n",
    "\n",
    "def preprocess(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_val: pd.DataFrame,\n",
    "    cat_cols: list,\n",
    "    config: dict,\n",
    "    preprocessing_type: str,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Preprocess the training and validation datasets based on the specified model type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pandas.DataFrame\n",
    "        The training dataset features.\n",
    "    y_train : pandas.Series or np.array\n",
    "        The target variable for the training dataset.\n",
    "    X_val : pandas.DataFrame\n",
    "        The validation dataset features.\n",
    "    cat_cols : list or array of bool\n",
    "        Boolean mask indicating which columns in X_train and X_val are categorical (True).\n",
    "    config : dict\n",
    "        Configuration dictionary containing model and preprocessing details.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : np.array\n",
    "        The preprocessed training dataset features.\n",
    "    X_val : np.array\n",
    "        The preprocessed validation dataset features.\n",
    "    \"\"\"\n",
    "    X_train, preprocessor_inner = _minimal_preprocess_train(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cat_cols,\n",
    "        preprocessing_type,\n",
    "        config,\n",
    "    )\n",
    "    X_val = _minimal_preprocess_test(X_val, preprocessor_inner)\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "\n",
    "def _minimal_preprocess_train(X, y, categorical_features, model_type, config):\n",
    "    \"\"\"\n",
    "    Perform minimal preprocessing on the input features for training.\n",
    "\n",
    "    This function applies preprocessing to both numeric and categorical features\n",
    "    based on the model type specified in the configuration. For Neural Networks,\n",
    "    it standardizes numeric features and one-hot encodes categorical features. For\n",
    "    tree-based models, it does not scale numeric features and applies different\n",
    "    encoding strategies for low- and high-cardinality categorical features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pandas.DataFrame\n",
    "        The input features.\n",
    "\n",
    "    categorical_features : list or array of bool\n",
    "        Boolean mask indicating which columns in X are categorical (True) and\n",
    "        which are numeric (False).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_preprocessed : np.array\n",
    "        The preprocessed features.\n",
    "    preprocessor : ColumnTransformer\n",
    "        The fitted preprocessor, which can be used to transform future datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the boolean mask to a NumPy array (if not already) for fast indexing.\n",
    "    cat_mask = np.asarray(categorical_features)\n",
    "\n",
    "    # Check that the mask length matches the number of columns in X.\n",
    "    if cat_mask.shape[0] != X.shape[1]:\n",
    "        raise ValueError(\n",
    "            \"Length of categorical_features mask must match the number of columns in X.\"\n",
    "        )\n",
    "\n",
    "    # Extract column names using boolean indexing.\n",
    "    categorical_feature_names = X.columns[cat_mask].tolist()\n",
    "    numeric_feature_names = X.columns[~cat_mask].tolist()\n",
    "\n",
    "    # Select pipeline based on config.\n",
    "    logger = setup_logging()\n",
    "\n",
    "    # Neural Networks: standardize numeric features and one-hot encode categoricals.\n",
    "    if model_type == \"nn\":\n",
    "\n",
    "        # Define the preprocessing pipeline for numeric features.\n",
    "        numeric_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Define the preprocessing pipeline for categorical features.\n",
    "        categorical_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\n",
    "                    \"onehot\",\n",
    "                    OneHotEncoder(\n",
    "                        drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        transformers = [\n",
    "            (\"num\", numeric_pipeline, numeric_feature_names),\n",
    "            (\"cat\", categorical_pipeline, categorical_feature_names),\n",
    "        ]\n",
    "\n",
    "        logger.info(\"Preprocessing pipeline for Neural Network model.\")\n",
    "\n",
    "    elif model_type == \"tree\":\n",
    "\n",
    "        # Tree-based models: leave numeric features unscaled, and differentiate encoding for categoricals.\n",
    "        numeric_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            ]\n",
    "        )\n",
    "        # Split categorical features into low- and high-cardinality groups.\n",
    "        threshold = config[\"preprocessing\"][\"threshold_high_cardinality\"]\n",
    "        low_card_features = []\n",
    "        high_card_features = []\n",
    "        for feature in categorical_feature_names:\n",
    "            if X[feature].nunique() <= threshold:\n",
    "                low_card_features.append(feature)\n",
    "            else:\n",
    "                high_card_features.append(feature)\n",
    "\n",
    "        # For low-cardinality categoricals, use one-hot encoding.\n",
    "        low_card_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\n",
    "                    \"onehot\",\n",
    "                    OneHotEncoder(\n",
    "                        drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # For high-cardinality categoricals, use target encoding.\n",
    "        high_card_pipeline = Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"target_encode\", TargetEncoder()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        transformers = [\n",
    "            (\"num\", numeric_pipeline, numeric_feature_names),\n",
    "            (\"low_card\", low_card_pipeline, low_card_features),\n",
    "            (\"high_card\", high_card_pipeline, high_card_features),\n",
    "        ]\n",
    "\n",
    "        logger.info(\"Preprocessing pipeline for Decision Tree model.\")\n",
    "\n",
    "    elif model_type == \"grande\":\n",
    "        logger.info(\"No preprocessing required for Grande model.\")\n",
    "        return X, None\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unknown teacher type. Must be 'nn' for Neural Network, 'tree' for Decision Tree, or 'grande' for Gradient Based Tree.\"\n",
    "        )\n",
    "\n",
    "    # Create a ColumnTransformer to apply the transformations to the appropriate columns.\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=transformers,\n",
    "        n_jobs=-2,\n",
    "    )\n",
    "\n",
    "    # Fit the preprocessor on the training data and transform it.\n",
    "    X_preprocessed = preprocessor.fit_transform(X, y)\n",
    "\n",
    "    return X_preprocessed, preprocessor\n",
    "\n",
    "\n",
    "def _minimal_preprocess_test(X, preprocessor):\n",
    "    \"\"\"\n",
    "    Transform the input features according to the preprocessor fitted on the training data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pandas.DataFrame\n",
    "        The input features.\n",
    "    preprocessor : ColumnTransformer\n",
    "        The preprocessor fitted on the training data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_preprocessed : np.array\n",
    "        The preprocessed features.\n",
    "    \"\"\"\n",
    "    if preprocessor is None:\n",
    "        return X\n",
    "    return preprocessor.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d700d2",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f642a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_id: int, config: dict):\n",
    "    \"\"\"\n",
    "    Loads an OpenML dataset based on its ID and processes it according to the task type.\n",
    "\n",
    "    This function fetches the dataset using the _fetch_dataset helper, then processes\n",
    "    the target variable based on whether the task is binary classification or regression.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_id (int): The ID of the dataset on OpenML.\n",
    "        config (dict): Configuration dictionary containing data paths and settings.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - X: The feature data (pandas DataFrame)\n",
    "            - y: The processed target variable (encoded for binary classification or numpy array for regression)\n",
    "            - cat_cols: List of booleans indicating which features are categorical\n",
    "            - attribute_names: List of attribute names\n",
    "            - task_type: String indicating the task type ('binary' or 'regression')\n",
    "    \"\"\"\n",
    "    X, y, cat_cols, attribute_names, task_type = fetch_dataset(\n",
    "        dataset_id=dataset_id,\n",
    "        cache_dir=config[\"data\"][\"cache_dir_path\"],\n",
    "    )\n",
    "    if task_type == \"binary\":\n",
    "        # Encode the target variable if it's binary\n",
    "        y = encode_target(y)\n",
    "    else:\n",
    "        # Transform to np.array for regression\n",
    "        y = np.array(y, dtype=float)\n",
    "\n",
    "    return X, y, cat_cols, attribute_names, task_type\n",
    "\n",
    "\n",
    "def fetch_dataset(dataset_id: int, cache_dir: str = \"data/cache/\"):\n",
    "    \"\"\"\n",
    "    Downloads an OpenML dataset based on its id, caches the data locally, and returns the data\n",
    "    along with its metadata.\n",
    "\n",
    "    The five returned objects are:\n",
    "        - X: The feature data (typically a pandas DataFrame).\n",
    "        - y: The target variable.\n",
    "        - categorical_indicator: A list of booleans indicating which features are categorical.\n",
    "        - attribute_names: A list of attribute names.\n",
    "        - task_type: A string indicating the type of task ('binary' or 'regression').\n",
    "\n",
    "    If the dataset has been previously downloaded and stored in the cache directory,\n",
    "    it will be loaded from the local file instead of re-downloading.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_id (int): The id of the dataset on OpenML.\n",
    "        cache_dir (str): The directory to store the downloaded dataset. Defaults to \"openml_cache\".\n",
    "\n",
    "    Returns:\n",
    "        X, y, categorical_indicator, attribute_names, task_type\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "\n",
    "    # Ensure the cache directory exists\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    # Define a cache file name that is unique to the dataset id\n",
    "    cache_file = os.path.join(cache_dir, f\"openml_dataset_{dataset_id}.pkl\")\n",
    "\n",
    "    # If the cache file exists, load the data from the file.\n",
    "    if os.path.exists(cache_file):\n",
    "        logger.info(\n",
    "            f\"Loading dataset {dataset_id} from cache at '{cache_file}'...\"\n",
    "        )\n",
    "        with open(cache_file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        X = data[\"X\"]\n",
    "        y = data[\"y\"]\n",
    "        categorical_indicator = data[\"categorical_indicator\"]\n",
    "        attribute_names = data[\"attribute_names\"]\n",
    "        task_type = data[\"task_type\"]\n",
    "    else:\n",
    "        # Download the dataset from OpenML.\n",
    "        logger.info(f\"Downloading dataset {dataset_id} from OpenML...\")\n",
    "        dataset = openml.datasets.get_dataset(dataset_id)\n",
    "\n",
    "        # Use the default target attribute (if defined) when retrieving the data.\n",
    "        X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            target=dataset.default_target_attribute, dataset_format=\"dataframe\"\n",
    "        )\n",
    "\n",
    "        # Determine the task type (binary classification or regression)\n",
    "        task_type = _determine_task_type(y)\n",
    "\n",
    "        # Store the data and metadata in a dictionary.\n",
    "        data = {\n",
    "            \"X\": X,\n",
    "            \"y\": y,\n",
    "            \"categorical_indicator\": categorical_indicator,\n",
    "            \"attribute_names\": attribute_names,\n",
    "            \"task_type\": task_type,\n",
    "        }\n",
    "\n",
    "        # Save the dictionary to a local file using pickle.\n",
    "        with open(cache_file, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "        logger.info(f\"Dataset {dataset_id} stored locally at '{cache_file}'.\")\n",
    "\n",
    "    logger.info(f\"Dataset {dataset_id} loaded successfully with task type: {task_type}\")\n",
    "\n",
    "    return X, y, categorical_indicator, attribute_names, task_type\n",
    "\n",
    "\n",
    "def _determine_task_type(y):\n",
    "    \"\"\"\n",
    "    Determines if the target variable is for binary classification, or regression.\n",
    "\n",
    "    Parameters:\n",
    "        y: The target variable (pandas dataframe).\n",
    "\n",
    "    Returns:\n",
    "        str: 'binary', or 'regression'\n",
    "    \"\"\"\n",
    "\n",
    "    # Get unique values\n",
    "    unique_values = pd.unique(y)\n",
    "\n",
    "    # Check if it's binary (2 unique values)\n",
    "    if len(unique_values) == 2:\n",
    "        return \"binary\"\n",
    "    else:\n",
    "        return \"regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4579812",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee7681de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_prob, y_true):\n",
    "    \"\"\"\n",
    "    Evaluate classification performance using balanced accuracy, F1 score, and ROC AUC.\n",
    "\n",
    "    Parameters:\n",
    "        y_prob (np.array): Predicted probabilities for the positive class.\n",
    "        y_true (np.array): True labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "    y_pred = (y_prob[:, 1] > 0.5).astype(int)\n",
    "    acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    roc_auc = roc_auc_score(y_true, y_prob[:, 1])\n",
    "\n",
    "    logger.info(f\"\\t Balanced Accuracy: {acc:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"roc\": roc_auc,\n",
    "    }\n",
    "\n",
    "def evaluate_regression(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Evaluate regression performance using R^2 score.\n",
    "\n",
    "    Parameters:\n",
    "        y_pred (np.array): Predicted values.\n",
    "        y_true (np.array): True values.\n",
    "\n",
    "    Returns:\n",
    "        float: R^2 score.\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    logger.info(f\"\\t MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"mae\": mae,\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse,\n",
    "        \"r2\": r2,\n",
    "    }\n",
    "\n",
    "def evaluate_fidelity_classification(y_prob_student, y_prob_teacher):\n",
    "    \"\"\"\n",
    "    Evaluate the fidelity of a student model compared to a teacher model in classification tasks.\n",
    "\n",
    "    Parameters:\n",
    "        y_prob_teacher (np.array): Predicted probabilities from the teacher model.\n",
    "        y_prob_student (np.array): Predicted probabilities from the student model.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics for fidelity.\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "\n",
    "    y_pred_student = (y_prob_student[:, 1] > 0.5).astype(int)\n",
    "\n",
    "    if y_prob_teacher.ndim == 2:\n",
    "        # y_prob_teacher is a 2D array of probabilities\n",
    "        y_pred_teacher = (y_prob_teacher[:, 1] > 0.5).astype(int)\n",
    "    elif y_prob_teacher.ndim == 1:\n",
    "        # y_prob_teacher is a 1D array, assumed to be predicted labels\n",
    "        y_pred_teacher = y_prob_teacher.astype(int)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"y_prob_teacher has unexpected shape: {y_prob_teacher.shape}\"\n",
    "        )\n",
    "    \n",
    "    acc = balanced_accuracy_score(y_pred_teacher, y_pred_student)\n",
    "    f1 = f1_score(y_pred_teacher, y_pred_student, average=\"macro\")\n",
    "    roc_auc = roc_auc_score(y_pred_teacher, y_prob_student[:, 1])\n",
    "\n",
    "    logger.info(f\"\\t Fidelity - Balanced Accuracy: {acc:.4f}, F1 Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"fidelity_acc\": acc,\n",
    "        \"fidelity_f1\": f1,\n",
    "        \"fidelity_roc\": roc_auc,\n",
    "    }\n",
    "\n",
    "def evaluate_fidelity_regression(y_pred_student, y_pred_teacher):\n",
    "    \"\"\"\n",
    "    Evaluate the fidelity of a student model compared to a teacher model in regression tasks.\n",
    "\n",
    "    Parameters:\n",
    "        y_pred_teacher (np.array): Predicted values from the teacher model.\n",
    "        y_pred_student (np.array): Predicted values from the student model.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics for fidelity.\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "\n",
    "    mae = mean_absolute_error(y_pred_teacher, y_pred_student)\n",
    "    mse = mean_squared_error(y_pred_teacher, y_pred_student)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_pred_teacher, y_pred_student)\n",
    "\n",
    "    logger.info(f\"\\t Fidelity - MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"fidelity_mae\": mae,\n",
    "        \"fidelity_mse\": mse,\n",
    "        \"fidelity_rmse\": rmse,\n",
    "        \"fidelity_r2\": r2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8af1a5",
   "metadata": {},
   "source": [
    "# Model Factory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb36799",
   "metadata": {},
   "source": [
    "## Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9825c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherModelBase(ABC):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.params = kwargs\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Trains the model on the given data.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.ndarray): The input features with shape (n_samples, n_features).\n",
    "            y (np.ndarray): The target labels with shape (n_samples,).\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Makes predictions on the provided data.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.ndarray): The input features with shape (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: An array of predicted probabilities with shape (n_samples, n_classes).\n",
    "                        (If the model returns logits, these should be post-processed to probabilities.)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, y_pred: np.ndarray, y_true: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluates the model's predictions against the true labels.\n",
    "\n",
    "        Parameters:\n",
    "            y_pred (np.ndarray): The predicted probabilities or values.\n",
    "            y_true (np.ndarray): The true labels.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: A dictionary containing evaluation metrics.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            metrics = evaluate_classification(y_pred, y_true)\n",
    "            metrics['parameters'] = self.count_parameters()\n",
    "            return metrics\n",
    "        \n",
    "        elif self.task_type == \"regression\":\n",
    "            metrics = evaluate_regression(y_pred, y_true)\n",
    "            metrics['parameters'] = self.count_parameters()\n",
    "            return metrics\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task type: {self.task_type}. Must be 'binary' or 'regression'.\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def count_parameters(self) -> int:\n",
    "        \"\"\"\n",
    "        Counts the number of trainable parameters in the model.\n",
    "\n",
    "        Returns:\n",
    "            int: The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class TabPFNTeacherModel(TeacherModelBase):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a TabPFN teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base\n",
    "            class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y, **training_params):\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model = TabPFNClassifier()\n",
    "        else:\n",
    "            self.model = TabPFNRegressor()\n",
    "        # If X is bigger than 10000 samples, reduce data size to 10000\n",
    "        if X.shape[0] > 10000:\n",
    "            X = X[:10000]\n",
    "            y = y[:10000]\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "\n",
    "    def count_parameters(self) -> int:\n",
    "        \"\"\"\n",
    "        Counts the number of trainable parameters in the underlying TabPFN model.\n",
    "\n",
    "        Returns:\n",
    "            int: Total number of trainable parameters.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the TabPFN model has not been fitted yet.\n",
    "        \"\"\"\n",
    "        if not hasattr(self.model, \"model_\"):\n",
    "            raise ValueError(\n",
    "                \"The TabPFN model is not fitted yet. Please call fit() first.\"\n",
    "            )\n",
    "        return sum(p.numel() for p in self.model.model_.parameters() if p.requires_grad)\n",
    "    \n",
    "\n",
    "class CatBoostTeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a CatBoost teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the CatBoost model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the CatBoost model's fit method.\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        # Initialize the CatBoost model\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model = CatBoostClassifier(\n",
    "                random_seed=random_state,\n",
    "                thread_count=-1,  # Use all available CPU cores\n",
    "                logging_level=\"Silent\",  # Suppress CatBoost output\n",
    "                task_type=(\"GPU\" if str(self.device).lower() == \"cuda\" else \"CPU\"),\n",
    "                **self.hyperparams,  # Include the sampled hyperparameters\n",
    "            )\n",
    "        else:\n",
    "            self.model = CatBoostRegressor(\n",
    "                random_seed=random_state,\n",
    "                thread_count=-1,  # Use all available CPU cores\n",
    "                logging_level=\"Silent\",  # Suppress CatBoost output\n",
    "                task_type=(\"GPU\" if str(self.device).lower() == \"cuda\" else \"CPU\"),\n",
    "                **self.hyperparams,  # Include the sampled hyperparameters\n",
    "            )\n",
    "\n",
    "        # Split data into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        # Train the model\n",
    "        self.model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=(X_val, y_val),\n",
    "            early_stopping_rounds=20, \n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples, n_classes)\n",
    "            The predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of parameters in the trained CatBoost model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of parameters in the model.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\") or self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet.\")\n",
    "\n",
    "        # Get the number of trees in the model\n",
    "        tree_count = self.model.tree_count_\n",
    "\n",
    "        # For each tree, count:\n",
    "        # - split values (one per non-leaf node)\n",
    "        # - leaf values (one per leaf node)\n",
    "        # - feature indices (one per non-leaf node)\n",
    "        # For a binary tree with depth d, there are 2^d - 1 non-leaf nodes and 2^d leaf nodes\n",
    "        # This is a simplified approximation\n",
    "        approx_depth = self.hyperparams.get(\"max_depth\", 6)  # Default depth in CatBoost is 6\n",
    "        non_leaf_nodes = 2**approx_depth - 1\n",
    "        leaf_nodes = 2**approx_depth\n",
    "\n",
    "        # Total parameters per tree\n",
    "        params_per_tree = (\n",
    "            non_leaf_nodes * 2 + leaf_nodes\n",
    "        )  # split values + feature indices + leaf values\n",
    "        return tree_count * params_per_tree\n",
    "    \n",
    "\n",
    "class GRANDETeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a GRANDE teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments. The `device` parameter is popped from kwargs and\n",
    "            defaults to 'cpu' if not provided.\n",
    "        \"\"\"\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "        os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        self.cat_cols = kwargs.pop(\"cat_cols\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the GRANDE teacher model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the GRANDE model's fit method.\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        # Determine categorical indices\n",
    "        cat_indices = [i for i, is_cat in enumerate(self.cat_cols) if is_cat]\n",
    "\n",
    "        training_params = {\n",
    "            \"epochs\": 1000,\n",
    "            \"early_stopping_epochs\": 25,\n",
    "            \"batch_size\": 64,\n",
    "            \"cat_idx\": cat_indices,\n",
    "            \"random_seed\": random_state,\n",
    "        }\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            training_params[\"objective\"] = \"binary\"\n",
    "        else:\n",
    "            training_params[\"objective\"] = \"regression\"\n",
    "\n",
    "        # Instantiate the GRANDE teacher model.\n",
    "        self.model = GRANDE(params=self.hyperparams, args=training_params)\n",
    "\n",
    "        # Split the data into training and validation sets.\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        self.model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given input data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like\n",
    "            The predicted target values.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict(X)\n",
    "        else:\n",
    "            return self.model.predict(X).squeeze()\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the GRANDE teacher model based on the\n",
    "        dense representation of a single tree and the number of trees in the ensemble.\n",
    "\n",
    "        The number of parameters for a single tree is computed as:\n",
    "            leaf parameters: 2^d\n",
    "            split thresholds: (2^d - 1) * n\n",
    "            feature selection (one-hot): (2^d - 1) * n\n",
    "        so that:\n",
    "            params_per_tree = 2^d + 2 * n * (2^d - 1)\n",
    "        The total is then:\n",
    "            total_params = n_estimators * params_per_tree\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained/initialized yet.\")\n",
    "\n",
    "        # These attributes must be set when the GRANDE model is instantiated.\n",
    "        # Adjust the attribute names if they are different in your GRANDE implementation.\n",
    "        d = self.model.depth  # Depth of each decision tree.\n",
    "        n = self.model.number_of_variables  # Number of features used in the tree.\n",
    "        E = self.model.n_estimators  # Number of trees in the ensemble.\n",
    "\n",
    "        # Calculate the number of parameters for one tree.\n",
    "        params_per_tree = (2**d) + 2 * n * ((2**d) - 1)\n",
    "        total_params = E * params_per_tree\n",
    "\n",
    "        return total_params\n",
    "    \n",
    "class TabMTeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a TabM teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Set up AMP if CUDA is available.\n",
    "        if torch.cuda.is_available():\n",
    "            self.amp_dtype = (\n",
    "                torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "            )\n",
    "            self.amp_enabled = True\n",
    "        else:\n",
    "            self.amp_dtype = None\n",
    "            self.amp_enabled = False\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the TabM model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the TabM model's fit method.\n",
    "        \"\"\"\n",
    "        # Get parameters\n",
    "        n_blocks = self.hyperparams.get(\"n_blocks\")\n",
    "        d_block = self.hyperparams.get(\"d_block\")\n",
    "        dropout = self.hyperparams.get(\"dropout\")\n",
    "        lr = self.hyperparams.get(\"learning_rate\")\n",
    "        weight_decay = self.hyperparams.get(\"weight_decay\")\n",
    "\n",
    "        # Set model architecture\n",
    "        arch_type = \"tabm\"\n",
    "        bins = None\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            n_classes = len(np.unique(y))\n",
    "            self.n_classes = n_classes\n",
    "            cat_idx = []  # Assumes all features are continuous\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=cat_idx,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=32,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        else:\n",
    "            if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "                # Multiclass logits\n",
    "                n_outputs = y.shape[1]\n",
    "            else:\n",
    "                # Binary or single-output regression\n",
    "                n_outputs = 1\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=[],  # Assumes all features are continuous\n",
    "                n_classes=n_outputs,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=32,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            make_parameter_groups(self.model), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        self.evaluation_mode = torch.no_grad if compile_model else torch.inference_mode\n",
    "\n",
    "        # Prepare data\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        if self.task_type == \"binary\":\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long, device=self.device)\n",
    "        else:\n",
    "            y_tensor = torch.tensor(y, dtype=torch.float32, device=self.device)\n",
    "        n_samples = X_tensor.size(0)\n",
    "        indices = torch.randperm(n_samples)\n",
    "        train_end = int(0.8 * n_samples)\n",
    "        train_idx, val_idx = indices[:train_end], indices[train_end:]\n",
    "        self.data = {\n",
    "            \"train\": {\"x_cont\": X_tensor[train_idx], \"y\": y_tensor[train_idx]},\n",
    "            \"val\": {\"x_cont\": X_tensor[val_idx], \"y\": y_tensor[val_idx]},\n",
    "        }\n",
    "        Y_train = self.data[\"train\"][\"y\"]\n",
    "\n",
    "        # Training parameters\n",
    "        n_epochs = 100000\n",
    "        patience = 16\n",
    "        batch_size = 256\n",
    "        train_size = len(Y_train)\n",
    "        best = {\"val\": -float(\"inf\"), \"epoch\": -1}\n",
    "        remaining_patience = patience\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            batches = torch.randperm(train_size, device=self.device).split(batch_size)\n",
    "            for batch_idx in batches:\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_fn(\n",
    "                    self.apply_model(\"train\", batch_idx), Y_train[batch_idx]\n",
    "                )\n",
    "                if self.amp_enabled and self.amp_dtype == torch.float16:\n",
    "                    scaler = torch.cuda.amp.GradScaler()\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            val_score = self.evaluate_tabm(\"val\")\n",
    "            if val_score > best[\"val\"]:\n",
    "                best = {\"val\": val_score, \"epoch\": epoch}\n",
    "                remaining_patience = patience\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "\n",
    "    def apply_model(self, part: str, idx: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply the model to a batch of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "        idx : torch.Tensor\n",
    "            The indices of the samples to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The model output.\n",
    "        \"\"\"\n",
    "        with torch.autocast(\n",
    "            self.device.type, enabled=self.amp_enabled, dtype=self.amp_dtype\n",
    "        ):\n",
    "            x_cont = self.data[part][\"x_cont\"][idx]\n",
    "            x_cat = self.data[part].get(\"x_cat\")\n",
    "            if self.task_type == \"binary\":\n",
    "                return self.model(x_cont, x_cat).float()\n",
    "            else:\n",
    "                return (\n",
    "                    self.model(x_cont, x_cat)\n",
    "                    .squeeze(-1)  # Remove the last dimension for regression tasks\n",
    "                    .float()\n",
    "                )\n",
    "\n",
    "    def loss_fn(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            The predicted outputs.\n",
    "        y_true : torch.Tensor\n",
    "            The ground truth.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss value.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            # Use the second-to-last dimension for averaging over k heads.\n",
    "            k = y_pred.shape[-2]\n",
    "            target = y_true.repeat_interleave(k)\n",
    "            return F.cross_entropy(y_pred.flatten(0, 1), target)\n",
    "        else:\n",
    "            # TabM produces k predictions. Each of them must be trained separately.\n",
    "            # For student model (regression on logits), y_pred.shape == (batch_size, k)\n",
    "            k = y_pred.shape[-1 if len(y_pred.shape) <= 2 else -2]\n",
    "\n",
    "            # Flatten the predictions and repeat the targets\n",
    "            return F.mse_loss(\n",
    "                y_pred.flatten(0, 1),\n",
    "                (\n",
    "                    y_true.repeat_interleave(k)\n",
    "                    if self.model.share_training_batches\n",
    "                    else y_true\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def evaluate_tabm(self, part: str) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model on a data partition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The accuracy score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with self.evaluation_mode():\n",
    "            eval_batch_size = 8096\n",
    "\n",
    "            if self.task_type == \"binary\":\n",
    "                indices = torch.arange(\n",
    "                    len(self.data[part][\"y\"]), device=self.device\n",
    "                ).split(eval_batch_size)\n",
    "                y_pred = torch.cat(\n",
    "                    [self.apply_model(part, idx) for idx in indices]\n",
    "                ).cpu()\n",
    "                y_pred = torch.softmax(y_pred, dim=-1).mean(1)\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "                return float(accuracy_score(y_true, y_pred.argmax(1)))\n",
    "            else:\n",
    "                y_pred = (\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            self.apply_model(part, idx)\n",
    "                            for idx in torch.arange(\n",
    "                                len(self.data[part][\"y\"]), device=self.device\n",
    "                            ).split(eval_batch_size)\n",
    "                        ]\n",
    "                    )\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "                # Transform the predictions back to the original label space\n",
    "                if hasattr(self, \"regression_label_stats\"):\n",
    "                    y_pred = (\n",
    "                        y_pred * self.regression_label_stats[\"std\"]\n",
    "                        + self.regression_label_stats[\"mean\"]\n",
    "                    )\n",
    "\n",
    "                # Compute the mean of the k predictions\n",
    "                y_pred = y_pred.mean(1)\n",
    "\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "\n",
    "                # For student model, we want to minimize MSE, so return negative MSE\n",
    "                # The higher the value, the better (consistent with example.ipynb)\n",
    "                score = -(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "                return float(score)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples,)\n",
    "            The predicted class indices.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(X_tensor)\n",
    "                # Since share_training_batches is True, average over the second dimension.\n",
    "                probs = torch.softmax(logits, dim=-1).mean(1)\n",
    "                return probs.cpu().numpy()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                # TabM produces output with shape (batch_size, k) or (batch_size, k, n_outputs)\n",
    "                logits = self.model(X_tensor)\n",
    "\n",
    "                # For student model (regression), we need to average over the k predictions\n",
    "                # Check the dimensions of logits and average appropriately\n",
    "                if logits.ndim > 2:  # Case: (batch_size, k, n_outputs)\n",
    "                    logits = logits.mean(1)  # Average over k dimension\n",
    "                elif (\n",
    "                    logits.shape[1] > 1\n",
    "                    and hasattr(self.model, \"k\")\n",
    "                    and self.model.k > 1\n",
    "                ):\n",
    "                    # Case: (batch_size, k) for single output regression\n",
    "                    logits = logits.mean(\n",
    "                        1, keepdim=True\n",
    "                    )  # Average and keep output dimension\n",
    "\n",
    "                return logits.cpu().numpy()\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained yet\")\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)    \n",
    "\n",
    "\n",
    "class MLPTeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a TabM teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Set up AMP if CUDA is available.\n",
    "        if torch.cuda.is_available():\n",
    "            self.amp_dtype = (\n",
    "                torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "            )\n",
    "            self.amp_enabled = True\n",
    "        else:\n",
    "            self.amp_dtype = None\n",
    "            self.amp_enabled = False\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the TabM model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the TabM model's fit method.\n",
    "        \"\"\"\n",
    "        # Get parameters\n",
    "        n_blocks = self.hyperparams.get(\"n_blocks\")\n",
    "        d_block = self.hyperparams.get(\"d_block\")\n",
    "        dropout = self.hyperparams.get(\"dropout\")\n",
    "        lr = self.hyperparams.get(\"learning_rate\")\n",
    "        weight_decay = self.hyperparams.get(\"weight_decay\")\n",
    "\n",
    "        # Set model architecture\n",
    "        arch_type = \"plain\"\n",
    "        bins = None\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            n_classes = len(np.unique(y))\n",
    "            self.n_classes = n_classes\n",
    "            cat_idx = []  # Assumes all features are continuous\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=cat_idx,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=None,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        else:\n",
    "            if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "                # Multiclass logits\n",
    "                n_outputs = y.shape[1]\n",
    "            else:\n",
    "                # Binary or single-output regression\n",
    "                n_outputs = 1\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=[],  # Assumes all features are continuous\n",
    "                n_classes=n_outputs,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=None,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            make_parameter_groups(self.model), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        self.evaluation_mode = torch.no_grad if compile_model else torch.inference_mode\n",
    "\n",
    "        # Prepare data\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        if self.task_type == \"binary\":\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long, device=self.device)\n",
    "        else:\n",
    "            y_tensor = torch.tensor(y, dtype=torch.float32, device=self.device)\n",
    "        n_samples = X_tensor.size(0)\n",
    "        indices = torch.randperm(n_samples)\n",
    "        train_end = int(0.8 * n_samples)\n",
    "        train_idx, val_idx = indices[:train_end], indices[train_end:]\n",
    "        self.data = {\n",
    "            \"train\": {\"x_cont\": X_tensor[train_idx], \"y\": y_tensor[train_idx]},\n",
    "            \"val\": {\"x_cont\": X_tensor[val_idx], \"y\": y_tensor[val_idx]},\n",
    "        }\n",
    "        Y_train = self.data[\"train\"][\"y\"]\n",
    "\n",
    "        # Training parameters\n",
    "        n_epochs = 100000\n",
    "        patience = 16\n",
    "        batch_size = 256\n",
    "        train_size = len(Y_train)\n",
    "        best = {\"val\": -float(\"inf\"), \"epoch\": -1}\n",
    "        remaining_patience = patience\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            batches = torch.randperm(train_size, device=self.device).split(batch_size)\n",
    "            for batch_idx in batches:\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_fn(\n",
    "                    self.apply_model(\"train\", batch_idx), Y_train[batch_idx]\n",
    "                )\n",
    "                if self.amp_enabled and self.amp_dtype == torch.float16:\n",
    "                    scaler = torch.cuda.amp.GradScaler()\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            val_score = self.evaluate_tabm(\"val\")\n",
    "            if val_score > best[\"val\"]:\n",
    "                best = {\"val\": val_score, \"epoch\": epoch}\n",
    "                remaining_patience = patience\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "\n",
    "    def apply_model(self, part: str, idx: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply the model to a batch of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "        idx : torch.Tensor\n",
    "            The indices of the samples to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The model output.\n",
    "        \"\"\"\n",
    "        with torch.autocast(\n",
    "            self.device.type, enabled=self.amp_enabled, dtype=self.amp_dtype\n",
    "        ):\n",
    "            x_cont = self.data[part][\"x_cont\"][idx]\n",
    "            x_cat = self.data[part].get(\"x_cat\")\n",
    "            if self.task_type == \"binary\":\n",
    "                return self.model(x_cont, x_cat).float()\n",
    "            else:\n",
    "                return (\n",
    "                    self.model(x_cont, x_cat)\n",
    "                    .squeeze(-1)  # Remove the last dimension for regression tasks\n",
    "                    .float()\n",
    "                )\n",
    "\n",
    "    def loss_fn(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            The predicted outputs.\n",
    "        y_true : torch.Tensor\n",
    "            The ground truth.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss value.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            # Use the second-to-last dimension for averaging over k heads.\n",
    "            k = y_pred.shape[-2]\n",
    "            target = y_true.repeat_interleave(k)\n",
    "            return F.cross_entropy(y_pred.flatten(0, 1), target)\n",
    "        else:\n",
    "            # TabM produces k predictions. Each of them must be trained separately.\n",
    "            # For student model (regression on logits), y_pred.shape == (batch_size, k)\n",
    "            k = y_pred.shape[-1 if len(y_pred.shape) <= 2 else -2]\n",
    "\n",
    "            # Flatten the predictions and repeat the targets\n",
    "            return F.mse_loss(\n",
    "                y_pred.flatten(0, 1),\n",
    "                (\n",
    "                    y_true.repeat_interleave(k)\n",
    "                    if self.model.share_training_batches\n",
    "                    else y_true\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def evaluate_tabm(self, part: str) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model on a data partition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The accuracy score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with self.evaluation_mode():\n",
    "            eval_batch_size = 8096\n",
    "\n",
    "            if self.task_type == \"binary\":\n",
    "                indices = torch.arange(\n",
    "                    len(self.data[part][\"y\"]), device=self.device\n",
    "                ).split(eval_batch_size)\n",
    "                y_pred = torch.cat(\n",
    "                    [self.apply_model(part, idx) for idx in indices]\n",
    "                ).cpu()\n",
    "                y_pred = torch.softmax(y_pred, dim=-1).mean(1)\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "                return float(accuracy_score(y_true, y_pred.argmax(1)))\n",
    "            else:\n",
    "                y_pred = (\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            self.apply_model(part, idx)\n",
    "                            for idx in torch.arange(\n",
    "                                len(self.data[part][\"y\"]), device=self.device\n",
    "                            ).split(eval_batch_size)\n",
    "                        ]\n",
    "                    )\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "                # Transform the predictions back to the original label space\n",
    "                if hasattr(self, \"regression_label_stats\"):\n",
    "                    y_pred = (\n",
    "                        y_pred * self.regression_label_stats[\"std\"]\n",
    "                        + self.regression_label_stats[\"mean\"]\n",
    "                    )\n",
    "\n",
    "                # Compute the mean of the k predictions\n",
    "                y_pred = y_pred.mean(1)\n",
    "\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "\n",
    "                # For student model, we want to minimize MSE, so return negative MSE\n",
    "                # The higher the value, the better (consistent with example.ipynb)\n",
    "                score = -(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "                return float(score)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples,)\n",
    "            The predicted class indices.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(X_tensor)\n",
    "                # Since share_training_batches is True, average over the second dimension.\n",
    "                probs = torch.softmax(logits, dim=-1).mean(1)\n",
    "                return probs.cpu().numpy()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                # TabM produces output with shape (batch_size, k) or (batch_size, k, n_outputs)\n",
    "                logits = self.model(X_tensor)\n",
    "\n",
    "                # For student model (regression), we need to average over the k predictions\n",
    "                # Check the dimensions of logits and average appropriately\n",
    "                if logits.ndim > 2:  # Case: (batch_size, k, n_outputs)\n",
    "                    logits = logits.mean(1)  # Average over k dimension\n",
    "                elif (\n",
    "                    logits.shape[1] > 1\n",
    "                    and hasattr(self.model, \"k\")\n",
    "                    and self.model.k > 1\n",
    "                ):\n",
    "                    # Case: (batch_size, k) for single output regression\n",
    "                    logits = logits.mean(\n",
    "                        1, keepdim=True\n",
    "                    )  # Average and keep output dimension\n",
    "\n",
    "                return logits.cpu().numpy()\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained yet\")\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "class GRANDETeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a GRANDE teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments. The `device` parameter is popped from kwargs and\n",
    "            defaults to 'cpu' if not provided.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\", \"cpu\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.dataset_id = kwargs.pop(\"dataset_id\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y, **training_params):\n",
    "        \"\"\"\n",
    "        Train the GRANDE teacher model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the GRANDE model's fit method.\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "        cat_idx = config[\"teacher_models\"][\"grande\"][\"hyperparameter_space\"][\n",
    "            f\"dataset_{self.dataset_id}\"\n",
    "        ][\"training_params\"].get(\"cat_idx\", None)\n",
    "\n",
    "        training_params[\"random_seed\"] = random_state\n",
    "        training_params[\"cat_idx\"] = cat_idx[\"choices\"][0]\n",
    "\n",
    "        # Instantiate the GRANDE teacher model.\n",
    "        self.model = GRANDE(params=self.params, args=training_params)\n",
    "\n",
    "        # Split the data into training and validation sets.\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        self.model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given input data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like\n",
    "            The predicted target values.\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def get_logits(self, X):\n",
    "        \"\"\"\n",
    "        Compute the logits of the GRANDE teacher model on the given input data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            The computed logits as a numpy array.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            probs = self.predict(X)\n",
    "\n",
    "            # Ensure binary classification (2 classes)\n",
    "            if probs.shape[1] != 2:\n",
    "                raise ValueError(\n",
    "                    \"get_logits is implemented for binary classification only.\"\n",
    "                )\n",
    "\n",
    "            # Clip probabilities to avoid log(0)\n",
    "            eps = 1e-15\n",
    "            probs = np.clip(probs, eps, 1 - eps)\n",
    "\n",
    "            # Compute logits by taking the logarithm of probabilities for each class.\n",
    "            logits = np.log(probs)\n",
    "\n",
    "        else:\n",
    "            # For regression, we can directly use the predictions as logits.\n",
    "            logits = self.predict(X)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        if self.task_type == \"binary\":\n",
    "            return evaluate_classification(\n",
    "                y_true=y,\n",
    "                y_pred=np.round(preds[:, 1]),\n",
    "                y_prob=preds[:, 1],\n",
    "                average=\"macro\",\n",
    "            )\n",
    "        else:\n",
    "            return evaluate_regression(y_true=y, y_pred=preds)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the GRANDE teacher model based on the\n",
    "        dense representation of a single tree and the number of trees in the ensemble.\n",
    "\n",
    "        The number of parameters for a single tree is computed as:\n",
    "            leaf parameters: 2^d\n",
    "            split thresholds: (2^d - 1) * n\n",
    "            feature selection (one-hot): (2^d - 1) * n\n",
    "        so that:\n",
    "            params_per_tree = 2^d + 2 * n * (2^d - 1)\n",
    "        The total is then:\n",
    "            total_params = n_estimators * params_per_tree\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained/initialized yet.\")\n",
    "\n",
    "        # These attributes must be set when the GRANDE model is instantiated.\n",
    "        # Adjust the attribute names if they are different in your GRANDE implementation.\n",
    "        d = self.model.depth  # Depth of each decision tree.\n",
    "        n = self.model.number_of_variables  # Number of features used in the tree.\n",
    "        E = self.model.n_estimators  # Number of trees in the ensemble.\n",
    "\n",
    "        # Calculate the number of parameters for one tree.\n",
    "        params_per_tree = (2**d) + 2 * n * ((2**d) - 1)\n",
    "        total_params = E * params_per_tree\n",
    "\n",
    "        return total_params\n",
    "\n",
    "class RandomForestTeacherModel(TeacherModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a RandomForest teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the RandomForest teacher model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters (not used for RandomForest).\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            # Initialize the RandomForest model with the provided hyperparameters\n",
    "            self.model = RandomForestClassifier(\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,  # Use all available CPU cores\n",
    "                **self.hyperparams,\n",
    "            )\n",
    "        else:\n",
    "            self.model = RandomForestRegressor(\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,  # Use all available CPU cores\n",
    "                **self.hyperparams,\n",
    "            )\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make probability predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples, n_classes)\n",
    "            The predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of parameters in the trained RandomForest model.\n",
    "\n",
    "        For each tree, we count:\n",
    "        - The feature indices at each node (1 parameter per node except leaf nodes)\n",
    "        - The thresholds at each node (1 parameter per node except leaf nodes)\n",
    "        - The values at each leaf node (1 parameter per leaf node)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of parameters in the model.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\") or self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet.\")\n",
    "\n",
    "        n_params = 0\n",
    "        for tree in self.model.estimators_:\n",
    "            tree = tree.tree_\n",
    "            # Number of nodes in the tree\n",
    "            n_nodes = tree.node_count\n",
    "            # Number of leaf nodes\n",
    "            n_leaves = tree.n_leaves\n",
    "            # Number of internal nodes\n",
    "            n_internal = n_nodes - n_leaves\n",
    "            # Each internal node has a feature index and a threshold\n",
    "            n_params += 2 * n_internal\n",
    "\n",
    "            # Each leaf node has value(s) - depends on task type\n",
    "            if self.task_type == \"binary\":\n",
    "                # For classification, each leaf stores class distribution\n",
    "                n_params += n_leaves * self.model.n_classes_\n",
    "            else:\n",
    "                # For regression, each leaf stores a single value\n",
    "                n_params += n_leaves\n",
    "\n",
    "        return n_params\n",
    "    \n",
    "def get_teacher_model(config: dict, task_type: Literal[\"binary\", \"regression\"], device, hyperparams, cat_cols=None) -> TeacherModelBase:\n",
    "    \"\"\"\n",
    "    Returns an instance of the teacher model based on the configuration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict\n",
    "        Configuration dictionary containing model and dataset details.\n",
    "    device : torch.device\n",
    "        The device to use for training (CPU or GPU).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TeacherModelBase\n",
    "        An instance of the teacher model.\n",
    "    \"\"\"\n",
    "    model_type = config[\"model\"][\"teacher_model\"]\n",
    "    if model_type == \"tabpfn\":\n",
    "        return TabPFNTeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"catboost\":\n",
    "        return CatBoostTeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"grande\":\n",
    "        return GRANDETeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams, cat_cols=cat_cols)\n",
    "    elif model_type == \"tabm\":\n",
    "        return TabMTeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"mlp\":\n",
    "        return MLPTeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"random_forest\":\n",
    "        return RandomForestTeacherModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown teacher type: {config['model']['teacher_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ba41a",
   "metadata": {},
   "source": [
    "## Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbb13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentModelBase(ABC):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.params = kwargs\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Trains the model on the given data.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.ndarray): The input features with shape (n_samples, n_features).\n",
    "            y (np.ndarray): The target labels with shape (n_samples,).\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Makes predictions on the provided data.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.ndarray): The input features with shape (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: An array of predicted probabilities with shape (n_samples, n_classes).\n",
    "                        (If the model returns logits, these should be post-processed to probabilities.)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, y_pred: np.ndarray, y_true: np.ndarray, y_teacher_true: np.ndarray, original_task_type: Literal[\"binary\", \"regression\"]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluates the model's predictions against the true labels.\n",
    "\n",
    "        Parameters:\n",
    "            y_pred (np.ndarray): The predicted probabilities or values.\n",
    "            y_true (np.ndarray): The true labels.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: A dictionary containing evaluation metrics.\n",
    "        \"\"\"     \n",
    "        if original_task_type == \"binary\":\n",
    "            if self.task_type == \"binary\":\n",
    "                metrics = evaluate_classification(y_pred, y_true)\n",
    "                fidelity_metrics = evaluate_fidelity_classification(y_pred, y_teacher_true)\n",
    "                metrics.update(fidelity_metrics)\n",
    "                metrics['parameters'] = self.count_parameters()\n",
    "                return metrics\n",
    "            \n",
    "            elif self.task_type == \"regression\":\n",
    "                # Convert logits to probabilities\n",
    "                y_prob = 1 / (1 + np.exp(-y_pred))  # Sigmoid function\n",
    "                y_prob = np.column_stack([1 - y_prob, y_prob])  # Create 2D array with probs for both classes\n",
    "\n",
    "                y_teacher_prob = 1 / (1 + np.exp(-y_teacher_true))\n",
    "                y_teacher_prob = np.column_stack([1 - y_teacher_prob, y_teacher_prob])\n",
    "                \n",
    "                metrics = evaluate_classification(y_prob, y_true)\n",
    "                class_fidelity_metrics = evaluate_fidelity_classification(y_prob, y_teacher_prob)\n",
    "                metrics.update(class_fidelity_metrics)\n",
    "                reg_fidelity_metrics = evaluate_fidelity_regression(y_pred, y_teacher_true)\n",
    "                metrics.update(reg_fidelity_metrics)\n",
    "                metrics['parameters'] = self.count_parameters()\n",
    "                return metrics\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(f\"Unknown task type: {self.task_type}. Must be 'binary' or 'regression'.\")\n",
    "        \n",
    "        elif original_task_type == \"regression\":\n",
    "            metrics = evaluate_regression(y_pred, y_true)\n",
    "            fidelity_metrics = evaluate_fidelity_regression(y_pred, y_teacher_true)\n",
    "            metrics.update(fidelity_metrics)\n",
    "            metrics['parameters'] = self.count_parameters()\n",
    "            return metrics\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task type: {self.task_type}. Must be 'binary' or 'regression'.\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def count_parameters(self) -> int:\n",
    "        \"\"\"\n",
    "        Counts the number of trainable parameters in the model.\n",
    "\n",
    "        Returns:\n",
    "            int: The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class CatBoostStudentModel(StudentModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a CatBoost teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the CatBoost model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the CatBoost model's fit method.\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        # Initialize the CatBoost model\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model = CatBoostClassifier(\n",
    "                random_seed=random_state,\n",
    "                thread_count=-1,  # Use all available CPU cores\n",
    "                logging_level=\"Silent\",  # Suppress CatBoost output\n",
    "                task_type=(\"GPU\" if str(self.device).lower() == \"cuda\" else \"CPU\"),\n",
    "                **self.hyperparams,  # Include the sampled hyperparameters\n",
    "            )\n",
    "        else:\n",
    "            self.model = CatBoostRegressor(\n",
    "                random_seed=random_state,\n",
    "                thread_count=-1,  # Use all available CPU cores\n",
    "                logging_level=\"Silent\",  # Suppress CatBoost output\n",
    "                task_type=(\"GPU\" if str(self.device).lower() == \"cuda\" else \"CPU\"),\n",
    "                **self.hyperparams,  # Include the sampled hyperparameters\n",
    "            )\n",
    "\n",
    "        # Split data into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        # Train the model\n",
    "        self.model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=(X_val, y_val),\n",
    "            early_stopping_rounds=20, \n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples, n_classes)\n",
    "            The predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of parameters in the trained CatBoost model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of parameters in the model.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\") or self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet.\")\n",
    "\n",
    "        # Get the number of trees in the model\n",
    "        tree_count = self.model.tree_count_\n",
    "\n",
    "        # For each tree, count:\n",
    "        # - split values (one per non-leaf node)\n",
    "        # - leaf values (one per leaf node)\n",
    "        # - feature indices (one per non-leaf node)\n",
    "        # For a binary tree with depth d, there are 2^d - 1 non-leaf nodes and 2^d leaf nodes\n",
    "        # This is a simplified approximation\n",
    "        approx_depth = self.hyperparams.get(\"max_depth\", 6)  # Default depth in CatBoost is 6\n",
    "        non_leaf_nodes = 2**approx_depth - 1\n",
    "        leaf_nodes = 2**approx_depth\n",
    "\n",
    "        # Total parameters per tree\n",
    "        params_per_tree = (\n",
    "            non_leaf_nodes * 2 + leaf_nodes\n",
    "        )  # split values + feature indices + leaf values\n",
    "        return tree_count * params_per_tree\n",
    "    \n",
    "\n",
    "class GRANDEStudentModel(StudentModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a GRANDE teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments. The `device` parameter is popped from kwargs and\n",
    "            defaults to 'cpu' if not provided.\n",
    "        \"\"\"\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "        os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        self.cat_cols = kwargs.pop(\"cat_cols\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the GRANDE teacher model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the GRANDE model's fit method.\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        # Determine categorical indices\n",
    "        cat_indices = [i for i, is_cat in enumerate(self.cat_cols) if is_cat]\n",
    "\n",
    "        training_params = {\n",
    "            \"epochs\": 1000,\n",
    "            \"early_stopping_epochs\": 25,\n",
    "            \"batch_size\": 64,\n",
    "            \"cat_idx\": cat_indices,\n",
    "            \"random_seed\": random_state,\n",
    "        }\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            training_params[\"objective\"] = \"binary\"\n",
    "        else:\n",
    "            training_params[\"objective\"] = \"regression\"\n",
    "\n",
    "        # Instantiate the GRANDE teacher model.\n",
    "        self.model = GRANDE(params=self.hyperparams, args=training_params)\n",
    "\n",
    "        # Split the data into training and validation sets.\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        self.model.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given input data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like\n",
    "            The predicted target values.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict(X)\n",
    "        else:\n",
    "            return self.model.predict(X).squeeze()\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the GRANDE teacher model based on the\n",
    "        dense representation of a single tree and the number of trees in the ensemble.\n",
    "\n",
    "        The number of parameters for a single tree is computed as:\n",
    "            leaf parameters: 2^d\n",
    "            split thresholds: (2^d - 1) * n\n",
    "            feature selection (one-hot): (2^d - 1) * n\n",
    "        so that:\n",
    "            params_per_tree = 2^d + 2 * n * (2^d - 1)\n",
    "        The total is then:\n",
    "            total_params = n_estimators * params_per_tree\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained/initialized yet.\")\n",
    "\n",
    "        # These attributes must be set when the GRANDE model is instantiated.\n",
    "        # Adjust the attribute names if they are different in your GRANDE implementation.\n",
    "        d = self.model.depth  # Depth of each decision tree.\n",
    "        n = self.model.number_of_variables  # Number of features used in the tree.\n",
    "        E = self.model.n_estimators  # Number of trees in the ensemble.\n",
    "\n",
    "        # Calculate the number of parameters for one tree.\n",
    "        params_per_tree = (2**d) + 2 * n * ((2**d) - 1)\n",
    "        total_params = E * params_per_tree\n",
    "\n",
    "        return total_params\n",
    "    \n",
    "class TabMStudentModel(StudentModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a TabM teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Set up AMP if CUDA is available.\n",
    "        if torch.cuda.is_available():\n",
    "            self.amp_dtype = (\n",
    "                torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "            )\n",
    "            self.amp_enabled = True\n",
    "        else:\n",
    "            self.amp_dtype = None\n",
    "            self.amp_enabled = False\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the TabM model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the TabM model's fit method.\n",
    "        \"\"\"\n",
    "        # Get parameters\n",
    "        n_blocks = self.hyperparams.get(\"n_blocks\")\n",
    "        d_block = self.hyperparams.get(\"d_block\")\n",
    "        dropout = self.hyperparams.get(\"dropout\")\n",
    "        lr = self.hyperparams.get(\"learning_rate\")\n",
    "        weight_decay = self.hyperparams.get(\"weight_decay\")\n",
    "\n",
    "        # Set model architecture\n",
    "        arch_type = \"tabm\"\n",
    "        bins = None\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            n_classes = len(np.unique(y))\n",
    "            self.n_classes = n_classes\n",
    "            cat_idx = []  # Assumes all features are continuous\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=cat_idx,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=32,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        else:\n",
    "            if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "                # Multiclass logits\n",
    "                n_outputs = y.shape[1]\n",
    "            else:\n",
    "                # Binary or single-output regression\n",
    "                n_outputs = 1\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=[],  # Assumes all features are continuous\n",
    "                n_classes=n_outputs,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=32,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            make_parameter_groups(self.model), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        self.evaluation_mode = torch.no_grad if compile_model else torch.inference_mode\n",
    "\n",
    "        # Prepare data\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        if self.task_type == \"binary\":\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long, device=self.device)\n",
    "        else:\n",
    "            y_tensor = torch.tensor(y, dtype=torch.float32, device=self.device)\n",
    "        n_samples = X_tensor.size(0)\n",
    "        indices = torch.randperm(n_samples)\n",
    "        train_end = int(0.8 * n_samples)\n",
    "        train_idx, val_idx = indices[:train_end], indices[train_end:]\n",
    "        self.data = {\n",
    "            \"train\": {\"x_cont\": X_tensor[train_idx], \"y\": y_tensor[train_idx]},\n",
    "            \"val\": {\"x_cont\": X_tensor[val_idx], \"y\": y_tensor[val_idx]},\n",
    "        }\n",
    "        Y_train = self.data[\"train\"][\"y\"]\n",
    "\n",
    "        # Training parameters\n",
    "        n_epochs = 100000\n",
    "        patience = 16\n",
    "        batch_size = 256\n",
    "        train_size = len(Y_train)\n",
    "        best = {\"val\": -float(\"inf\"), \"epoch\": -1}\n",
    "        remaining_patience = patience\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            batches = torch.randperm(train_size, device=self.device).split(batch_size)\n",
    "            for batch_idx in batches:\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_fn(\n",
    "                    self.apply_model(\"train\", batch_idx), Y_train[batch_idx]\n",
    "                )\n",
    "                if self.amp_enabled and self.amp_dtype == torch.float16:\n",
    "                    scaler = torch.cuda.amp.GradScaler()\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            val_score = self.evaluate_tabm(\"val\")\n",
    "            if val_score > best[\"val\"]:\n",
    "                best = {\"val\": val_score, \"epoch\": epoch}\n",
    "                remaining_patience = patience\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "\n",
    "    def apply_model(self, part: str, idx: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply the model to a batch of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "        idx : torch.Tensor\n",
    "            The indices of the samples to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The model output.\n",
    "        \"\"\"\n",
    "        with torch.autocast(\n",
    "            self.device.type, enabled=self.amp_enabled, dtype=self.amp_dtype\n",
    "        ):\n",
    "            x_cont = self.data[part][\"x_cont\"][idx]\n",
    "            x_cat = self.data[part].get(\"x_cat\")\n",
    "            if self.task_type == \"binary\":\n",
    "                return self.model(x_cont, x_cat).float()\n",
    "            else:\n",
    "                return (\n",
    "                    self.model(x_cont, x_cat)\n",
    "                    .squeeze(-1)  # Remove the last dimension for regression tasks\n",
    "                    .float()\n",
    "                )\n",
    "\n",
    "    def loss_fn(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            The predicted outputs.\n",
    "        y_true : torch.Tensor\n",
    "            The ground truth.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss value.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            # Use the second-to-last dimension for averaging over k heads.\n",
    "            k = y_pred.shape[-2]\n",
    "            target = y_true.repeat_interleave(k)\n",
    "            return F.cross_entropy(y_pred.flatten(0, 1), target)\n",
    "        else:\n",
    "            # TabM produces k predictions. Each of them must be trained separately.\n",
    "            # For student model (regression on logits), y_pred.shape == (batch_size, k)\n",
    "            k = y_pred.shape[-1 if len(y_pred.shape) <= 2 else -2]\n",
    "\n",
    "            # Flatten the predictions and repeat the targets\n",
    "            return F.mse_loss(\n",
    "                y_pred.flatten(0, 1),\n",
    "                (\n",
    "                    y_true.repeat_interleave(k)\n",
    "                    if self.model.share_training_batches\n",
    "                    else y_true\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def evaluate_tabm(self, part: str) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model on a data partition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The accuracy score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with self.evaluation_mode():\n",
    "            eval_batch_size = 8096\n",
    "\n",
    "            if self.task_type == \"binary\":\n",
    "                indices = torch.arange(\n",
    "                    len(self.data[part][\"y\"]), device=self.device\n",
    "                ).split(eval_batch_size)\n",
    "                y_pred = torch.cat(\n",
    "                    [self.apply_model(part, idx) for idx in indices]\n",
    "                ).cpu()\n",
    "                y_pred = torch.softmax(y_pred, dim=-1).mean(1)\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "                return float(accuracy_score(y_true, y_pred.argmax(1)))\n",
    "            else:\n",
    "                y_pred = (\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            self.apply_model(part, idx)\n",
    "                            for idx in torch.arange(\n",
    "                                len(self.data[part][\"y\"]), device=self.device\n",
    "                            ).split(eval_batch_size)\n",
    "                        ]\n",
    "                    )\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "                # Transform the predictions back to the original label space\n",
    "                if hasattr(self, \"regression_label_stats\"):\n",
    "                    y_pred = (\n",
    "                        y_pred * self.regression_label_stats[\"std\"]\n",
    "                        + self.regression_label_stats[\"mean\"]\n",
    "                    )\n",
    "\n",
    "                # Compute the mean of the k predictions\n",
    "                y_pred = y_pred.mean(1)\n",
    "\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "\n",
    "                # For student model, we want to minimize MSE, so return negative MSE\n",
    "                # The higher the value, the better (consistent with example.ipynb)\n",
    "                score = -(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "                return float(score)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples,)\n",
    "            The predicted class indices.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(X_tensor)\n",
    "                # Since share_training_batches is True, average over the second dimension.\n",
    "                probs = torch.softmax(logits, dim=-1).mean(1)\n",
    "                return probs.cpu().numpy()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                # TabM produces output with shape (batch_size, k) or (batch_size, k, n_outputs)\n",
    "                logits = self.model(X_tensor)\n",
    "\n",
    "                # For student model (regression), we need to average over the k predictions\n",
    "                # Check the dimensions of logits and average appropriately\n",
    "                if logits.ndim > 2:  # Case: (batch_size, k, n_outputs)\n",
    "                    logits = logits.mean(1)  # Average over k dimension\n",
    "                elif (\n",
    "                    logits.shape[1] > 1\n",
    "                    and hasattr(self.model, \"k\")\n",
    "                    and self.model.k > 1\n",
    "                ):\n",
    "                    # Case: (batch_size, k) for single output regression\n",
    "                    logits = logits.mean(\n",
    "                        1, keepdim=True\n",
    "                    )  # Average and keep output dimension\n",
    "\n",
    "                return logits.cpu().numpy().squeeze(-1)  # Squeeze to remove last dimension if needed\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained yet\")\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)    \n",
    "\n",
    "\n",
    "class MLPStudentModel(StudentModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a TabM teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Set up AMP if CUDA is available.\n",
    "        if torch.cuda.is_available():\n",
    "            self.amp_dtype = (\n",
    "                torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "            )\n",
    "            self.amp_enabled = True\n",
    "        else:\n",
    "            self.amp_dtype = None\n",
    "            self.amp_enabled = False\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the TabM model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters to pass to the TabM model's fit method.\n",
    "        \"\"\"\n",
    "        # Get parameters\n",
    "        n_blocks = self.hyperparams.get(\"n_blocks\")\n",
    "        d_block = self.hyperparams.get(\"d_block\")\n",
    "        dropout = self.hyperparams.get(\"dropout\")\n",
    "        lr = self.hyperparams.get(\"learning_rate\")\n",
    "        weight_decay = self.hyperparams.get(\"weight_decay\")\n",
    "\n",
    "        # Set model architecture\n",
    "        arch_type = \"plain\"\n",
    "        bins = None\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            n_classes = len(np.unique(y))\n",
    "            self.n_classes = n_classes\n",
    "            cat_idx = []  # Assumes all features are continuous\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=cat_idx,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=None,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        else:\n",
    "            if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "                # Multiclass logits\n",
    "                n_outputs = y.shape[1]\n",
    "            else:\n",
    "                # Binary or single-output regression\n",
    "                n_outputs = 1\n",
    "\n",
    "            # Initialize model\n",
    "            compile_model = False\n",
    "            self.model = Model(\n",
    "                n_num_features=n_features,\n",
    "                cat_cardinalities=[],  # Assumes all features are continuous\n",
    "                n_classes=n_outputs,\n",
    "                backbone={\n",
    "                    \"type\": \"MLP\",\n",
    "                    \"n_blocks\": n_blocks,\n",
    "                    \"d_block\": d_block,\n",
    "                    \"dropout\": dropout,\n",
    "                },\n",
    "                bins=bins,\n",
    "                num_embeddings=(\n",
    "                    None\n",
    "                    if bins is None\n",
    "                    else {\n",
    "                        \"type\": \"PiecewiseLinearEmbeddings\",\n",
    "                        \"d_embedding\": 16,\n",
    "                        \"activation\": False,\n",
    "                        \"version\": \"B\",\n",
    "                    }\n",
    "                ),\n",
    "                arch_type=arch_type,\n",
    "                k=None,\n",
    "                share_training_batches=True,\n",
    "            ).to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            make_parameter_groups(self.model), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        self.evaluation_mode = torch.no_grad if compile_model else torch.inference_mode\n",
    "\n",
    "        # Prepare data\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        if self.task_type == \"binary\":\n",
    "            y_tensor = torch.tensor(y, dtype=torch.long, device=self.device)\n",
    "        else:\n",
    "            y_tensor = torch.tensor(y, dtype=torch.float32, device=self.device)\n",
    "        n_samples = X_tensor.size(0)\n",
    "        indices = torch.randperm(n_samples)\n",
    "        train_end = int(0.8 * n_samples)\n",
    "        train_idx, val_idx = indices[:train_end], indices[train_end:]\n",
    "        self.data = {\n",
    "            \"train\": {\"x_cont\": X_tensor[train_idx], \"y\": y_tensor[train_idx]},\n",
    "            \"val\": {\"x_cont\": X_tensor[val_idx], \"y\": y_tensor[val_idx]},\n",
    "        }\n",
    "        Y_train = self.data[\"train\"][\"y\"]\n",
    "\n",
    "        # Training parameters\n",
    "        n_epochs = 100000\n",
    "        patience = 16\n",
    "        batch_size = 256\n",
    "        train_size = len(Y_train)\n",
    "        best = {\"val\": -float(\"inf\"), \"epoch\": -1}\n",
    "        remaining_patience = patience\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            batches = torch.randperm(train_size, device=self.device).split(batch_size)\n",
    "            for batch_idx in batches:\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_fn(\n",
    "                    self.apply_model(\"train\", batch_idx), Y_train[batch_idx]\n",
    "                )\n",
    "                if self.amp_enabled and self.amp_dtype == torch.float16:\n",
    "                    scaler = torch.cuda.amp.GradScaler()\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "            val_score = self.evaluate_tabm(\"val\")\n",
    "            if val_score > best[\"val\"]:\n",
    "                best = {\"val\": val_score, \"epoch\": epoch}\n",
    "                remaining_patience = patience\n",
    "            else:\n",
    "                remaining_patience -= 1\n",
    "            if remaining_patience < 0:\n",
    "                break\n",
    "\n",
    "    def apply_model(self, part: str, idx: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply the model to a batch of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "        idx : torch.Tensor\n",
    "            The indices of the samples to use.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The model output.\n",
    "        \"\"\"\n",
    "        with torch.autocast(\n",
    "            self.device.type, enabled=self.amp_enabled, dtype=self.amp_dtype\n",
    "        ):\n",
    "            x_cont = self.data[part][\"x_cont\"][idx]\n",
    "            x_cat = self.data[part].get(\"x_cat\")\n",
    "            if self.task_type == \"binary\":\n",
    "                return self.model(x_cont, x_cat).float()\n",
    "            else:\n",
    "                return (\n",
    "                    self.model(x_cont, x_cat)\n",
    "                    .squeeze(-1)  # Remove the last dimension for regression tasks\n",
    "                    .float()\n",
    "                )\n",
    "\n",
    "    def loss_fn(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : torch.Tensor\n",
    "            The predicted outputs.\n",
    "        y_true : torch.Tensor\n",
    "            The ground truth.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The loss value.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            # Use the second-to-last dimension for averaging over k heads.\n",
    "            k = y_pred.shape[-2]\n",
    "            target = y_true.repeat_interleave(k)\n",
    "            return F.cross_entropy(y_pred.flatten(0, 1), target)\n",
    "        else:\n",
    "            # TabM produces k predictions. Each of them must be trained separately.\n",
    "            # For student model (regression on logits), y_pred.shape == (batch_size, k)\n",
    "            k = y_pred.shape[-1 if len(y_pred.shape) <= 2 else -2]\n",
    "\n",
    "            # Flatten the predictions and repeat the targets\n",
    "            return F.mse_loss(\n",
    "                y_pred.flatten(0, 1),\n",
    "                (\n",
    "                    y_true.repeat_interleave(k)\n",
    "                    if self.model.share_training_batches\n",
    "                    else y_true\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def evaluate_tabm(self, part: str) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model on a data partition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        part : str\n",
    "            The data partition to use ('train' or 'val').\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The accuracy score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with self.evaluation_mode():\n",
    "            eval_batch_size = 8096\n",
    "\n",
    "            if self.task_type == \"binary\":\n",
    "                indices = torch.arange(\n",
    "                    len(self.data[part][\"y\"]), device=self.device\n",
    "                ).split(eval_batch_size)\n",
    "                y_pred = torch.cat(\n",
    "                    [self.apply_model(part, idx) for idx in indices]\n",
    "                ).cpu()\n",
    "                y_pred = torch.softmax(y_pred, dim=-1).mean(1)\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "                return float(accuracy_score(y_true, y_pred.argmax(1)))\n",
    "            else:\n",
    "                y_pred = (\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            self.apply_model(part, idx)\n",
    "                            for idx in torch.arange(\n",
    "                                len(self.data[part][\"y\"]), device=self.device\n",
    "                            ).split(eval_batch_size)\n",
    "                        ]\n",
    "                    )\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "                # Transform the predictions back to the original label space\n",
    "                if hasattr(self, \"regression_label_stats\"):\n",
    "                    y_pred = (\n",
    "                        y_pred * self.regression_label_stats[\"std\"]\n",
    "                        + self.regression_label_stats[\"mean\"]\n",
    "                    )\n",
    "\n",
    "                # Compute the mean of the k predictions\n",
    "                y_pred = y_pred.mean(1)\n",
    "\n",
    "                y_true = self.data[part][\"y\"].cpu().numpy()\n",
    "\n",
    "                # For student model, we want to minimize MSE, so return negative MSE\n",
    "                # The higher the value, the better (consistent with example.ipynb)\n",
    "                score = -(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "                return float(score)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples,)\n",
    "            The predicted class indices.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(X_tensor)\n",
    "                # Since share_training_batches is True, average over the second dimension.\n",
    "                probs = torch.softmax(logits, dim=-1).mean(1)\n",
    "                return probs.cpu().numpy()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                # TabM produces output with shape (batch_size, k) or (batch_size, k, n_outputs)\n",
    "                logits = self.model(X_tensor)\n",
    "\n",
    "                # For student model (regression), we need to average over the k predictions\n",
    "                # Check the dimensions of logits and average appropriately\n",
    "                if logits.ndim > 2:  # Case: (batch_size, k, n_outputs)\n",
    "                    logits = logits.mean(1)  # Average over k dimension\n",
    "                elif (\n",
    "                    logits.shape[1] > 1\n",
    "                    and hasattr(self.model, \"k\")\n",
    "                    and self.model.k > 1\n",
    "                ):\n",
    "                    # Case: (batch_size, k) for single output regression\n",
    "                    logits = logits.mean(\n",
    "                        1, keepdim=True\n",
    "                    )  # Average and keep output dimension\n",
    "\n",
    "                return logits.cpu().numpy().squeeze(-1)  # Squeeze to remove last dimension if needed\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of trainable parameters in the model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The total number of trainable parameters.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise ValueError(\"The model has not been trained yet\")\n",
    "        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "\n",
    "class RandomForestStudentModel(StudentModelBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize a RandomForest teacher model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs : dict\n",
    "            Additional keyword arguments to pass to the base class constructor.\n",
    "        \"\"\"\n",
    "        self.device = kwargs.pop(\"device\")\n",
    "        self.config = kwargs.pop(\"config\")\n",
    "        self.task_type = kwargs.pop(\"task_type\")\n",
    "        self.hyperparams = kwargs.pop(\"hyperparams\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the RandomForest teacher model using the provided data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target data.\n",
    "        **training_params : dict\n",
    "            Additional training parameters (not used for RandomForest).\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        random_state = config[\"training\"][\"random_state\"]\n",
    "\n",
    "        if self.task_type == \"binary\":\n",
    "            # Initialize the RandomForest model with the provided hyperparameters\n",
    "            self.model = RandomForestClassifier(\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,  # Use all available CPU cores\n",
    "                **self.hyperparams,\n",
    "            )\n",
    "        else:\n",
    "            self.model = RandomForestRegressor(\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,  # Use all available CPU cores\n",
    "                **self.hyperparams,\n",
    "            )\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make probability predictions on the given data using the trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like of shape (n_samples, n_classes)\n",
    "            The predicted probabilities for each class.\n",
    "        \"\"\"\n",
    "        if self.task_type == \"binary\":\n",
    "            return self.model.predict_proba(X)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Count the number of parameters in the trained RandomForest model.\n",
    "\n",
    "        For each tree, we count:\n",
    "        - The feature indices at each node (1 parameter per node except leaf nodes)\n",
    "        - The thresholds at each node (1 parameter per node except leaf nodes)\n",
    "        - The values at each leaf node (1 parameter per leaf node)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The number of parameters in the model.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"model\") or self.model is None:\n",
    "            raise ValueError(\"The model has not been trained yet.\")\n",
    "\n",
    "        n_params = 0\n",
    "        for tree in self.model.estimators_:\n",
    "            tree = tree.tree_\n",
    "            # Number of nodes in the tree\n",
    "            n_nodes = tree.node_count\n",
    "            # Number of leaf nodes\n",
    "            n_leaves = tree.n_leaves\n",
    "            # Number of internal nodes\n",
    "            n_internal = n_nodes - n_leaves\n",
    "            # Each internal node has a feature index and a threshold\n",
    "            n_params += 2 * n_internal\n",
    "\n",
    "            # Each leaf node has value(s) - depends on task type\n",
    "            if self.task_type == \"binary\":\n",
    "                # For classification, each leaf stores class distribution\n",
    "                n_params += n_leaves * self.model.n_classes_\n",
    "            else:\n",
    "                # For regression, each leaf stores a single value\n",
    "                n_params += n_leaves\n",
    "\n",
    "        return n_params\n",
    "    \n",
    "def get_student_model(config: dict, task_type: Literal[\"binary\", \"regression\"], device, hyperparams, cat_cols=None) -> StudentModelBase:\n",
    "    \"\"\"\n",
    "    Returns an instance of the teacher model based on the configuration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict\n",
    "        Configuration dictionary containing model and dataset details.\n",
    "    device : torch.device\n",
    "        The device to use for training (CPU or GPU).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TeacherModelBase\n",
    "        An instance of the teacher model.\n",
    "    \"\"\"\n",
    "    model_type = config[\"model\"][\"student_model\"]\n",
    "    if model_type == \"catboost\":\n",
    "        return CatBoostStudentModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"grande\":\n",
    "        return GRANDEStudentModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams, cat_cols=cat_cols)\n",
    "    elif model_type == \"tabm\":\n",
    "        return TabMStudentModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"mlp\":\n",
    "        return MLPStudentModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    elif model_type == \"random_forest\":\n",
    "        return RandomForestStudentModel(config=config, task_type=task_type, device=device, hyperparams=hyperparams)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown teacher type: {config['model']['student_model']}. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d7a3c",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab890760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_hyperparameters(trial: optuna.Trial, model_type: str, task_type: str, use_hpo: bool) -> dict:\n",
    "    \"\"\"\n",
    "    Suggest hyperparameters for the given model type using Optuna.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trial : optuna.Trial\n",
    "        Optuna trial object for suggesting hyperparameters.\n",
    "    model_type : str\n",
    "        Type of model ('tabpfn', 'catboost', etc.).\n",
    "    task_type : str\n",
    "        Type of task ('binary', 'regression').\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary of suggested hyperparameters.\n",
    "    \"\"\"\n",
    "    hyperparameter = {}\n",
    "    \n",
    "    if model_type == \"catboost\":\n",
    "        if use_hpo:\n",
    "            hyperparameter = {\n",
    "                \"iterations\": trial.suggest_int(\"iterations\", 512, 4096),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 2, 12),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "                \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.5, 30),\n",
    "                \"boosting_type\": \"Plain\",\n",
    "            }\n",
    "        else:\n",
    "            hyperparameter = {\n",
    "                \"iterations\": 1000,\n",
    "                \"max_depth\": 6,\n",
    "                \"l2_leaf_reg\": 3,\n",
    "                \"boosting_type\": \"Plain\",\n",
    "            }\n",
    "        if task_type == \"binary\":\n",
    "            hyperparameter[\"loss_function\"] = \"Logloss\"\n",
    "        else:\n",
    "            hyperparameter[\"loss_function\"] = \"RMSE\"\n",
    "    \n",
    "    elif model_type == \"grande\":\n",
    "        if use_hpo:\n",
    "            hyperparameter = {\n",
    "                \"depth\": trial.suggest_int(\"depth\", 3, 7),\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 512, 4096),\n",
    "                \"learning_rate_weights\": trial.suggest_float(\"learning_rate_weights\", 0.0001, 0.05, log=True),\n",
    "                \"learning_rate_index\": trial.suggest_float(\"learning_rate_index\", 0.001, 0.2, log=True),\n",
    "                \"learning_rate_values\": trial.suggest_float(\"learning_rate_values\", 0.001, 0.2, log=True),\n",
    "                \"learning_rate_leaf\": trial.suggest_float(\"learning_rate_leaf\", 0.001, 0.2, log=True),\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"cosine_decay_steps\": trial.suggest_categorical(\"cosine_decay_steps\", [0.0, 0.1, 1.0, 100.0, 1000.0]),\n",
    "                \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.75),\n",
    "                \"selected_variables\": trial.suggest_float(\"selected_variables\", 0.0, 1.0),\n",
    "                \"data_subset_fraction\": trial.suggest_float(\"data_subset_fraction\", 0.1, 1.0),\n",
    "                \"focal_loss\": False,\n",
    "                \"temperature\": 0.0,\n",
    "                \"from_logits\": True,\n",
    "                \"use_class_weights\": True,\n",
    "            }\n",
    "        else:\n",
    "            hyperparameter = {\n",
    "                \"depth\": 5,\n",
    "                \"n_estimators\": 2048,\n",
    "                \"learning_rate_weights\": 0.005,\n",
    "                \"learning_rate_index\": 0.01,\n",
    "                \"learning_rate_values\": 0.01,\n",
    "                \"learning_rate_leaf\": 0.01,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"cosine_decay_steps\": 0,\n",
    "                \"dropout\": 0.0,\n",
    "                \"selected_variables\": 0.8,\n",
    "                \"data_subset_fraction\": 1.0,\n",
    "                \"focal_loss\": False,\n",
    "                \"temperature\": 0.0,\n",
    "                \"from_logits\": True,\n",
    "                \"use_class_weights\": True,\n",
    "            }\n",
    "        if task_type == \"binary\":\n",
    "            hyperparameter[\"loss\"] = \"crossentropy\"\n",
    "        else:\n",
    "            hyperparameter[\"loss\"] = \"mse\"\n",
    "\n",
    "    elif model_type == \"tabm\":\n",
    "        if use_hpo:\n",
    "            hyperparameter = {\n",
    "                \"n_blocks\": trial.suggest_int(\"n_blocks\", 1, 5),\n",
    "                \"d_block\": trial.suggest_int(\"d_block\", 64, 1024),\n",
    "                \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.5),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.0001, 0.005, log=True),\n",
    "                \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0001, 0.1, log=True),\n",
    "            }\n",
    "        else:\n",
    "            hyperparameter = {\n",
    "                \"n_blocks\": 3,\n",
    "                \"d_block\": 512,\n",
    "                \"dropout\": 0.1,\n",
    "                \"learning_rate\": 0.002,\n",
    "                \"weight_decay\": 0.0003,\n",
    "            }\n",
    "\n",
    "    elif model_type == \"mlp\":\n",
    "        if use_hpo:\n",
    "            hyperparameter = {\n",
    "                \"n_blocks\": trial.suggest_int(\"n_blocks\", 1, 5),\n",
    "                \"d_block\": trial.suggest_int(\"d_block\", 64, 1024),\n",
    "                \"dropout\": trial.suggest_float(\"dropout\", 0.0, 0.5),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.0001, 0.005, log=True),\n",
    "                \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0001, 0.1, log=True),\n",
    "            }\n",
    "        else:\n",
    "            hyperparameter = {\n",
    "                \"n_blocks\": 3,\n",
    "                \"d_block\": 512,\n",
    "                \"dropout\": 0.1,\n",
    "                \"learning_rate\": 0.002,\n",
    "                \"weight_decay\": 0.0003,\n",
    "            }\n",
    "\n",
    "    elif model_type == \"random_forest\":\n",
    "        if use_hpo:\n",
    "            hyperparameter = {\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 4096),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 5, 100),\n",
    "                \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "                \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "                \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", 0.3, 0.5, 0.7, 1.0]),\n",
    "                \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "            }\n",
    "            if task_type == \"binary\":\n",
    "                hyperparameter[\"criterion\"] = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "            else:\n",
    "                hyperparameter[\"criterion\"] = trial.suggest_categorical(\"criterion\", [\"squared_error\", \"absolute_error\", \"poisson\", \"friedman_mse\"])\n",
    "        else:\n",
    "            hyperparameter = {\n",
    "                \"n_estimators\": 1000,\n",
    "                \"max_depth\": None,\n",
    "                \"min_samples_split\": 2,\n",
    "                \"min_samples_leaf\": 1,\n",
    "            }\n",
    "            if task_type == \"binary\":\n",
    "                hyperparameter[\"criterion\"] = \"gini\"\n",
    "                hyperparameter[\"max_features\"] = \"sqrt\"\n",
    "            else:\n",
    "                hyperparameter[\"criterion\"] = \"squared_error\"\n",
    "                hyperparameter[\"max_features\"] = 1.0\n",
    "\n",
    "    return hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad02857a",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59b406d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"datasets\": [\n",
    "                    #  23381, # Binary classification datasets\n",
    "                       197, # Regression datasets\n",
    "                     ],  \n",
    "        \"cache_dir_path\": \"data/cache/\",\n",
    "        \"fold_indices_path\": \"data/fold_indices/\",\n",
    "        \"optuna_db_path\": \"data/optuna_db/\",\n",
    "        \"output_dir_path\": \"data/output/\",\n",
    "        \"outer_folds_path\": \"data/outer_fold/\",\n",
    "        \"results_dir_path\": \"results/\",\n",
    "    },\n",
    "\n",
    "    \"preprocessing\": {\n",
    "        \"threshold_high_cardinality\": 10,  \n",
    "    },\n",
    "\n",
    "    \"model\": {\n",
    "        \"teacher_model\": \"tabpfn\",   # Options: 'tabpfn', 'grande', 'catboost', 'tabm', 'mlp', 'random_forest'\n",
    "        \"student_model\": \"random_forest\", # Options: 'grande', 'catboost', 'tabm', 'mlp', 'random_forest'\n",
    "    },\n",
    "\n",
    "    \"training\": {\n",
    "        \"use_hpo\": False,\n",
    "        \"train_on_logits\": False,\n",
    "        \"trials\": 30,\n",
    "        \"random_state\": 42,\n",
    "        \"outer_folds\": 5,\n",
    "        \"inner_folds\": 2,\n",
    "    },\n",
    "\n",
    "    \"teacher_models\": {\n",
    "        \"tabpfn\": {\n",
    "            \"preprocessing\": \"nn\",  \n",
    "        },\n",
    "        \"catboost\": {\n",
    "            \"preprocessing\": \"tree\", \n",
    "        },\n",
    "        \"grande\": {\n",
    "            \"preprocessing\": \"grande\",  \n",
    "        },\n",
    "        \"tabm\": {\n",
    "            \"preprocessing\": \"nn\",  \n",
    "        },\n",
    "        \"mlp\": {\n",
    "            \"preprocessing\": \"nn\",  \n",
    "        },\n",
    "        \"random_forest\": {\n",
    "            \"preprocessing\": \"tree\",  \n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"student_models\": {\n",
    "        \"catboost\": {\n",
    "            \"preprocessing\": \"tree\",  \n",
    "        },\n",
    "        \"grande\": {\n",
    "            \"preprocessing\": \"grande\",  \n",
    "        },\n",
    "        \"tabm\": {\n",
    "            \"preprocessing\": \"nn\",  \n",
    "        },\n",
    "        \"mlp\": {\n",
    "            \"preprocessing\": \"nn\",  \n",
    "        },\n",
    "        \"random_forest\": {\n",
    "            \"preprocessing\": \"tree\",  \n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17729927",
   "metadata": {},
   "source": [
    "# Train Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9dce1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 15:49:46,148 - __main__ - INFO - Loading configuration...\n",
      "2025-06-05 15:49:46,149 - __main__ - INFO - Loading dataset 23381 from cache at 'data/cache/openml_dataset_23381.pkl'...\n",
      "2025-06-05 15:49:46,151 - __main__ - INFO - Dataset 23381 loaded successfully with task type: binary\n",
      "2025-06-05 15:49:46,152 - __main__ - INFO - Results already exist for dataset 23381 with model tabpfn, HPO: False, seed: 42\n",
      "2025-06-05 15:49:46,153 - __main__ - INFO - Skipping dataset 23381 - results already computed\n",
      "2025-06-05 15:49:46,153 - __main__ - INFO - Loading configuration...\n",
      "2025-06-05 15:49:46,154 - __main__ - INFO - Loading dataset 197 from cache at 'data/cache/openml_dataset_197.pkl'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 15:49:46,158 - __main__ - INFO - Dataset 197 loaded successfully with task type: regression\n",
      "2025-06-05 15:49:46,159 - __main__ - INFO - Results already exist for dataset 197 with model tabpfn, HPO: False, seed: 42\n",
      "2025-06-05 15:49:46,160 - __main__ - INFO - Skipping dataset 197 - results already computed\n"
     ]
    }
   ],
   "source": [
    "# Get list of datasets to process from configuration\n",
    "datasets = config[\"data\"][\"datasets\"]\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN TRAINING LOOP - Process each dataset independently\n",
    "# =============================================================================\n",
    "for dataset_id in datasets:\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SETUP AND INITIALIZATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    logger = setup_logging()\n",
    "    logger.info(\"Loading configuration...\")\n",
    "\n",
    "    # Extract model configuration for this run\n",
    "    model_type = config[\"model\"][\"teacher_model\"]\n",
    "    preprocessing_type = config[\"teacher_models\"][model_type][\"preprocessing\"]\n",
    "    use_hpo = config[\"training\"][\"use_hpo\"]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 0: DATA LOADING\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Load dataset from OpenML with caching for efficiency\n",
    "    X, y, cat_cols, _, task_type = load_dataset(\n",
    "        dataset_id=dataset_id,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 1: INFRASTRUCTURE SETUP\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Note: Checking for existing results is placeholder for future implementation\n",
    "    summary_file = os.path.join(config[\"data\"][\"results_dir_path\"], \"teacher\", f\"{dataset_id}_results.json\")\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file, 'r') as f:\n",
    "            existing_results = json.load(f)\n",
    "        \n",
    "        # Check if we already have results with the same configuration\n",
    "        config_exists = False\n",
    "        for key, result in existing_results.items():\n",
    "            if (result.get('model_type') == model_type and \n",
    "                result.get('use_hpo') == use_hpo and \n",
    "                result.get('seed') == config[\"training\"][\"random_state\"]):\n",
    "                config_exists = True\n",
    "                logger.info(f\"Results already exist for dataset {dataset_id} with model {model_type}, HPO: {use_hpo}, seed: {config['training']['random_state']}\")\n",
    "                break\n",
    "        \n",
    "        if config_exists:\n",
    "            logger.info(f\"Skipping dataset {dataset_id} - results already computed\")\n",
    "            continue\n",
    "\n",
    "    # Configure GPU/CPU usage for training\n",
    "    device = check_GPU_availability()\n",
    "\n",
    "    # Set random seed for reproducibility across all libraries\n",
    "    set_seed(config[\"training\"][\"random_state\"])\n",
    "    logger.info(f\"Random seed set to {config['training']['random_state']}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 2: INITIALIZE DATA STRUCTURES\n",
    "    # -------------------------------------------------------------------------\n",
    "    # List to store predictions from each outer fold\n",
    "    output_dfs = []\n",
    "\n",
    "    outer_fold_scores = []\n",
    "    \n",
    "    # Dictionary to store all fold indices for reproducibility and student training\n",
    "    # Structure: {\"outer_folds\": {fold_id: {train_idx, test_idx}},\n",
    "    #            \"inner_folds\": {outer_fold_id: {inner_fold_id: {train_idx, val_idx}}}}\n",
    "    fold_indices = {\n",
    "        \"outer_folds\": {},\n",
    "        \"inner_folds\": {}\n",
    "    }\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 3: OUTER CROSS-VALIDATION SETUP\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Choose appropriate CV strategy based on task type to maintain class balance\n",
    "    if task_type == \"binary\":\n",
    "        outer_cv = StratifiedKFold(\n",
    "            n_splits=config[\"training\"][\"outer_folds\"],\n",
    "            shuffle=True,\n",
    "            random_state=config[\"training\"][\"random_state\"],\n",
    "        )\n",
    "    else:\n",
    "        outer_cv = KFold(\n",
    "            n_splits=config[\"training\"][\"outer_folds\"],\n",
    "            shuffle=True,\n",
    "            random_state=config[\"training\"][\"random_state\"],\n",
    "        )\n",
    "\n",
    "    # =========================================================================\n",
    "    # STEP 4: OUTER CROSS-VALIDATION LOOP\n",
    "    # =========================================================================\n",
    "    # Each iteration provides one unbiased performance estimate\n",
    "    for outer_fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), start=1):\n",
    "\n",
    "        # Log the first 10 indices of the outer fold for debugging\n",
    "        logger.info(f\"Outer Fold {outer_fold} - Train Indices: {train_idx[:10]}, Test Indices: {test_idx[:10]}\")\n",
    "\n",
    "        logger.info(f\"-------------------- Outer Fold {outer_fold} --------------------\")\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # FOLD INDEX MANAGEMENT\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Store outer fold indices for later use in student training and validation\n",
    "        fold_indices[\"outer_folds\"][f\"fold_{outer_fold}\"] = {\n",
    "            \"train_idx\": train_idx.tolist(),\n",
    "            \"test_idx\": test_idx.tolist()\n",
    "        }\n",
    "\n",
    "        # Split data according to current outer fold\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # INNER CROSS-VALIDATION SETUP (for model validation)\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Choose appropriate CV strategy for inner folds\n",
    "        if task_type == \"binary\":\n",
    "            inner_cv = StratifiedKFold(\n",
    "                n_splits=config[\"training\"][\"inner_folds\"],\n",
    "                shuffle=True,\n",
    "                random_state=config[\"training\"][\"random_state\"],\n",
    "            )\n",
    "        else:\n",
    "            inner_cv = KFold(\n",
    "                n_splits=config[\"training\"][\"inner_folds\"],\n",
    "                shuffle=True,\n",
    "                random_state=config[\"training\"][\"random_state\"],\n",
    "            )\n",
    "        \n",
    "        # Initialize storage for inner fold indices within this outer fold\n",
    "        fold_indices[\"inner_folds\"][f\"outer_fold_{outer_fold}\"] = {}\n",
    "\n",
    "        # =====================================================================\n",
    "        # STEP 5: INNER CROSS-VALIDATION LOOP (hyperparameter validation) \n",
    "        # =====================================================================\n",
    "        def objective(trial):\n",
    "\n",
    "            hyperparams = suggest_hyperparameters(\n",
    "                trial=trial,\n",
    "                model_type=model_type,\n",
    "                task_type=task_type,\n",
    "                use_hpo=use_hpo,\n",
    "            )\n",
    "\n",
    "            inner_fold_scores = []\n",
    "            val_metrics_list = []\n",
    "\n",
    "            # This loop would typically be used for hyperparameter optimization\n",
    "            for inner_fold, (inner_train_index, inner_val_index) in enumerate(inner_cv.split(X_train, y_train), start=1):\n",
    "                \n",
    "                # -----------------------------------------------------------------\n",
    "                # INDEX MANAGEMENT (Critical for avoiding data leakage)\n",
    "                # -----------------------------------------------------------------\n",
    "                # Convert relative indices (within outer training set) to absolute indices\n",
    "                absolute_inner_train_idx = train_idx[inner_train_index]\n",
    "                absolute_inner_val_idx = train_idx[inner_val_index]\n",
    "                \n",
    "                # Store inner fold indices using absolute indices for consistency\n",
    "                # Only store indices for the first trial\n",
    "                if trial.number == 0:  \n",
    "                    fold_indices[\"inner_folds\"][f\"outer_fold_{outer_fold}\"][f\"inner_fold_{inner_fold}\"] = {\n",
    "                        \"train_idx\": absolute_inner_train_idx.tolist(),\n",
    "                        \"val_idx\": absolute_inner_val_idx.tolist()\n",
    "                    }\n",
    "\n",
    "                # Split inner training data using relative indices\n",
    "                X_inner_train, X_inner_val = X_train.iloc[inner_train_index], X_train.iloc[inner_val_index]\n",
    "                y_inner_train, y_inner_val = y_train[inner_train_index], y_train[inner_val_index]\n",
    "\n",
    "                # -----------------------------------------------------------------\n",
    "                # PREPROCESSING: Apply model-specific data transformations\n",
    "                # -----------------------------------------------------------------\n",
    "                X_inner_train, X_inner_val = preprocess(\n",
    "                    X_inner_train,\n",
    "                    y_inner_train,\n",
    "                    X_inner_val, \n",
    "                    cat_cols,\n",
    "                    config,\n",
    "                    preprocessing_type=preprocessing_type,\n",
    "                )\n",
    "\n",
    "                # -----------------------------------------------------------------\n",
    "                # MODEL TRAINING: Train teacher model on inner training data\n",
    "                # -----------------------------------------------------------------\n",
    "                model = get_teacher_model(config=config, task_type=task_type, device=device, hyperparams=hyperparams, cat_cols=cat_cols)\n",
    "                logger.info(f\"Training Model on Outer Fold {outer_fold}, Inner Fold {inner_fold}...\")\n",
    "                model.train(X_inner_train, y_inner_train)\n",
    "\n",
    "                # -----------------------------------------------------------------\n",
    "                # VALIDATION: Evaluate model performance on inner validation set\n",
    "                # -----------------------------------------------------------------\n",
    "                val_preds = model.predict(X_inner_val)\n",
    "                val_metrics = model.evaluate(val_preds, y_inner_val)\n",
    "\n",
    "                # Store metrics from this fold for later mean calculation\n",
    "                val_metrics_list.append(val_metrics)\n",
    "\n",
    "                if task_type == \"binary\":\n",
    "                    inner_fold_scores.append(val_metrics[\"f1\"])\n",
    "                    trial.report(np.mean(inner_fold_scores), step=inner_fold)\n",
    "                else:\n",
    "                    inner_fold_scores.append(-val_metrics[\"mae\"])\n",
    "                    trial.report(np.mean(inner_fold_scores), step=inner_fold)\n",
    "\n",
    "                # Check if the trial should be pruned (With 2 inner folds, pruning not recommended)\n",
    "                # if trial.should_prune():\n",
    "                #     logger.info(\"Trial pruned.\")\n",
    "                #     raise optuna.TrialPruned()\n",
    "\n",
    "            # Calculate and set mean metrics as user attributes after all inner folds\n",
    "            if val_metrics_list:\n",
    "                # Get all metric keys from the first fold\n",
    "                metric_keys = val_metrics_list[0].keys()\n",
    "                \n",
    "                for metric_key in metric_keys:\n",
    "                    # Calculate mean across all inner folds for this metric\n",
    "                    metric_values = [fold_metrics[metric_key] for fold_metrics in val_metrics_list]\n",
    "                    mean_metric = np.mean(metric_values)\n",
    "                    trial.set_user_attr(f\"mean_{metric_key}\", mean_metric)\n",
    "\n",
    "            return np.mean(inner_fold_scores)\n",
    "            \n",
    "        logger.info(f\"Starting hyperparameter optimization for outer fold {outer_fold}...\")\n",
    "\n",
    "        study_kwargs = dict(\n",
    "            direction=\"maximize\",\n",
    "            study_name=f\"{dataset_id}.{outer_fold}.{model_type}\",\n",
    "            load_if_exists=True,\n",
    "            sampler=optuna.samplers.TPESampler(seed=config[\"training\"][\"random_state\"]),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=1),\n",
    "        )\n",
    "\n",
    "        if use_hpo:\n",
    "            os.makedirs(config[\"data\"][\"optuna_db_path\"], exist_ok=True)\n",
    "            study_kwargs[\"storage\"] = f\"sqlite:///{config['data']['optuna_db_path']}/optuna.db\"\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            **study_kwargs,\n",
    "        )\n",
    "\n",
    "        # Optimize\n",
    "        completed_trials = len(study.trials)\n",
    "        remaining_trials = config[\"training\"][\"trials\"] - completed_trials\n",
    "\n",
    "        if remaining_trials > 0:\n",
    "            default_hyperparams = suggest_hyperparameters(None, model_type, task_type, False)\n",
    "            study.enqueue_trial(default_hyperparams)\n",
    "            study.optimize(\n",
    "                objective, \n",
    "                n_trials=remaining_trials if use_hpo else 1,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"The study has already reached the maximum number of trials.\")\n",
    "\n",
    "        if use_hpo:\n",
    "            # When HPO is used, trial.suggest_ methods are called, populating trial.params\n",
    "            best_hyperparams = study.best_trial.params \n",
    "        else:\n",
    "            # When not using HPO, a single trial runs with default parameters.\n",
    "            best_hyperparams = suggest_hyperparameters(trial=None, model_type=model_type, task_type=task_type, use_hpo=False)\n",
    "\n",
    "        logger.info(f\"Best hyperparameters for fold {outer_fold}: {best_hyperparams}\")\n",
    "        logger.info(f\"Best score: {study.best_value:.4f}\")\n",
    "\n",
    "        # =====================================================================\n",
    "        # STEP 6: FINAL MODEL TRAINING (on complete outer training set)\n",
    "        # =====================================================================        \n",
    "        # Apply same preprocessing to outer training and test sets\n",
    "        X_train, X_test = preprocess(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            cat_cols,\n",
    "            config,\n",
    "            preprocessing_type=preprocessing_type,  \n",
    "        )\n",
    "        \n",
    "        # Train final model on complete outer training set\n",
    "        logger.info(\"------------------------------------------------------\")\n",
    "        logger.info(f\"Retraining Model on Outer Fold {outer_fold}\")\n",
    "\n",
    "        model = get_teacher_model(\n",
    "            config=config,\n",
    "            task_type=task_type,\n",
    "            device=device,\n",
    "            hyperparams=best_hyperparams,  # Use best hyperparameters from HPO\n",
    "            cat_cols=cat_cols,  \n",
    "        )\n",
    "        model.train(X_train, y_train)\n",
    "\n",
    "        # =====================================================================\n",
    "        # STEP 7: FINAL EVALUATION (unbiased performance on outer test set)\n",
    "        # =====================================================================\n",
    "        # This provides the unbiased performance estimate for this fold\n",
    "        start_time = time.time()\n",
    "        test_preds = model.predict(X_test)\n",
    "        end_time = time.time() - start_time\n",
    "        logger.info(f\"\\t Inference Time: {end_time:.5f} seconds\")\n",
    "        test_metrics = model.evaluate(test_preds, y_test)\n",
    "\n",
    "        # Store outer fold score for later analysis\n",
    "        outer_fold_results = {\n",
    "            \"fold\": outer_fold,\n",
    "            \"seed\": config[\"training\"][\"random_state\"],\n",
    "            \"inference_time\": end_time,\n",
    "            **test_metrics,\n",
    "        }\n",
    "        outer_fold_scores.append(outer_fold_results)\n",
    "\n",
    "        # =====================================================================\n",
    "        # STEP 8: STORE PREDICTIONS FOR STUDENT TRAINING\n",
    "        # =====================================================================\n",
    "        # Save predictions with their corresponding dataset indices\n",
    "        # These will be used as targets for training student models\n",
    "        output_dfs.append(pd.DataFrame({\n",
    "            \"index\": test_idx,\n",
    "            \"output\": test_preds[:, 1] if task_type == \"binary\" else test_preds\n",
    "        }))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 9: SAVE RESULTS AND METADATA\n",
    "    # =========================================================================\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE OUTER FOLD METRICS\n",
    "    # -------------------------------------------------------------------------\n",
    "    outer_fold_df = pd.DataFrame(outer_fold_scores)\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    output_dir = os.path.join(config[\"data\"][\"outer_folds_path\"], \"teacher\", sub_folder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    metrics_file = os.path.join(output_dir, f\"{dataset_id}_{model_type}.csv\")\n",
    "    outer_fold_df.to_csv(metrics_file, index=False)\n",
    "    logger.info(f\"Outer fold metrics saved to: {metrics_file}\")\n",
    "\n",
    "    # Calculate and log overall performance across all folds\n",
    "    mean_inference_time = outer_fold_df['inference_time'].mean()\n",
    "    std_inference_time = outer_fold_df['inference_time'].std()\n",
    "    mean_parameters = outer_fold_df['parameters'].mean()\n",
    "    std_parameters = outer_fold_df['parameters'].std()\n",
    "\n",
    "    if task_type == \"binary\":\n",
    "        mean_acc = outer_fold_df['acc'].mean()\n",
    "        std_acc = outer_fold_df['acc'].std()\n",
    "        mean_f1 = outer_fold_df['f1'].mean()\n",
    "        std_f1 = outer_fold_df['f1'].std()\n",
    "        mean_roc = outer_fold_df['roc'].mean()\n",
    "        std_roc = outer_fold_df['roc'].std()\n",
    "        \n",
    "        logger.info(f\"=== FINAL RESULTS FOR DATASET {dataset_id} ===\")\n",
    "        logger.info(f\"Balanced Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "        logger.info(f\"F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "        logger.info(f\"ROC AUC: {mean_roc:.4f} ± {std_roc:.4f}\")\n",
    "    else:\n",
    "        mean_mae = outer_fold_df['mae'].mean()\n",
    "        std_mae = outer_fold_df['mae'].std()\n",
    "        mean_mse = outer_fold_df['mse'].mean()\n",
    "        std_mse = outer_fold_df['mse'].std()\n",
    "        mean_rmse = outer_fold_df['rmse'].mean()\n",
    "        std_rmse = outer_fold_df['rmse'].std()\n",
    "        mean_r2 = outer_fold_df['r2'].mean()\n",
    "        std_r2 = outer_fold_df['r2'].std()\n",
    "\n",
    "        \n",
    "        logger.info(f\"=== FINAL RESULTS FOR DATASET {dataset_id} ===\")\n",
    "        logger.info(f\"MAE: {mean_mae:.4f} ± {std_mae:.4f}\")\n",
    "        logger.info(f\"MSE: {mean_mse:.4f} ± {std_mse:.4f}\")\n",
    "        logger.info(f\"RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "        logger.info(f\"R2: {mean_r2:.4f} ± {std_r2:.4f}\")\n",
    "    \n",
    "    logger.info(f\"Mean Inference Time: {mean_inference_time:.4f} ± {std_inference_time:.4f}\")\n",
    "    logger.info(f\"Mean Parameters: {mean_parameters:.4f} ± {std_parameters:.4f}\")\n",
    "\n",
    "    # Save summary statistics as well\n",
    "    summary_stats = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"model_type\": model_type,\n",
    "        \"task_type\": task_type,\n",
    "        \"seed\": config[\"training\"][\"random_state\"],\n",
    "        \"use_hpo\": config[\"training\"][\"use_hpo\"],\n",
    "        \"mean_inference_time\": mean_inference_time,\n",
    "        \"std_inference_time\": std_inference_time,\n",
    "        \"mean_parameters\": mean_parameters,\n",
    "        \"std_parameters\": std_parameters,\n",
    "    }\n",
    "\n",
    "    if task_type == \"binary\":\n",
    "        summary_stats.update({\n",
    "            \"mean_acc\": mean_acc,\n",
    "            \"std_acc\": std_acc,\n",
    "            \"mean_f1\": mean_f1,\n",
    "            \"std_f1\": std_f1,\n",
    "            \"mean_roc\": mean_roc,\n",
    "            \"std_roc\": std_roc,\n",
    "        })\n",
    "    else:\n",
    "        summary_stats.update({\n",
    "            \"mean_mae\": mean_mae,\n",
    "            \"std_mae\": std_mae,\n",
    "            \"mean_mse\": mean_mse,\n",
    "            \"std_mse\": std_mse,\n",
    "            \"mean_rmse\": mean_rmse,\n",
    "            \"std_rmse\": std_rmse,\n",
    "            \"mean_r2\": mean_r2,\n",
    "            \"std_r2\": std_r2,\n",
    "        })\n",
    "\n",
    "    # Load existing summary file if it exists, otherwise create new\n",
    "    summary_file = os.path.join(config[\"data\"][\"results_dir_path\"], \"teacher\", f\"{dataset_id}_results.json\")\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(summary_file), exist_ok=True)\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file, 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "    else:\n",
    "        all_results = {}\n",
    "\n",
    "    # Add current model results to the dataset summary\n",
    "    # Use simple incremental numbering\n",
    "    next_num = len(all_results) + 1\n",
    "    model_key = str(next_num)\n",
    "\n",
    "    # Add current model results to the dataset summary\n",
    "    all_results[model_key] = summary_stats\n",
    "\n",
    "    # Save updated summary\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    logger.info(f\"Summary statistics saved to: {summary_file}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE FOLD INDICES (for reproducibility and student training)\n",
    "    # -------------------------------------------------------------------------\n",
    "    fold_indices_file = os.path.join(config[\"data\"][\"fold_indices_path\"], f\"dataset_{dataset_id}.json\")\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(config[\"data\"][\"fold_indices_path\"], exist_ok=True)\n",
    "    if not os.path.exists(fold_indices_file):\n",
    "        with open(fold_indices_file, 'w') as f:\n",
    "            json.dump(fold_indices, f, indent=2)\n",
    "        logger.info(f\"Fold indices saved to: {fold_indices_file}\")\n",
    "    else:\n",
    "        logger.info(f\"Fold indices file already exists: {fold_indices_file}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE TEACHER PREDICTIONS (targets for student training)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Combine predictions from all outer folds\n",
    "    if output_dfs:  # Check if we have any DataFrames to concatenate\n",
    "        output_df = pd.concat(output_dfs, ignore_index=True)\n",
    "    else:\n",
    "        output_df = pd.DataFrame(columns=[\"index\", \"output\"])\n",
    "    output_df = output_df.sort_values(by=\"index\")\n",
    "    \n",
    "    # Create the full directory structure\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    output_dir = os.path.join(config[\"data\"][\"output_dir_path\"], sub_folder, \"teacher\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_file = os.path.join(output_dir, f\"{dataset_id}_{model_type}.csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    logger.info(f\"{config['model']['teacher_model']} outputs saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1e150",
   "metadata": {},
   "source": [
    "# Train Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1289fc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 09:49:10,438 - __main__ - INFO - Loading configuration...\n",
      "2025-06-06 09:49:10,439 - __main__ - INFO - Loading dataset 197 from cache at 'data/cache/openml_dataset_197.pkl'...\n",
      "2025-06-06 09:49:10,441 - __main__ - INFO - Dataset 197 loaded successfully with task type: regression\n",
      "2025-06-06 09:49:10,442 - __main__ - INFO - Results already exist for dataset 197 with model random_forest(tabpfn), HPO: False, seed: 42\n",
      "2025-06-06 09:49:10,443 - __main__ - INFO - Skipping dataset 197 - results already computed\n"
     ]
    }
   ],
   "source": [
    "# Get list of datasets to process from configuration\n",
    "datasets = config[\"data\"][\"datasets\"]\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN TRAINING LOOP - Process each dataset independently\n",
    "# =============================================================================\n",
    "for dataset_id in datasets:\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SETUP AND INITIALIZATION\n",
    "    # -------------------------------------------------------------------------\n",
    "    logger = setup_logging()\n",
    "    logger.info(\"Loading configuration...\")\n",
    "\n",
    "    # Extract model configuration for this run\n",
    "    student_model_type = config[\"model\"][\"student_model\"]\n",
    "    teacher_model_type = config[\"model\"][\"teacher_model\"]\n",
    "    preprocessing_type = config[\"student_models\"][student_model_type][\"preprocessing\"]\n",
    "    use_hpo = config[\"training\"][\"use_hpo\"]\n",
    "    train_on_logits = config[\"training\"][\"train_on_logits\"]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 0: DATA LOADING\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Load dataset from OpenML with caching for efficiency\n",
    "    X, y, cat_cols, _, original_task_type = load_dataset(\n",
    "        dataset_id=dataset_id,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 1: INFRASTRUCTURE SETUP\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Note: Checking for existing results is placeholder for future implementation\n",
    "    model_task_type = \"binary\" if (original_task_type == \"binary\" and not train_on_logits) else \"regression\"\n",
    "    summary_file = os.path.join(config[\"data\"][\"results_dir_path\"], \"student\", f\"{dataset_id}_results.json\")\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file, 'r') as f:\n",
    "            existing_results = json.load(f)\n",
    "        \n",
    "        # Check if we already have results with the same configuration\n",
    "        config_exists = False\n",
    "        for key, result in existing_results.items():\n",
    "            if (result.get('student_model_type') == student_model_type and \n",
    "                result.get('teacher_model_type') == teacher_model_type and\n",
    "                result.get('student_task_type') == model_task_type and\n",
    "                result.get('use_hpo') == use_hpo and \n",
    "                result.get('seed') == config[\"training\"][\"random_state\"]):\n",
    "                config_exists = True\n",
    "                logger.info(f\"Results already exist for dataset {dataset_id} with model {student_model_type}({teacher_model_type}), HPO: {use_hpo}, seed: {config['training']['random_state']}\")\n",
    "                break\n",
    "        \n",
    "        if config_exists:\n",
    "            logger.info(f\"Skipping dataset {dataset_id} - results already computed\")\n",
    "            continue\n",
    "\n",
    "    # Configure GPU/CPU usage for training\n",
    "    device = check_GPU_availability()\n",
    "\n",
    "    # Set random seed for reproducibility across all libraries\n",
    "    set_seed(config[\"training\"][\"random_state\"])\n",
    "    logger.info(f\"Random seed set to {config['training']['random_state']}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 2: LOAD PREVIOUSLY SAVED FOLD INDICES AND TEACHER PREDICTIONS\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Load the saved fold indices \n",
    "    fold_indices_file = os.path.join(config[\"data\"][\"fold_indices_path\"], f\"dataset_{dataset_id}.json\")\n",
    "    with open(fold_indices_file, 'r') as f:\n",
    "        fold_indices = json.load(f)\n",
    "    logger.info(f\"Loaded fold indices from: {fold_indices_file}\") \n",
    "\n",
    "    # Load the TabPFN outputs (teacher predictions)\n",
    "    subfolder = \"hpo\" if config[\"training\"][\"use_hpo\"] else \"default\"\n",
    "    directory = os.path.join(config[\"data\"][\"output_dir_path\"], subfolder, \"teacher\")\n",
    "    teacher_outputs_file = os.path.join(directory, f\"{dataset_id}_{teacher_model_type}.csv\")\n",
    "    teacher_outputs_df = pd.read_csv(teacher_outputs_file)\n",
    "    logger.info(f\"Loaded {teacher_model_type} outputs from: {teacher_outputs_file}\")\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # STEP 3: PREPROCESS TEACHER OUTPUTS\n",
    "    # --------------------------------------------------------------------------\n",
    "    if original_task_type == \"regression\":\n",
    "        model_task_type = \"regression\"\n",
    "        # For regression, we can use the outputs directly as they are already numeric\n",
    "        teacher_preds = teacher_outputs_df['output'].astype(float)\n",
    "        # Create a mapping from index to outputs for easy lookup\n",
    "        index_to_outputs = dict(zip(teacher_outputs_df['index'].values, teacher_preds))\n",
    "\n",
    "    else:\n",
    "        if train_on_logits:\n",
    "            model_task_type = \"regression\"\n",
    "            # Convert probabilities to logits\n",
    "            # Clip probabilities to avoid log(0) or log(1)\n",
    "            eps = 1e-7\n",
    "            teacher_probs = np.clip(teacher_outputs_df['output'].values, eps, 1 - eps)\n",
    "            teacher_logits = np.log(teacher_probs / (1 - teacher_probs))\n",
    "            # Create a mapping from index to logits for easy lookup\n",
    "            index_to_outputs = dict(zip(teacher_outputs_df['index'].values, teacher_logits))\n",
    "        else:\n",
    "            model_task_type = \"binary\"\n",
    "            # Convert probabilities to binary predictions\n",
    "            teacher_preds = (teacher_outputs_df['output'].values > 0.5).astype(int)\n",
    "            # Create a mapping from index to predictions for easy lookup\n",
    "            index_to_outputs = dict(zip(teacher_outputs_df['index'].values, teacher_preds))\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # STEP 4: INITIALIZE DATA STRUCTURES\n",
    "    # -------------------------------------------------------------------------\n",
    "    output_dfs = []\n",
    "\n",
    "    outer_fold_scores = []\n",
    "\n",
    "    # =========================================================================\n",
    "    # STEP 5: OUTER CROSS-VALIDATION LOOP\n",
    "    # =========================================================================\n",
    "    # Each iteration provides one unbiased performance estimate\n",
    "    for fold_key, fold_data in fold_indices[\"outer_folds\"].items():\n",
    "\n",
    "        # Extract outer fold number and indices from the fold key\n",
    "        outer_fold = int(fold_key.split('_')[1])\n",
    "        train_idx = np.array(fold_data[\"train_idx\"])\n",
    "        test_idx = np.array(fold_data[\"test_idx\"])\n",
    "\n",
    "        # Log the first 10 indices of the outer fold for debugging\n",
    "        logger.info(f\"Outer Fold {outer_fold} - Train Indices: {train_idx[:10]}, Test Indices: {test_idx[:10]}\")\n",
    "\n",
    "        logger.info(f\"-------------------- Outer Fold {outer_fold} --------------------\")\n",
    "\n",
    "        # Split data according to current outer fold\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # INNER CROSS-VALIDATION SETUP (for model validation)\n",
    "        # ---------------------------------------------------------------------\n",
    "        inner_folds_data = fold_indices[\"inner_folds\"][f\"outer_fold_{outer_fold}\"]\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 6: INNER CROSS-VALIDATION LOOP (hyperparameter validation)\n",
    "        # =========================================================================\n",
    "        def objective(trial):\n",
    "            \n",
    "            hyperparams = suggest_hyperparameters(\n",
    "                trial=trial,\n",
    "                model_type=student_model_type,\n",
    "                task_type=model_task_type,\n",
    "                use_hpo=use_hpo,\n",
    "            )\n",
    "\n",
    "            inner_fold_scores = []\n",
    "            val_metrics_list = []\n",
    "\n",
    "            # This loop would typically be used for hyperparameter optimization\n",
    "            for inner_fold_key, inner_fold_data in inner_folds_data.items():\n",
    "                inner_fold = int(inner_fold_key.split('_')[2])\n",
    "                \n",
    "                # -----------------------------------------------------------------\n",
    "                # INDEX MANAGEMENT (Critical for avoiding data leakage)\n",
    "                # -----------------------------------------------------------------\n",
    "                # Get absolute indices from saved data\n",
    "                absolute_inner_train_idx = np.array(inner_fold_data[\"train_idx\"])\n",
    "                absolute_inner_val_idx = np.array(inner_fold_data[\"val_idx\"])\n",
    "                \n",
    "                # Convert absolute indices to relative indices for the current outer training set\n",
    "                inner_train_relative = np.where(np.isin(train_idx, absolute_inner_train_idx))[0]\n",
    "                inner_val_relative = np.where(np.isin(train_idx, absolute_inner_val_idx))[0] \n",
    "\n",
    "                # Split inner training data using relative indices\n",
    "                X_inner_train, X_inner_val = X_train.iloc[inner_train_relative], X_train.iloc[inner_val_relative]\n",
    "                y_inner_train, y_inner_val = y_train[inner_train_relative], y_train[inner_val_relative] # Hard labels or Regression targets\n",
    "\n",
    "                # Get teacher outputs for inner training and validation sets\n",
    "                teacher_outputs_inner_train = np.array([index_to_outputs[idx] for idx in absolute_inner_train_idx])\n",
    "                teacher_outputs_inner_val = np.array([index_to_outputs[idx] for idx in absolute_inner_val_idx]) # Probs or Regression logits\n",
    "\n",
    "                # ---------------------------------------------------------------------\n",
    "                # PREPROCESSING: Apply model-specific data transformations\n",
    "                # ---------------------------------------------------------------------\n",
    "                X_inner_train, X_inner_val = preprocess(\n",
    "                    X_inner_train,\n",
    "                    y_inner_train,\n",
    "                    X_inner_val, \n",
    "                    cat_cols,\n",
    "                    config,\n",
    "                    preprocessing_type=preprocessing_type,\n",
    "                )\n",
    "                # ----------------------------------------------------------------------\n",
    "                # MODEL TRAINING: Train student model on inner training data\n",
    "                # ----------------------------------------------------------------------\n",
    "                model = get_student_model(config=config, task_type=model_task_type, device=device, hyperparams=hyperparams, cat_cols=cat_cols)\n",
    "                logger.info(f\"Training Model on Outer Fold {outer_fold}, Inner Fold {inner_fold}...\")\n",
    "                model.train(X_inner_train, teacher_outputs_inner_train)\n",
    "\n",
    "                # ----------------------------------------------------------------------\n",
    "                # VALIDATION: Evaluate model performance on inner validation set\n",
    "                # ----------------------------------------------------------------------\n",
    "                val_preds = model.predict(X_inner_val) # Probs or Regression logits\n",
    "                val_metrics = model.evaluate(y_pred=val_preds, y_true=y_inner_val, y_teacher_true=teacher_outputs_inner_val, original_task_type=original_task_type)\n",
    "\n",
    "                # Store metrics from this fold for later mean calculation\n",
    "                val_metrics_list.append(val_metrics)\n",
    "\n",
    "                if model_task_type == \"binary\":\n",
    "                    inner_fold_scores.append(val_metrics[\"fidelity_f1\"])\n",
    "                    trial.report(np.mean(inner_fold_scores), step=inner_fold)\n",
    "                else:\n",
    "                    inner_fold_scores.append(-val_metrics[\"fidelity_mae\"])\n",
    "                    trial.report(np.mean(inner_fold_scores), step=inner_fold)\n",
    "\n",
    "            # Calculate mean metrics as user attributes after all inner folds\n",
    "            if val_metrics_list:\n",
    "                # Get all metric keys from the first fold\n",
    "                metric_keys = val_metrics_list[0].keys()\n",
    "                \n",
    "                for metric_key in metric_keys:\n",
    "                    # Calculate mean across all inner folds for this metric\n",
    "                    metric_values = [fold_metrics[metric_key] for fold_metrics in val_metrics_list]\n",
    "                    mean_metric = np.mean(metric_values)\n",
    "                    trial.set_user_attr(f\"mean_{metric_key}\", mean_metric)\n",
    "\n",
    "            return np.mean(inner_fold_scores)\n",
    "        \n",
    "        logger.info(f\"Starting hyperparameter optimization for outer fold {outer_fold}...\")\n",
    "\n",
    "        study_kwargs = dict(\n",
    "            direction=\"maximize\",\n",
    "            study_name=f\"{dataset_id}.{outer_fold}.{student_model_type}({teacher_model_type}).{model_task_type[:2]}\",\n",
    "            load_if_exists=True,\n",
    "            sampler=optuna.samplers.TPESampler(seed=config[\"training\"][\"random_state\"]),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=1),\n",
    "        )\n",
    "\n",
    "        if use_hpo:\n",
    "            os.makedirs(config[\"data\"][\"optuna_db_path\"], exist_ok=True)\n",
    "            study_kwargs[\"storage\"] = f\"sqlite:///{config['data']['optuna_db_path']}/optuna.db\"\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            **study_kwargs,\n",
    "        )\n",
    "\n",
    "        # Optimize\n",
    "        completed_trials = len(study.trials)\n",
    "        remaining_trials = config[\"training\"][\"trials\"] - completed_trials\n",
    "\n",
    "\n",
    "        if remaining_trials > 0:\n",
    "            default_hyperparams = suggest_hyperparameters(None, student_model_type, model_task_type, False)\n",
    "            study.enqueue_trial(default_hyperparams)\n",
    "            study.optimize(\n",
    "                objective, \n",
    "                n_trials=remaining_trials if use_hpo else 1,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"The study has already reached the maximum number of trials.\")\n",
    "\n",
    "        if use_hpo:\n",
    "            # When HPO is used, trial.suggest_ methods are called, populating trial.params\n",
    "            best_hyperparams = study.best_trial.params\n",
    "        else:\n",
    "            # When not using HPO, a single trial runs with default parameters.\n",
    "            best_hyperparams = suggest_hyperparameters(trial=None, model_type=student_model_type, task_type=model_task_type, use_hpo=False)\n",
    "\n",
    "        logger.info(f\"Best hyperparameters for fold {outer_fold}: {best_hyperparams}\")\n",
    "        logger.info(f\"Best score: {study.best_value:.4f}\")\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 7: FINAL MODEL TRAINING (on complete outer training set)\n",
    "        # =========================================================================\n",
    "        # Get teacher logits for outer training set\n",
    "        teacher_outputs_train = np.array([index_to_outputs[idx] for idx in train_idx])\n",
    "        # Preprocess the outer training and test sets\n",
    "        X_train, X_test = preprocess(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            cat_cols,\n",
    "            config,\n",
    "            preprocessing_type=preprocessing_type,  \n",
    "        )\n",
    "        \n",
    "        # Train final model on complete outer training set\n",
    "        logger.info(\"------------------------------------------------------\")\n",
    "        logger.info(f\"Retraining Model on Outer Fold {outer_fold}\")\n",
    "        model = get_student_model(\n",
    "            config=config,\n",
    "            task_type=model_task_type,\n",
    "            device=device,\n",
    "            hyperparams=best_hyperparams,  # Use best hyperparameters from HPO\n",
    "            cat_cols=cat_cols,  \n",
    "        )\n",
    "        model.train(X_train, teacher_outputs_train)\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 8: FINAL EVALUATION (unbiased performance on outer test set)\n",
    "        # =========================================================================\n",
    "        # This provides the unbiased performance estimate for this fold\n",
    "        start_time = time.time()\n",
    "        test_preds = model.predict(X_test)  # Predicted logits or probabilities\n",
    "        end_time = time.time() - start_time\n",
    "        logger.info(f\"\\t Inference Time: {end_time:.5f} seconds\")\n",
    "        teacher_outputs_test = np.array([index_to_outputs[idx] for idx in test_idx])\n",
    "        test_metrics = model.evaluate(test_preds, y_test, teacher_outputs_test, original_task_type)\n",
    "\n",
    "        # Store outer fold score for later analysis\n",
    "        outer_fold_results = {\n",
    "            \"fold\": outer_fold,\n",
    "            \"seed\": config[\"training\"][\"random_state\"],\n",
    "            \"inference_time\": end_time,\n",
    "            **test_metrics,\n",
    "        }\n",
    "        outer_fold_scores.append(outer_fold_results)\n",
    "\n",
    "        # =========================================================================\n",
    "        # STEP 9: STORE PREDICTIONS FOR STUDENT TRAINING\n",
    "        # =========================================================================\n",
    "        # Save predictions with their corresponding dataset indices\n",
    "        output_dfs.append(pd.DataFrame({\n",
    "            \"index\": test_idx,\n",
    "            \"output\": test_preds[:, 1] if model_task_type == \"binary\" else test_preds  \n",
    "        }))\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 10: SAVE RESULTS AND METADATA\n",
    "    # =========================================================================\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE OUTER FOLD METRICS\n",
    "    # -------------------------------------------------------------------------\n",
    "    outer_fold_df = pd.DataFrame(outer_fold_scores)\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    output_dir = os.path.join(config[\"data\"][\"outer_folds_path\"], \"student\", sub_folder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    metrics_file = os.path.join(output_dir, f\"{dataset_id}_{student_model_type}({teacher_model_type}).{model_task_type[:2]}.csv\")\n",
    "    outer_fold_df.to_csv(metrics_file, index=False)\n",
    "    logger.info(f\"Outer fold metrics saved to: {metrics_file}\")\n",
    "\n",
    "    # Calculate and log overall performance across all folds\n",
    "    mean_inference_time = outer_fold_df['inference_time'].mean()\n",
    "    std_inference_time = outer_fold_df['inference_time'].std()\n",
    "    mean_parameters = outer_fold_df['parameters'].mean()\n",
    "    std_parameters = outer_fold_df['parameters'].std()\n",
    "\n",
    "    if original_task_type == \"binary\":\n",
    "        mean_acc = outer_fold_df['acc'].mean()\n",
    "        std_acc = outer_fold_df['acc'].std()\n",
    "        mean_f1 = outer_fold_df['f1'].mean()\n",
    "        std_f1 = outer_fold_df['f1'].std()\n",
    "        mean_roc = outer_fold_df['roc'].mean()\n",
    "        std_roc = outer_fold_df['roc'].std()\n",
    "        \n",
    "        mean_fidelity_acc = outer_fold_df['fidelity_acc'].mean()\n",
    "        std_fidelity_acc = outer_fold_df['fidelity_acc'].std()\n",
    "        mean_fidelity_f1 = outer_fold_df['fidelity_f1'].mean()\n",
    "        std_fidelity_f1 = outer_fold_df['fidelity_f1'].std()\n",
    "        mean_fidelity_roc = outer_fold_df['fidelity_roc'].mean()\n",
    "        std_fidelity_roc = outer_fold_df['fidelity_roc'].std()\n",
    "        \n",
    "        logger.info(f\"=== FINAL RESULTS FOR DATASET {dataset_id} ===\")\n",
    "        logger.info(f\"Balanced Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "        logger.info(f\"F1 Score: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "        logger.info(f\"ROC AUC: {mean_roc:.4f} ± {std_roc:.4f}\")\n",
    "        logger.info(f\"Fidelity Accuracy: {mean_fidelity_acc:.4f} ± {std_fidelity_acc:.4f}\")\n",
    "        logger.info(f\"Fidelity F1 Score: {mean_fidelity_f1:.4f} ± {std_fidelity_f1:.4f}\")\n",
    "        logger.info(f\"Fidelity ROC AUC: {mean_fidelity_roc:.4f} ± {std_fidelity_roc:.4f}\")\n",
    "\n",
    "        if model_task_type == \"regression\":\n",
    "            mean_fidelity_mae = outer_fold_df['fidelity_mae'].mean()\n",
    "            std_fidelity_mae = outer_fold_df['fidelity_mae'].std()\n",
    "            mean_fidelity_mse = outer_fold_df['fidelity_mse'].mean()\n",
    "            std_fidelity_mse = outer_fold_df['fidelity_mse'].std()\n",
    "            mean_fidelity_rmse = outer_fold_df['fidelity_rmse'].mean()\n",
    "            std_fidelity_rmse = outer_fold_df['fidelity_rmse'].std()\n",
    "            mean_fidelity_r2 = outer_fold_df['fidelity_r2'].mean()\n",
    "            std_fidelity_r2 = outer_fold_df['fidelity_r2'].std()\n",
    "\n",
    "            logger.info(f\"Fidelity MAE: {mean_fidelity_mae:.4f} ± {std_fidelity_mae:.4f}\")\n",
    "            logger.info(f\"Fidelity MSE: {mean_fidelity_mse:.4f} ± {std_fidelity_mse:.4f}\")\n",
    "            logger.info(f\"Fidelity RMSE: {mean_fidelity_rmse:.4f} ± {std_fidelity_rmse:.4f}\")\n",
    "            logger.info(f\"Fidelity R2: {mean_fidelity_r2:.4f} ± {std_fidelity_r2:.4f}\")\n",
    "\n",
    "    else:\n",
    "        mean_mae = outer_fold_df['mae'].mean()\n",
    "        std_mae = outer_fold_df['mae'].std()\n",
    "        mean_mse = outer_fold_df['mse'].mean()\n",
    "        std_mse = outer_fold_df['mse'].std()\n",
    "        mean_rmse = outer_fold_df['rmse'].mean()\n",
    "        std_rmse = outer_fold_df['rmse'].std()\n",
    "        mean_r2 = outer_fold_df['r2'].mean()\n",
    "        std_r2 = outer_fold_df['r2'].std()\n",
    "\n",
    "        logger.info(f\"=== FINAL RESULTS FOR DATASET {dataset_id} ===\")\n",
    "        logger.info(f\"MAE: {mean_mae:.4f} ± {std_mae:.4f}\")\n",
    "        logger.info(f\"MSE: {mean_mse:.4f} ± {std_mse:.4f}\")\n",
    "        logger.info(f\"RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "        logger.info(f\"R2: {mean_r2:.4f} ± {std_r2:.4f}\")\n",
    "\n",
    "        mean_fidelity_mae = outer_fold_df['fidelity_mae'].mean()\n",
    "        std_fidelity_mae = outer_fold_df['fidelity_mae'].std()\n",
    "        mean_fidelity_mse = outer_fold_df['fidelity_mse'].mean()\n",
    "        std_fidelity_mse = outer_fold_df['fidelity_mse'].std()\n",
    "        mean_fidelity_rmse = outer_fold_df['fidelity_rmse'].mean()\n",
    "        std_fidelity_rmse = outer_fold_df['fidelity_rmse'].std()\n",
    "        mean_fidelity_r2 = outer_fold_df['fidelity_r2'].mean()\n",
    "        std_fidelity_r2 = outer_fold_df['fidelity_r2'].std()\n",
    "\n",
    "        logger.info(f\"Fidelity MAE: {mean_fidelity_mae:.4f} ± {std_fidelity_mae:.4f}\")\n",
    "        logger.info(f\"Fidelity MSE: {mean_fidelity_mse:.4f} ± {std_fidelity_mse:.4f}\")\n",
    "        logger.info(f\"Fidelity RMSE: {mean_fidelity_rmse:.4f} ± {std_fidelity_rmse:.4f}\")\n",
    "        logger.info(f\"Fidelity R2: {mean_fidelity_r2:.4f} ± {std_fidelity_r2:.4f}\")\n",
    "\n",
    "    logger.info(f\"Mean Inference Time: {mean_inference_time:.4f} ± {std_inference_time:.4f}\")\n",
    "    logger.info(f\"Mean Parameters: {mean_parameters:.4f} ± {std_parameters:.4f}\")\n",
    "\n",
    "    # Save summary statistics as well\n",
    "    summary_stats = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"student_model_type\": student_model_type,\n",
    "        \"teacher_model_type\": teacher_model_type,\n",
    "        \"original_task_type\": original_task_type,\n",
    "        \"student_task_type\": model_task_type,\n",
    "        \"seed\": config[\"training\"][\"random_state\"],\n",
    "        \"use_hpo\": config[\"training\"][\"use_hpo\"],\n",
    "        \"mean_inference_time\": mean_inference_time,\n",
    "        \"std_inference_time\": std_inference_time,\n",
    "        \"mean_parameters\": mean_parameters,\n",
    "        \"std_parameters\": std_parameters,\n",
    "    }\n",
    "\n",
    "    if original_task_type == \"binary\":\n",
    "        summary_stats.update({\n",
    "            \"mean_acc\": mean_acc,\n",
    "            \"std_acc\": std_acc,\n",
    "            \"mean_f1\": mean_f1,\n",
    "            \"std_f1\": std_f1,\n",
    "            \"mean_roc\": mean_roc,\n",
    "            \"std_roc\": std_roc,\n",
    "            \"mean_fidelity_acc\": mean_fidelity_acc,\n",
    "            \"std_fidelity_acc\": std_fidelity_acc,\n",
    "            \"mean_fidelity_f1\": mean_fidelity_f1,\n",
    "            \"std_fidelity_f1\": std_fidelity_f1,\n",
    "            \"mean_fidelity_roc\": mean_fidelity_roc,\n",
    "            \"std_fidelity_roc\": std_fidelity_roc,\n",
    "        })\n",
    "        if model_task_type == \"regression\":\n",
    "            summary_stats.update({\n",
    "                \"mean_fidelity_mae\": mean_fidelity_mae,\n",
    "                \"std_fidelity_mae\": std_fidelity_mae,\n",
    "                \"mean_fidelity_mse\": mean_fidelity_mse,\n",
    "                \"std_fidelity_mse\": std_fidelity_mse,\n",
    "                \"mean_fidelity_rmse\": mean_fidelity_rmse,\n",
    "                \"std_fidelity_rmse\": std_fidelity_rmse,\n",
    "                \"mean_fidelity_r2\": mean_fidelity_r2,\n",
    "                \"std_fidelity_r2\": std_fidelity_r2,\n",
    "            })\n",
    "    else:\n",
    "        summary_stats.update({\n",
    "            \"mean_mae\": mean_mae,\n",
    "            \"std_mae\": std_mae,\n",
    "            \"mean_mse\": mean_mse,\n",
    "            \"std_mse\": std_mse,\n",
    "            \"mean_rmse\": mean_rmse,\n",
    "            \"std_rmse\": std_rmse,\n",
    "            \"mean_r2\": mean_r2,\n",
    "            \"std_r2\": std_r2,\n",
    "            \"mean_fidelity_mae\": mean_fidelity_mae,\n",
    "            \"std_fidelity_mae\": std_fidelity_mae,\n",
    "            \"mean_fidelity_mse\": mean_fidelity_mse,\n",
    "            \"std_fidelity_mse\": std_fidelity_mse,\n",
    "            \"mean_fidelity_rmse\": mean_fidelity_rmse,\n",
    "            \"std_fidelity_rmse\": std_fidelity_rmse,\n",
    "            \"mean_fidelity_r2\": mean_fidelity_r2,\n",
    "            \"std_fidelity_r2\": std_fidelity_r2,\n",
    "        })\n",
    "\n",
    "    # Load existing summary file if it exists, otherwise create new\n",
    "    summary_file = os.path.join(config[\"data\"][\"results_dir_path\"], \"student\", f\"{dataset_id}_results.json\")\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(summary_file), exist_ok=True)\n",
    "    if os.path.exists(summary_file):\n",
    "        with open(summary_file, 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "    else:\n",
    "        all_results = {}\n",
    "\n",
    "    # Add current model results to the dataset summary\n",
    "    # Use simple incremental numbering\n",
    "    next_num = len(all_results) + 1\n",
    "    model_key = str(next_num)\n",
    "\n",
    "    # Add current model results to the dataset summary\n",
    "    all_results[model_key] = summary_stats\n",
    "\n",
    "    # Save updated summary\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    logger.info(f\"Summary statistics saved to: {summary_file}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # SAVE STUDENT PREDICTIONS\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Combine predictions from all outer folds\n",
    "    if output_dfs:  # Check if we have any DataFrames to concatenate\n",
    "        output_df = pd.concat(output_dfs, ignore_index=True)\n",
    "    else:\n",
    "        output_df = pd.DataFrame(columns=[\"index\", \"output\"])\n",
    "    output_df = output_df.sort_values(by=\"index\")\n",
    "    \n",
    "    # Create the full directory structure\n",
    "    sub_folder = \"hpo\" if use_hpo else \"default\"\n",
    "    output_dir = os.path.join(config[\"data\"][\"output_dir_path\"], sub_folder, \"student\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_file = os.path.join(output_dir, f\"{dataset_id}_{student_model_type}({teacher_model_type}).csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    logger.info(f\"{config['model']['student_model']} outputs saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
